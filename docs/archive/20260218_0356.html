<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-18 03:56</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260218_0356</div>
    <div class="row"><div class="card">
<div class="title">EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing</div>
<div class="meta-line">Authors: Yehonathan Litman, Shikun Liu, Dario Seyb, Nicholas Milef, Yang Zhou, Carl Marshall, Shubham Tulsiani, Caleb Leak</div>
<div class="meta-line">First: 2026-02-16T18:59:58+00:00 · Latest: 2026-02-16T18:59:58+00:00</div>
<div class="meta-line">Comments: Project page: https://yehonathanlitman.github.io/edit_ctrl</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15031v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15031v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://yehonathanlitman.github.io/edit_ctrl">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">High-fidelity generative video editing has seen significant quality improvements by leveraging pre-trained video foundation models. However, their computational cost is a major bottleneck, as they are often designed to inefficiently process the full video context regardless of the inpainting mask&#x27;s size, even for sparse, localized edits. In this paper, we introduce EditCtrl, an efficient video inpainting control framework that focuses computation only where it is needed. Our approach features a novel local video context module that operates solely on masked tokens, yielding a computational cost proportional to the edit size. This local-first generation is then guided by a lightweight temporal global context embedder that ensures video-wide context consistency with minimal overhead. Not only is EditCtrl 10 times more compute efficient than state-of-the-art generative editing methods, it even improves editing quality compared to methods designed with full-attention. Finally, we showcase how EditCtrl unlocks new capabilities, including multi-region editing with text prompts and autoregressive content propagation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>EditCtrl：实时生成视频编辑的局部与全局控制解耦</div>
<div class="mono" style="margin-top:8px">高保真生成视频编辑通过利用预训练的视频基础模型实现了显著的质量提升。然而，它们的计算成本是一个主要瓶颈，因为它们通常设计为低效地处理完整视频上下文，而不考虑修补掩码的大小，即使对于稀疏的局部编辑。在本文中，我们介绍了EditCtrl，一个高效的视频修补控制框架，仅在需要的地方集中计算。我们的方法具有一个新颖的局部视频上下文模块，仅在掩码标记上操作，计算成本与编辑大小成正比。这种局部优先的生成由一个轻量级的时间全局上下文嵌入器引导，确保视频范围内的上下文一致性，且开销最小。EditCtrl的计算效率比最先进的生成编辑方法高出10倍，甚至在编辑质量上优于设计为全注意力的方法。最后，我们展示了EditCtrl如何解锁新功能，包括使用文本提示的多区域编辑和自回归内容传播。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the inefficiencies in computational costs associated with pre-trained video foundation models used for generative video editing, particularly when performing localized edits. The authors introduce EditCtrl, a video inpainting control framework that optimizes computation by focusing only on the masked regions needing edits, utilizing a local video context module and a lightweight global context embedder for consistency. Experimental results demonstrate that EditCtrl is ten times more computationally efficient than existing generative editing methods while also enhancing editing quality, enabling new functionalities such as multi-region editing with text prompts and autoregressive content propagation.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决现有生成视频编辑方法在处理整个视频上下文时的计算低效问题，这些方法并不考虑编辑的大小。作者提出了EditCtrl，这是一种视频修补控制框架，采用局部视频上下文模块，仅对掩码标记进行计算，从而降低与编辑大小相关的计算成本。实验结果表明，EditCtrl的计算效率比当前最先进的方法高出十倍，并且提高了编辑质量，同时还实现了多区域编辑与文本提示和自回归内容传播等新功能。</div>
</details>
</div>
<div class="card">
<div class="title">Image Generation with a Sphere Encoder</div>
<div class="meta-line">Authors: Kaiyu Yue, Menglin Jia, Ji Hou, Tom Goldstein</div>
<div class="meta-line">First: 2026-02-16T18:59:57+00:00 · Latest: 2026-02-16T18:59:57+00:00</div>
<div class="meta-line">Comments: Technical report</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15030v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15030v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://sphere-encoder.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce the Sphere Encoder, an efficient generative framework capable of producing images in a single forward pass and competing with many-step diffusion models using fewer than five steps. Our approach works by learning an encoder that maps natural images uniformly onto a spherical latent space, and a decoder that maps random latent vectors back to the image space. Trained solely through image reconstruction losses, the model generates an image by simply decoding a random point on the sphere. Our architecture naturally supports conditional generation, and looping the encoder/decoder a few times can further enhance image quality. Across several datasets, the sphere encoder approach yields performance competitive with state of the art diffusions, but with a small fraction of the inference cost. Project page is available at https://sphere-encoder.github.io .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>球体编码器的图像生成</div>
<div class="mono" style="margin-top:8px">我们介绍了球体编码器，这是一种高效的生成框架，能够在单次前向传递中生成图像，并且在使用不到五个步骤的情况下与多步骤扩散模型竞争。我们的方法通过学习一个编码器，将自然图像均匀映射到球形潜在空间，以及一个解码器，将随机潜在向量映射回图像空间。模型仅通过图像重建损失进行训练，通过简单地解码球面上的随机点生成图像。我们的架构自然支持条件生成，并且循环使用编码器/解码器几次可以进一步提高图像质量。在多个数据集上，球体编码器方法的性能与最先进的扩散模型相当，但推理成本仅为其一小部分。项目页面可在 https://sphere-encoder.github.io 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for efficient image generation methods that can compete with existing diffusion models while reducing computational costs. The authors propose the Sphere Encoder, which utilizes an encoder to map images to a spherical latent space and a decoder to reconstruct images from random latent vectors, trained through image reconstruction losses. Experimental results demonstrate that this method achieves competitive performance with state-of-the-art diffusion models, requiring significantly fewer steps and lower inference costs across various datasets.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于需要高效的图像生成方法，以便在降低计算成本的同时与现有的扩散模型竞争。作者提出了球体编码器，该编码器利用一个将图像映射到球形潜在空间的编码器和一个从随机潜在向量重建图像的解码器，所有这些都是通过图像重建损失进行训练的。实验结果表明，该方法在推理步骤和计算资源显著减少的情况下，仍能实现与最先进的扩散模型竞争的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Superposed parameterised quantum circuits</div>
<div class="meta-line">Authors: Viktoria Patapovich, Maniraman Periyasamy, Mo Kordzanganeh, Alexey Melnikov</div>
<div class="meta-line">First: 2025-06-10T12:44:11+00:00 · Latest: 2026-02-16T18:59:56+00:00</div>
<div class="meta-line">Comments: 20 pages, 6 figures, 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.08749v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.08749v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Quantum machine learning has shown promise for high-dimensional data analysis, yet many existing approaches rely on linear unitary operations and shared trainable parameters across outputs. These constraints limit expressivity and scalability relative to the multi-layered, non-linear architectures of classical deep networks. We introduce superposed parameterised quantum circuits to overcome these limitations. By combining flip-flop quantum random-access memory with repeat-until-success protocols, a superposed parameterised quantum circuit embeds an exponential number of parameterised sub-models in a single circuit and induces polynomial activation functions through amplitude transformations and post-selection. We provide an analytic description of the architecture, showing how multiple parameter sets are trained in parallel while non-linear amplitude transformations broaden representational power beyond conventional quantum kernels. Numerical experiments underscore these advantages: on a 1D step-function regression a two-qubit superposed parameterised quantum circuit cuts the mean-squared error by three orders of magnitude versus a parameter-matched variational baseline; on a 2D star-shaped two-dimensional classification task, introducing a quadratic activation lifts accuracy to 81.4\% and reduces run-to-run variance three-fold. These results position superposed parameterised quantum circuits as a hardware-efficient route toward deeper, more versatile parameterised quantum circuits capable of learning complex decision boundaries.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>叠加参数化量子电路</div>
<div class="mono" style="margin-top:8px">量子机器学习在高维数据分析中展现出潜力，但许多现有方法依赖于线性单位操作和跨输出共享的可训练参数。这些限制相对于经典深度网络的多层非线性架构限制了表达能力和可扩展性。我们引入叠加参数化量子电路以克服这些限制。通过将翻转量子随机存取存储器与重复直到成功的协议相结合，叠加参数化量子电路在单个电路中嵌入了指数数量的参数化子模型，并通过幅度变换和后选择引入多项式激活函数。我们提供了架构的分析描述，展示了如何并行训练多个参数集，同时非线性幅度变换扩展了表示能力，超越了传统量子核。数值实验强调了这些优势：在1D阶跃函数回归中，两个量子比特的叠加参数化量子电路将均方误差降低了三个数量级，相较于参数匹配的变分基线；在2D星形二维分类任务中，引入二次激活将准确率提升至81.4\%，并将运行间方差减少三倍。这些结果将叠加参数化量子电路定位为实现更深、更灵活的参数化量子电路的硬件高效路径，能够学习复杂的决策边界。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the expressivity and scalability of quantum machine learning methods, which are often limited by linear operations and shared parameters. The authors propose superposed parameterised quantum circuits that integrate flip-flop quantum random-access memory with repeat-until-success protocols, enabling the embedding of numerous parameterised sub-models within a single circuit and facilitating polynomial activation functions. Experimental results demonstrate significant improvements, with a two-qubit circuit achieving a three orders of magnitude reduction in mean-squared error for 1D step-function regression and an accuracy increase to 81.4% with reduced variance in a 2D classification task, highlighting the potential of these circuits for more complex learning tasks.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于增强量子机器学习方法的表现力和可扩展性，而这些方法通常受到线性操作和共享参数的限制。作者提出了超叠加参数化量子电路，该电路结合了翻转-翻转量子随机存取存储器和重复直到成功的协议，允许在单个电路中嵌入多个参数化子模型，并通过幅度变换实现多项式激活函数。实验结果表明显著改善，在一维回归任务中，两量子比特电路的均方误差比基线降低了三个数量级，而在二维分类任务中，引入二次激活函数使分类准确率提高到81.4%，并将方差降低了三倍。</div>
</details>
</div>
<div class="card">
<div class="title">Symmetry in language statistics shapes the geometry of model representations</div>
<div class="meta-line">Authors: Dhruva Karkada, Daniel J. Korchinski, Andres Nava, Matthieu Wyart, Yasaman Bahri</div>
<div class="meta-line">First: 2026-02-16T18:59:55+00:00 · Latest: 2026-02-16T18:59:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15029v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15029v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although learned representations underlie neural networks&#x27; success, their fundamental properties remain poorly understood. A striking example is the emergence of simple geometric structures in LLM representations: for example, calendar months organize into a circle, years form a smooth one-dimensional manifold, and cities&#x27; latitudes and longitudes can be decoded by a linear probe. We show that the statistics of language exhibit a translation symmetry -- e.g., the co-occurrence probability of two months depends only on the time interval between them -- and we prove that the latter governs the aforementioned geometric structures in high-dimensional word embedding models. Moreover, we find that these structures persist even when the co-occurrence statistics are strongly perturbed (for example, by removing all sentences in which two months appear together) and at moderate embedding dimension. We show that this robustness naturally emerges if the co-occurrence statistics are collectively controlled by an underlying continuous latent variable. We empirically validate this theoretical framework in word embedding models, text embedding models, and large language models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语言统计中的对称性塑造模型表示的几何结构</div>
<div class="mono" style="margin-top:8px">尽管学习到的表示是神经网络成功的基础，但其基本属性仍然不够清楚。一个显著的例子是大型语言模型（LLM）表示中简单几何结构的出现：例如，日历月份组织成一个圆，年份形成一个平滑的一维流形，城市的纬度和经度可以通过线性探测解码。我们表明，语言的统计数据表现出一种平移对称性——例如，两个月份的共现概率仅依赖于它们之间的时间间隔——并且我们证明后者支配了高维词嵌入模型中上述几何结构。此外，我们发现这些结构即使在共现统计数据受到强烈扰动（例如，通过删除所有两个月份一起出现的句子）和在适度的嵌入维度下仍然存在。我们表明，如果共现统计数据由一个潜在的连续变量共同控制，这种鲁棒性自然出现。我们在词嵌入模型、文本嵌入模型和大型语言模型中实证验证了这一理论框架。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the fundamental properties of learned representations in neural networks, particularly focusing on the geometric structures that emerge in language model representations. The authors demonstrate that language statistics exhibit a translation symmetry, which influences the geometric organization of representations in high-dimensional word embedding models. Key findings reveal that these geometric structures remain robust even under significant perturbations of co-occurrence statistics and at moderate embedding dimensions, suggesting that they are governed by an underlying continuous latent variable, which is validated through empirical studies across various embedding models.</div>
<div class="mono" style="margin-top:8px">本研究探讨了神经网络中学习表示的基本特性，特别关注大型语言模型（LLM）表示中出现的几何结构。作者证明语言统计具有平移对称性，这影响了表示的几何组织，例如日历月份的圆形排列和年份的线性结构。关键实验结果表明，这些几何结构即使在共现统计数据受到显著扰动和中等嵌入维度下仍然保持稳健，表明它们受一个潜在的连续变量控制，该变量共同控制不同嵌入模型中的共现统计。</div>
</details>
</div>
<div class="card">
<div class="title">Long Context, Less Focus: A Scaling Gap in LLMs Revealed through Privacy and Personalization</div>
<div class="meta-line">Authors: Shangding Gu</div>
<div class="meta-line">First: 2026-02-16T18:59:42+00:00 · Latest: 2026-02-16T18:59:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15028v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15028v1">PDF</a> · <a href="https://github.com/SafeRL-Lab/PAPerBench">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) are increasingly deployed in privacy-critical and personalization-oriented scenarios, yet the role of context length in shaping privacy leakage and personalization effectiveness remains largely unexplored. We introduce a large-scale benchmark, PAPerBench, to systematically study how increasing context length influences both personalization quality and privacy protection in LLMs. The benchmark comprises approximately 29,000 instances with context lengths ranging from 1K to 256K tokens, yielding a total of 377K evaluation questions. It jointly evaluates personalization performance and privacy risks across diverse scenarios, enabling controlled analysis of long-context model behavior. Extensive evaluations across state-of-the-art LLMs reveal consistent performance degradation in both personalization and privacy as context length increases. We further provide a theoretical analysis of attention dilution under context scaling, explaining this behavior as an inherent limitation of soft attention in fixed-capacity Transformers. The empirical and theoretical findings together suggest a general scaling gap in current models -- long context, less focus. We release the benchmark to support reproducible evaluation and future research on scalable privacy and personalization. Code and data are available at https://github.com/SafeRL-Lab/PAPerBench</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>长上下文，低聚焦：通过隐私和个性化揭示的LLM扩展差距</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）越来越多地应用于隐私关键和个性化导向的场景，但上下文长度在塑造隐私泄露和个性化效果中的作用仍然 largely 未被探索。我们引入了一个大规模基准，PAPerBench，系统研究增加上下文长度如何影响LLMs中的个性化质量和隐私保护。该基准包含约29,000个实例，上下文长度范围从1K到256K个标记，总共产生377K个评估问题。它在多种场景中共同评估个性化性能和隐私风险，使得对长上下文模型行为的控制分析成为可能。对最先进的LLMs进行的广泛评估显示，随着上下文长度的增加，个性化和隐私的性能均一致下降。我们进一步提供了上下文扩展下注意力稀释的理论分析，解释这种行为是固定容量变换器中软注意力的固有限制。经验和理论发现共同表明当前模型中存在一般的扩展差距——长上下文，低聚焦。我们发布该基准以支持可重复的评估和未来在可扩展隐私和个性化方面的研究。代码和数据可在 https://github.com/SafeRL-Lab/PAPerBench 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the impact of context length on privacy leakage and personalization effectiveness in large language models (LLMs), motivated by their deployment in privacy-sensitive applications. The authors introduce a benchmark called PAPerBench, which includes around 29,000 instances with context lengths from 1K to 256K tokens, allowing for a comprehensive evaluation of personalization performance and privacy risks. The findings indicate that as context length increases, both personalization quality and privacy protection consistently degrade, which is attributed to attention dilution in fixed-capacity Transformers, highlighting a scaling gap in current LLMs.</div>
<div class="mono" style="margin-top:8px">本研究探讨了上下文长度对大型语言模型（LLMs）中隐私泄露和个性化效果的影响，动机是它们在敏感应用中的日益使用。作者引入了一个名为PAPerBench的基准，包含约29,000个实例，上下文长度从1K到256K标记，允许对个性化性能和隐私风险进行全面评估。研究结果表明，随着上下文长度的增加，个性化质量和隐私保护均持续下降，这一现象通过对固定容量变换器中注意力稀释的理论分析得以解释，突显了当前模型中的一个缩放差距，即更长的上下文导致关注度降低。</div>
</details>
</div>
<div class="card">
<div class="title">Generalization from Low- to Moderate-Resolution Spectra with Neural Networks for Stellar Parameter Estimation: A Case Study with DESI</div>
<div class="meta-line">Authors: Xiaosheng Zhao, Yuan-Sen Ting, Rosemary F. G. Wyse, Alexander S. Szalay, Yang Huang, László Dobos, Tamás Budavári, Viska Wei</div>
<div class="meta-line">First: 2026-02-16T18:58:47+00:00 · Latest: 2026-02-16T18:58:47+00:00</div>
<div class="meta-line">Comments: 20 pages, 13 figures, 4 tables. Submitted to AAS journals. Comments welcome</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15021v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15021v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cross-survey generalization is a critical challenge in stellar spectral analysis, particularly in cases such as transferring from low- to moderate-resolution surveys. We investigate this problem using pre-trained models, focusing on simple neural networks such as multilayer perceptrons (MLPs), with a case study transferring from LAMOST low-resolution spectra (LRS) to DESI medium-resolution spectra (MRS). Specifically, we pre-train MLPs on either LRS or their embeddings and fine-tune them for application to DESI stellar spectra. We compare MLPs trained directly on spectra with those trained on embeddings derived from transformer-based models (self-supervised foundation models pre-trained for multiple downstream tasks). We also evaluate different fine-tuning strategies, including residual-head adapters, LoRA, and full fine-tuning. We find that MLPs pre-trained on LAMOST LRS achieve strong performance, even without fine-tuning, and that modest fine-tuning with DESI spectra further improves the results. For iron abundance, embeddings from a transformer-based model yield advantages in the metal-rich ([Fe/H] &gt; -1.0) regime, but underperform in the metal-poor regime compared to MLPs trained directly on LRS. We also show that the optimal fine-tuning strategy depends on the specific stellar parameter under consideration. These results highlight that simple pre-trained MLPs can provide competitive cross-survey generalization, while the role of spectral foundation models for cross-survey stellar parameter estimation requires further exploration.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用神经网络从低分辨率到中分辨率光谱的泛化进行恒星参数估计：以DESI为案例研究</div>
<div class="mono" style="margin-top:8px">跨调查泛化是恒星光谱分析中的一个关键挑战，特别是在从低分辨率到中分辨率调查的转移中。我们使用预训练模型研究这个问题，重点关注简单的神经网络，如多层感知器（MLP），以LAMOST低分辨率光谱（LRS）到DESI中分辨率光谱（MRS）的转移为案例研究。具体而言，我们在LRS或其嵌入上预训练MLP，并对其进行微调以应用于DESI恒星光谱。我们比较了直接在光谱上训练的MLP与在基于变换器模型（自监督基础模型，预训练用于多个下游任务）衍生的嵌入上训练的MLP。我们还评估了不同的微调策略，包括残差头适配器、LoRA和完全微调。我们发现，在没有微调的情况下，预训练于LAMOST LRS的MLP表现出强大的性能，而使用DESI光谱的适度微调进一步改善了结果。对于铁丰度，来自变换器模型的嵌入在金属丰富（[Fe/H] &gt; -1.0）区域具有优势，但在金属贫乏区域的表现不如直接在LRS上训练的MLP。我们还表明，最佳微调策略取决于所考虑的特定恒星参数。这些结果强调，简单的预训练MLP可以提供竞争性的跨调查泛化，而光谱基础模型在跨调查恒星参数估计中的作用需要进一步探索。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to address the challenge of cross-survey generalization in stellar spectral analysis, particularly the transfer from low- to moderate-resolution spectra. The study employs pre-trained multilayer perceptrons (MLPs) to analyze LAMOST low-resolution spectra (LRS) and their application to DESI medium-resolution spectra (MRS), comparing MLPs trained directly on spectra with those trained on embeddings from transformer-based models. The findings indicate that MLPs pre-trained on LRS perform well without fine-tuning, and modest fine-tuning with DESI spectra enhances results, particularly for iron abundance, where transformer embeddings excel in metal-rich conditions but not in metal-poor scenarios, suggesting that the optimal fine-tuning strategy varies by stellar parameter.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决恒星光谱分析中跨调查泛化的挑战，特别是从低分辨率到中分辨率光谱的转移。该研究采用预训练的多层感知器（MLP）分析从LAMOST低分辨率光谱到DESI中分辨率光谱的转移，比较直接在光谱上训练的MLP与基于变换器模型的嵌入训练的MLP。研究结果表明，预训练于LAMOST LRS的MLP即使在没有微调的情况下也表现良好，适度的DESI光谱微调进一步提高了性能。此外，虽然变换器模型的嵌入在金属丰富的条件下改善了铁丰度的结果，但在金属贫乏的情况下表现不如直接在LRS上训练的MLP，这表明最佳微调策略因恒星参数而异。</div>
</details>
</div>
<div class="card">
<div class="title">Hunt Globally: Deep Research AI Agents for Drug Asset Scouting in Investing, Business Development, and Search &amp; Evaluation</div>
<div class="meta-line">Authors: Alisa Vinogradova, Vlad Vinogradov, Luba Greenwood, Ilya Yasny, Dmitry Kobyzev, Shoman Kasbekar, Kong Nguyen, Dmitrii Radkevich, Roman Doronin, Andrey Doronichev</div>
<div class="meta-line">First: 2026-02-16T18:57:49+00:00 · Latest: 2026-02-16T18:57:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15019v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15019v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests &gt;85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total; a growing share of scholarly output is also non-U.S. Industry estimates put China at ~30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing to surface &quot;under-the-radar&quot; assets creates multi-billion-dollar risk for investors and business development teams, making asset scouting a coverage-critical competition where speed and completeness drive value. Yet today&#x27;s Deep Research AI agents still lag human experts in achieving high-recall discovery across heterogeneous, multilingual sources without hallucinations.
  We propose a benchmarking methodology for drug asset scouting and a tuned, tree-based self-learning Bioptic Agent aimed at complete, non-hallucinated scouting. We construct a challenging completeness benchmark using a multilingual multi-agent pipeline: complex user queries paired with ground-truth assets that are largely outside U.S.-centric radar. To reflect real deal complexity, we collected screening queries from expert investors, BD, and VC professionals and used them as priors to conditionally generate benchmark queries. For grading, we use LLM-as-judge evaluation calibrated to expert opinions. We compare Bioptic Agent against Claude Opus 4.6, OpenAI GPT-5.2 Pro, Perplexity Deep Research, Gemini 3 Pro + Deep Research, and Exa Websets. Bioptic Agent achieves 79.7% F1 versus 56.2% (Claude Opus 4.6), 50.6% (Gemini 3 Pro + Deep Research), 46.6% (GPT-5.2 Pro), 44.2% (Perplexity Deep Research), and 26.9% (Exa Websets). Performance improves steeply with additional compute, supporting the view that more compute yields better results.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>全球猎寻：用于投资、业务发展和搜索与评估的药物资产侦察深度研究AI代理</div>
<div class="mono" style="margin-top:8px">生物制药创新已发生转变：许多新药资产现在源自美国以外，主要通过区域性非英语渠道披露。最近的数据表明，超过85%的专利申请源自美国以外，中国占全球总量的近一半；越来越多的学术成果也来自非美国。行业估计中国在全球药物开发中占约30%，涵盖1200多个新候选药物。在这个高风险环境中，未能发现“低调”的资产给投资者和业务发展团队带来了数十亿美元的风险，使资产侦察成为一个覆盖至关重要的竞争领域，速度和完整性驱动价值。然而，今天的深度研究AI代理在跨异构多语言来源实现高召回发现方面仍落后于人类专家。我们提出了一种药物资产侦察的基准方法论和一个调优的基于树的自学习Bioptic代理，旨在实现完整且无幻觉的侦察。我们使用多语言多代理管道构建了一个具有挑战性的完整性基准：复杂的用户查询与主要不在美国雷达范围内的真实资产配对。为了反映真实交易的复杂性，我们收集了来自专家投资者、业务发展和风险投资专业人士的筛选查询，并将其用作先验条件生成基准查询。对于评分，我们使用基于LLM的评估，经过专家意见的校准。我们将Bioptic代理与Claude Opus 4.6、OpenAI GPT-5.2 Pro、Perplexity Deep Research、Gemini 3 Pro + Deep Research和Exa Websets进行比较。Bioptic代理的F1得分为79.7%，而Claude Opus 4.6为56.2%，Gemini 3 Pro + Deep Research为50.6%，GPT-5.2 Pro为46.6%，Perplexity Deep Research为44.2%，Exa Websets为26.9%。随着计算能力的增加，性能显著提升，支持更多计算带来更好结果的观点。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is the increasing importance of identifying drug assets originating outside the U.S., particularly as over 85% of patent filings now come from international sources, with China being a significant contributor. The authors propose a benchmarking methodology and a self-learning Bioptic Agent designed to enhance the discovery of drug assets by utilizing a multilingual multi-agent pipeline that processes complex user queries. Experimental results show that the Bioptic Agent achieved an F1 score of 79.7%, significantly outperforming other AI models such as Claude Opus 4.6 and GPT-5.2 Pro, indicating that increased computational resources lead to improved performance in drug asset scouting.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于在快速发展的生物制药领域中有效进行药物资产侦查，因为大量新药资产主要来源于美国以外的地区。作者提出了一种基准方法，并引入了一种自学习的Bioptic Agent，旨在通过在多样化的多语言来源中实现高召回率来增强侦查能力。实验结果表明，Bioptic Agent的F1得分为79.7%，显著高于Claude Opus 4.6和GPT-5.2 Pro等竞争对手，表明其在识别对投资者和业务发展团队至关重要的“隐秘”资产方面的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Privileged Information Distillation for Language Models</div>
<div class="meta-line">Authors: Emiliano Penaloza, Dheeraj Vattikonda, Nicolas Gontier, Alexandre Lacoste, Laurent Charlin, Massimo Caccia</div>
<div class="meta-line">First: 2026-02-04T18:46:17+00:00 · Latest: 2026-02-16T18:57:38+00:00</div>
<div class="meta-line">Comments: Abstract border should have been purple</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04942v3">Abs</a> · <a href="https://arxiv.org/pdf/2602.04942v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, which typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable, but the reasoning process is not. For this, we introduce π-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically, we find that π-Distill and, in some cases, OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on π-Distill and characterizing when OPSD is competitive.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语言模型的特权信息蒸馏</div>
<div class="mono" style="margin-top:8px">训练时的特权信息（PI）可以使语言模型在本会失败的任务上取得成功，使其成为强化学习在困难、长时间范围设置中的强大工具。然而，将使用PI学习到的能力转移到在推理时必须不使用PI的策略上仍然是一个基本挑战。我们在多轮代理环境中蒸馏前沿模型的背景下研究这个问题，这些环境通常隐藏其内部推理，仅暴露行动轨迹。这打破了标准的蒸馏流程，因为成功的行为是可观察的，但推理过程却不可见。为此，我们引入了π-Distill，这是一种联合教师-学生目标，使用相同的模型同时训练一个条件于PI的教师和一个不条件的学生。此外，我们还引入了基于策略的自蒸馏（OPSD），这是一种使用强化学习（RL）训练的替代方法，学生与条件于PI的教师之间存在反向KL惩罚。我们展示了这两种算法有效地使用仅基于行动的PI蒸馏前沿代理。具体而言，我们发现π-Distill以及在某些情况下OPSD，优于行业标准实践（监督微调后进行RL），这些实践假设在多个代理基准、模型和PI形式中可以访问完整的思维链监督。我们通过广泛的分析补充了我们的结果，描述了使有效学习PI成为可能的因素，主要集中在π-Distill上，并描述了何时OPSD具有竞争力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenge of transferring capabilities learned from privileged information (PI) to language models that must operate without it during inference, particularly in complex multi-turn environments. The authors propose π-Distill, a joint teacher-student training method that utilizes a PI-conditioned teacher and an unconditioned student, alongside On-Policy Self-Distillation (OPSD), which employs Reinforcement Learning with a reverse KL-penalty. Experimental results demonstrate that both π-Distill and OPSD effectively distill frontier agents using action-only PI, outperforming traditional methods that rely on full Chain-of-Thought supervision across various benchmarks and models, with a detailed analysis of the factors contributing to effective learning with PI.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决将从特权信息（PI）中学习的能力转移到在推理时必须在没有这些信息的情况下操作的语言模型的挑战，特别是在多轮代理环境中。作者提出了两种方法：π-Distill，它采用联合教师-学生目标，同时训练一个基于PI的教师和一个无条件的学生，以及基于策略的自蒸馏（OPSD），它利用反向KL惩罚进行强化学习。实验结果表明，π-Distill和OPSD都能有效地使用仅基于动作的PI来蒸馏前沿代理，且在多个基准和模型上超越了依赖于完整思维链监督的标准实践。</div>
</details>
</div>
<div class="card">
<div class="title">Neurosim: A Fast Simulator for Neuromorphic Robot Perception</div>
<div class="meta-line">Authors: Richeek Das, Pratik Chaudhari</div>
<div class="meta-line">First: 2026-02-16T18:57:04+00:00 · Latest: 2026-02-16T18:57:04+00:00</div>
<div class="meta-line">Comments: 13 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15018v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15018v1">PDF</a> · <a href="https://github.com/grasp-lyrl/neurosim">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neurosim is a fast, real-time, high-performance library for simulating sensors such as dynamic vision sensors, RGB cameras, depth sensors, and inertial sensors. It can also simulate agile dynamics of multi-rotor vehicles in complex and dynamic environments. Neurosim can achieve frame rates as high as ~2700 FPS on a desktop GPU. Neurosim integrates with a ZeroMQ-based communication library called Cortex to facilitate seamless integration with machine learning and robotics workflows. Cortex provides a high-throughput, low-latency message-passing system for Python and C++ applications, with native support for NumPy arrays and PyTorch tensors. This paper discusses the design philosophy behind Neurosim and Cortex. It demonstrates how they can be used to (i) train neuromorphic perception and control algorithms, e.g., using self-supervised learning on time-synchronized multi-modal data, and (ii) test real-time implementations of these algorithms in closed-loop. Neurosim and Cortex are available at https://github.com/grasp-lyrl/neurosim .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Neurosim：一种快速的神经形态机器人感知模拟器</div>
<div class="mono" style="margin-top:8px">Neurosim 是一个快速、实时、高性能的库，用于模拟动态视觉传感器、RGB 摄像头、深度传感器和惯性传感器等传感器。它还可以模拟多旋翼飞行器在复杂和动态环境中的灵活动态。Neurosim 在桌面 GPU 上可以实现高达 ~2700 FPS 的帧率。Neurosim 与一个基于 ZeroMQ 的通信库 Cortex 集成，以便与机器学习和机器人工作流程无缝集成。Cortex 为 Python 和 C++ 应用提供高吞吐量、低延迟的消息传递系统，原生支持 NumPy 数组和 PyTorch 张量。本文讨论了 Neurosim 和 Cortex 背后的设计理念。它演示了如何使用它们来 (i) 训练神经形态感知和控制算法，例如，使用自监督学习对时间同步的多模态数据进行训练，以及 (ii) 在闭环中测试这些算法的实时实现。Neurosim 和 Cortex 可在 https://github.com/grasp-lyrl/neurosim 获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to create a high-performance simulator for neuromorphic robot perception that can handle various sensor types and dynamic environments. The main method involves the development of Neurosim, a library capable of simulating sensors and agile dynamics with frame rates up to approximately 2700 FPS, integrated with a communication library called Cortex for efficient data handling. Key experimental findings demonstrate that Neurosim and Cortex effectively facilitate the training of neuromorphic perception and control algorithms using self-supervised learning on synchronized multi-modal data, as well as enabling real-time testing of these algorithms in closed-loop scenarios.</div>
<div class="mono" style="margin-top:8px">本研究的动机是创建一个高性能的神经形态机器人感知模拟器，能够处理各种传感器类型和动态环境。作者开发了Neurosim，一个能够模拟动态视觉传感器和多旋翼飞行器动态的库，在桌面GPU上实现了高达约2700 FPS的帧率。关键实验结果表明，Neurosim与Cortex通信库结合，能够有效促进神经形态感知和控制算法的训练，使用自监督学习对同步的多模态数据进行处理，并允许实时测试这些算法的闭环系统。</div>
</details>
</div>
<div class="card">
<div class="title">Scaling Beyond Masked Diffusion Language Models</div>
<div class="meta-line">Authors: Subham Sekhar Sahoo, Jean-Marie Lemercier, Zhihan Yang, Justin Deschenaux, Jingyu Liu, John Thickstun, Ante Jukic</div>
<div class="meta-line">First: 2026-02-16T18:54:47+00:00 · Latest: 2026-02-16T18:54:47+00:00</div>
<div class="meta-line">Comments: code: https://github.com/s-sahoo/scaling-dllms</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15014v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15014v1">PDF</a> · <a href="https://github.com/s-sahoo/scaling-dllms">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a> · <a href="http://s-sahoo.github.io/scaling-dllms">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion language models are a promising alternative to autoregressive models due to their potential for faster generation. Among discrete diffusion approaches, Masked diffusion currently dominates, largely driven by strong perplexity on language modeling benchmarks. In this work, we present the first scaling law study of uniform-state and interpolating discrete diffusion methods. We also show that Masked diffusion models can be made approximately 12% more FLOPs-efficient when trained with a simple cross-entropy objective. We find that perplexity is informative within a diffusion family but can be misleading across families, where models with worse likelihood scaling may be preferable due to faster and more practical sampling, as reflected by the speed-quality Pareto frontier. These results challenge the view that Masked diffusion is categorically the future of diffusion language modeling and that perplexity alone suffices for cross-algorithm comparison. Scaling all methods to 1.7B parameters, we show that uniform-state diffusion remains competitive on likelihood-based benchmarks and outperforms autoregressive and Masked diffusion models on GSM8K, despite worse validation perplexity. We provide the code, model checkpoints, and video tutorials on the project page: http://s-sahoo.github.io/scaling-dllms</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超越掩码扩散语言模型的扩展</div>
<div class="mono" style="margin-top:8px">扩散语言模型由于其更快生成的潜力，是自回归模型的有前景的替代方案。在离散扩散方法中，掩码扩散目前占主导地位，主要是由于其在语言建模基准上的强困惑度。在这项工作中，我们首次研究了均匀状态和插值离散扩散方法的扩展规律。我们还表明，当使用简单的交叉熵目标进行训练时，掩码扩散模型的FLOPs效率可以提高约12%。我们发现，困惑度在扩散家族内是有信息的，但在不同家族之间可能会产生误导，其中可能由于更快和更实用的采样，具有较差似然扩展的模型可能更可取，这在速度-质量帕累托前沿中得到了反映。这些结果挑战了掩码扩散是扩散语言建模未来的绝对观点，以及仅凭困惑度就足以进行跨算法比较的看法。将所有方法扩展到17亿参数，我们表明均匀状态扩散在基于似然的基准上仍然具有竞争力，并且在GSM8K上超越了自回归和掩码扩散模型，尽管验证困惑度较差。我们在项目页面提供代码、模型检查点和视频教程：http://s-sahoo.github.io/scaling-dllms</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to explore the potential of diffusion language models as a faster alternative to autoregressive models, particularly focusing on the limitations of Masked diffusion. The authors conducted a scaling law study on uniform-state and interpolating discrete diffusion methods, revealing that Masked diffusion can achieve approximately 12% greater FLOPs efficiency when trained with a cross-entropy objective. The findings indicate that while perplexity is useful within diffusion families, it can be misleading across different families, suggesting that models with lower likelihood scaling may still be preferable for practical sampling, as demonstrated by the competitive performance of uniform-state diffusion against autoregressive and Masked diffusion models on the GSM8K benchmark despite higher validation perplexity.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于探讨扩散语言模型作为自回归模型更快替代方案的潜力，特别关注掩蔽扩散的局限性。作者对均匀状态和插值离散扩散方法进行了扩展法则研究，揭示了当使用交叉熵目标训练时，掩蔽扩散模型的FLOPs效率可以提高约12%。研究结果表明，尽管困惑度在扩散家族内是一个有用的指标，但在不同家族之间可能会产生误导，暗示具有较低似然扩展的模型在实际采样中可能更有效，均匀状态扩散在GSM8K等基准测试中表现出竞争力，尽管其验证困惑度较差，仍优于自回归和掩蔽扩散模型。</div>
</details>
</div>
<div class="card">
<div class="title">Cold-Start Personalization via Training-Free Priors from Structured World Models</div>
<div class="meta-line">Authors: Avinandan Bose, Shuyue Stella Li, Faeze Brahman, Pang Wei Koh, Simon Shaolei Du, Yulia Tsvetkov, Maryam Fazel, Lin Xiao, Asli Celikyilmaz</div>
<div class="meta-line">First: 2026-02-16T18:52:13+00:00 · Latest: 2026-02-16T18:52:13+00:00</div>
<div class="meta-line">Comments: 24 pages, 4 figures, 4 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15012v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15012v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cold-start personalization requires inferring user preferences through interaction when no user-specific historical data is available. The core challenge is a routing problem: each task admits dozens of preference dimensions, yet individual users care about only a few, and which ones matter depends on who is asking. With a limited question budget, asking without structure will miss the dimensions that matter. Reinforcement learning is the natural formulation, but in multi-turn settings its terminal reward fails to exploit the factored, per-criterion structure of preference data, and in practice learned policies collapse to static question sequences that ignore user responses. We propose decomposing cold-start elicitation into offline structure learning and online Bayesian inference. Pep (Preference Elicitation with Priors) learns a structured world model of preference correlations offline from complete profiles, then performs training-free Bayesian inference online to select informative questions and predict complete preference profiles, including dimensions never asked about. The framework is modular across downstream solvers and requires only simple belief models. Across medical, mathematical, social, and commonsense reasoning, Pep achieves 80.8% alignment between generated responses and users&#x27; stated preferences versus 68.5% for RL, with 3-5x fewer interactions. When two users give different answers to the same question, Pep changes its follow-up 39-62% of the time versus 0-28% for RL. It does so with ~10K parameters versus 8B for RL, showing that the bottleneck in cold-start elicitation is the capability to exploit the factored structure of preference data.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过结构化世界模型的无训练先验实现冷启动个性化</div>
<div class="mono" style="margin-top:8px">冷启动个性化需要在没有用户特定历史数据的情况下通过交互推断用户偏好。核心挑战是路由问题：每个任务有数十个偏好维度，但个别用户只关心其中少数，哪些维度重要取决于提问者。有限的问题预算下，缺乏结构的提问会遗漏重要维度。强化学习是自然的表述，但在多轮设置中，其终端奖励未能利用偏好数据的分解、按标准结构，且在实践中学习的策略会崩溃为忽视用户响应的静态问题序列。我们建议将冷启动引导分解为离线结构学习和在线贝叶斯推断。Pep（带先验的偏好引导）从完整的用户画像中离线学习偏好相关性的结构化世界模型，然后在线进行无训练的贝叶斯推断，以选择信息性问题并预测完整的偏好画像，包括从未询问的维度。该框架在下游求解器中是模块化的，仅需简单的信念模型。在医学、数学、社会和常识推理中，Pep生成的响应与用户陈述的偏好之间的对齐率为80.8%，而强化学习为68.5%，交互次数减少3-5倍。当两个用户对同一问题给出不同答案时，Pep在39-62%的情况下改变其后续问题，而强化学习为0-28%。Pep使用约1万参数，而强化学习为80亿，显示冷启动引导的瓶颈在于利用偏好数据的分解结构的能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenge of cold-start personalization, where user preferences must be inferred without historical data. The authors propose a method called Pep (Preference Elicitation with Priors), which decomposes the elicitation process into offline structure learning and online Bayesian inference, allowing for the selection of informative questions and the prediction of complete preference profiles. Experimental results demonstrate that Pep achieves an 80.8% alignment with users&#x27; stated preferences, significantly outperforming reinforcement learning (68.5%) while requiring 3-5 times fewer interactions and utilizing only ~10K parameters compared to 8B for RL.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决冷启动个性化的问题，即在没有历史数据的情况下推断用户偏好。作者提出了一种名为Pep（带先验的偏好引导）的方法，将问题分解为离线结构学习和在线贝叶斯推断，从而能够选择信息丰富的问题并预测完整的偏好轮廓。实验结果表明，Pep在生成的响应与用户陈述的偏好之间实现了80.8%的对齐，显著优于强化学习的68.5%，同时所需的交互次数减少了3-5倍，并且仅使用约10K个参数，而强化学习则需要8B个参数。</div>
</details>
</div>
<div class="card">
<div class="title">Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance</div>
<div class="meta-line">Authors: Lorenzo Tausani, Paolo Muratore, Morgan B. Talbot, Giacomo Amerio, Gabriel Kreiman, Davide Zoccolan</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2025-06-20T14:49:35+00:00 · Latest: 2026-02-16T18:51:59+00:00</div>
<div class="meta-line">Comments: 33 pages, 15 figures, Accepted as a conference paper at ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.17040v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.17040v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Uncovering which feature combinations are encoded by visual units is critical to understanding how images are transformed into representations that support recognition. While existing feature visualization approaches typically infer a unit&#x27;s most exciting images, this is insufficient to reveal the manifold of transformations under which responses remain invariant, which is critical to generalization in vision. Here we introduce Stretch-and-Squeeze (SnS), a model-agnostic, gradient-free framework to systematically characterize a unit&#x27;s maximally invariant stimuli, and its vulnerability to adversarial perturbations, in both biological and artificial visual systems. SnS frames these transformations as bi-objective optimization problems. To probe invariance, SnS seeks image perturbations that maximally alter (stretch) the representation of a reference stimulus in a given processing stage while preserving unit activation downstream (squeeze). To probe adversarial sensitivity, stretching and squeezing are reversed to maximally perturb unit activation while minimizing changes to the upstream representation. Applied to CNNs, SnS revealed invariant transformations that were farther from a reference image in pixel-space than those produced by affine transformations, while more strongly preserving the target unit&#x27;s response. The discovered invariant images differed depending on the stage of the image representation used for optimization: pixel-level changes primarily affected luminance and contrast, while stretching mid- and late-layer representations mainly altered texture and pose. By measuring how well the hierarchical invariant images obtained for L2 robust networks were classified by humans and other observer networks, we discovered a substantial drop in their interpretability when the representation was stretched in deep layers, while the opposite trend was found for standard models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超越显而易见的拉伸：一种无梯度框架揭示视觉不变性的隐藏景观</div>
<div class="mono" style="margin-top:8px">揭示视觉单元编码的特征组合对于理解图像如何转化为支持识别的表征至关重要。现有的特征可视化方法通常推断单元最激发的图像，但这不足以揭示响应保持不变的变换流形，这对视觉中的泛化至关重要。在此，我们介绍了拉伸与挤压（SnS），一种模型无关的无梯度框架，系统性地表征单元的最大不变刺激及其对对抗扰动的脆弱性，适用于生物和人工视觉系统。SnS将这些变换框架化为双目标优化问题。为了探测不变性，SnS寻求最大程度改变（拉伸）给定处理阶段中参考刺激的表征，同时保持下游单元激活（挤压）。为了探测对抗敏感性，拉伸和挤压被反转，以最大程度扰动单元激活，同时最小化对上游表征的变化。应用于卷积神经网络（CNN），SnS揭示的无变换在像素空间中距离参考图像更远，而更强地保持目标单元的响应。发现的无变换图像因用于优化的图像表征阶段而异：像素级变化主要影响亮度和对比度，而拉伸中层和后层表征主要改变纹理和姿态。通过测量人类和其他观察网络对L2鲁棒网络获得的层次不变图像的分类效果，我们发现当深层表征被拉伸时，其可解释性显著下降，而标准模型则发现相反的趋势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to better understand how visual units encode feature combinations and to reveal the transformations that maintain response invariance, which is essential for visual recognition. The authors introduce a gradient-free framework called Stretch-and-Squeeze (SnS) that characterizes a unit&#x27;s maximally invariant stimuli and its susceptibility to adversarial perturbations by framing these transformations as bi-objective optimization problems. The key findings indicate that SnS can identify invariant transformations that are more distant from reference images in pixel-space than traditional affine transformations, with varying effects on luminance, contrast, texture, and pose depending on the image representation stage, and it also highlights a significant decrease in interpretability of hierarchical invariant images when deep layer representations are stretched compared to standard models.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于更好地理解视觉单元编码的特征组合，这对于识别图像如何转化为支持识别的表示至关重要。作者提出了一种名为Stretch-and-Squeeze（SnS）的模型无关、无梯度框架，以系统地表征单元的最大不变刺激及其对对抗扰动的脆弱性。关键发现表明，SnS能够识别出在像素空间中距离参考图像更远的不变变换，相较于仿射变换，更有效地保持目标单元的响应。此外，研究还揭示了不变图像的性质随着图像表示阶段的不同而变化，影响亮度、对比度、纹理和姿态等方面，并强调了在鲁棒网络中深层表示的可解释性显著下降，而标准模型则呈现相反趋势。</div>
</details>
</div>
<div class="card">
<div class="title">BPP: Long-Context Robot Imitation Learning by Focusing on Key History Frames</div>
<div class="meta-line">Authors: Max Sobol Mark, Jacky Liang, Maria Attarian, Chuyuan Fu, Debidatta Dwibedi, Dhruv Shah, Aviral Kumar</div>
<div class="meta-line">First: 2026-02-16T18:49:56+00:00 · Latest: 2026-02-16T18:49:56+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15010v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15010v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Many robot tasks require attending to the history of past observations. For example, finding an item in a room requires remembering which places have already been searched. However, the best-performing robot policies typically condition only on the current observation, limiting their applicability to such tasks. Naively conditioning on past observations often fails due to spurious correlations: policies latch onto incidental features of training histories that do not generalize to out-of-distribution trajectories upon deployment. We analyze why policies latch onto these spurious correlations and find that this problem stems from limited coverage over the space of possible histories during training, which grows exponentially with horizon. Existing regularization techniques provide inconsistent benefits across tasks, as they do not fundamentally address this coverage problem. Motivated by these findings, we propose Big Picture Policies (BPP), an approach that conditions on a minimal set of meaningful keyframes detected by a vision-language model. By projecting diverse rollouts onto a compact set of task-relevant events, BPP substantially reduces distribution shift between training and deployment, without sacrificing expressivity. We evaluate BPP on four challenging real-world manipulation tasks and three simulation tasks, all requiring history conditioning. BPP achieves 70% higher success rates than the best comparison on real-world evaluations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BPP：通过关注关键历史帧实现长上下文机器人模仿学习</div>
<div class="mono" style="margin-top:8px">许多机器人任务需要关注过去观察的历史。例如，在房间中寻找物品需要记住哪些地方已经被搜索过。然而，表现最佳的机器人策略通常仅基于当前观察进行条件限制，这限制了它们在此类任务中的适用性。简单地依赖过去的观察往往由于虚假相关性而失败：策略依赖于训练历史中的偶然特征，这些特征在部署时无法推广到分布外轨迹。我们分析了为什么策略会依赖这些虚假相关性，发现这个问题源于训练期间对可能历史空间的覆盖有限，而这一覆盖随着时间范围的增加呈指数增长。现有的正则化技术在任务间提供不一致的好处，因为它们并未从根本上解决这一覆盖问题。基于这些发现，我们提出了大视野策略（BPP），这是一种基于视觉-语言模型检测到的最小有意义关键帧集进行条件限制的方法。通过将多样化的回放投影到一组紧凑的任务相关事件上，BPP显著减少了训练和部署之间的分布偏移，而不牺牲表达能力。我们在四个具有挑战性的真实世界操作任务和三个模拟任务上评估BPP，这些任务都需要历史条件。BPP在真实世界评估中实现了比最佳对比方法高70%的成功率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of robot tasks that require the retention of historical observations, as traditional policies often rely solely on current observations, leading to poor generalization. The authors introduce Big Picture Policies (BPP), which utilize a vision-language model to identify keyframes that represent significant historical events, thereby improving the conditioning on relevant past observations. Experimental results demonstrate that BPP achieves a 70% higher success rate compared to the best existing methods across four real-world manipulation tasks and three simulation tasks that necessitate history conditioning.</div>
<div class="mono" style="margin-top:8px">本研究解决了机器人任务中需要记住过去观察的问题，因为传统策略通常仅依赖当前观察，导致泛化能力差。作者提出了大视野策略（BPP），利用视觉-语言模型对一组关键帧进行条件化，从而减少训练和部署之间的分布偏移。实验结果表明，BPP在四个真实世界操作任务和三个需要历史条件的仿真任务中，相较于现有最佳方法成功率提高了70%。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient Sampling with Discrete Diffusion Models: Sharp and Adaptive Guarantees</div>
<div class="meta-line">Authors: Daniil Dmitriev, Zhihan Huang, Yuting Wei</div>
<div class="meta-line">First: 2026-02-16T18:48:17+00:00 · Latest: 2026-02-16T18:48:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15008v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15008v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion models over discrete spaces have recently shown striking empirical success, yet their theoretical foundations remain incomplete. In this paper, we study the sampling efficiency of score-based discrete diffusion models under a continuous-time Markov chain (CTMC) formulation, with a focus on $τ$-leaping-based samplers. We establish sharp convergence guarantees for attaining $\varepsilon$ accuracy in Kullback-Leibler (KL) divergence for both uniform and masking noising processes. For uniform discrete diffusion, we show that the $τ$-leaping algorithm achieves an iteration complexity of order $\tilde O(d/\varepsilon)$, with $d$ the ambient dimension of the target distribution, eliminating linear dependence on the vocabulary size $S$ and improving existing bounds by a factor of $d$; moreover, we establish a matching algorithmic lower bound showing that linear dependence on the ambient dimension is unavoidable in general. For masking discrete diffusion, we introduce a modified $τ$-leaping sampler whose convergence rate is governed by an intrinsic information-theoretic quantity, termed the effective total correlation, which is bounded by $d \log S$ but can be sublinear or even constant for structured data. As a consequence, the sampler provably adapts to low-dimensional structure without prior knowledge or algorithmic modification, yielding sublinear convergence rates for various practical examples (such as hidden Markov models, image data, and random graphs). Our analysis requires no boundedness or smoothness assumptions on the score estimator beyond control of the score entropy loss.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于离散扩散模型的高效采样：精确和自适应保证</div>
<div class="mono" style="margin-top:8px">离散空间上的扩散模型最近显示出显著的经验成功，但其理论基础仍不完整。本文研究了基于分数的离散扩散模型在连续时间马尔可夫链（CTMC）框架下的采样效率，重点关注$τ$-跳跃采样器。我们建立了在Kullback-Leibler（KL）散度中达到$\varepsilon$精度的精确收敛保证，适用于均匀和掩蔽噪声过程。对于均匀离散扩散，我们证明$τ$-跳跃算法的迭代复杂度为$\tilde O(d/\varepsilon)$，其中$d$是目标分布的环境维度，消除了对词汇大小$S$的线性依赖，并将现有界限提高了$d$倍；此外，我们建立了一个匹配的算法下界，表明在一般情况下，线性依赖于环境维度是不可避免的。对于掩蔽离散扩散，我们引入了一种修改后的$τ$-跳跃采样器，其收敛速率由一个内在的信息论量控制，称为有效总相关，该量被$d \log S$所限制，但对于结构化数据可以是亚线性甚至常数。因此，该采样器在没有先验知识或算法修改的情况下，证明能够适应低维结构，为各种实际例子（如隐马尔可夫模型、图像数据和随机图）提供亚线性收敛速率。我们的分析不需要对分数估计器的有界性或光滑性假设，超出了对分数熵损失的控制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to address the incomplete theoretical foundations of discrete diffusion models, which have shown empirical success. The authors investigate the sampling efficiency of score-based discrete diffusion models using a continuous-time Markov chain framework, focusing on $τ$-leaping-based samplers. They establish sharp convergence guarantees for achieving $\varepsilon$ accuracy in Kullback-Leibler divergence, demonstrating that the $τ$-leaping algorithm for uniform discrete diffusion achieves an iteration complexity of $\tilde O(d/\varepsilon)$, improving existing bounds and showing that linear dependence on the ambient dimension is unavoidable. For masking discrete diffusion, a modified $τ$-leaping sampler is introduced, which adapts to low-dimensional structures and yields sublinear convergence rates for various practical applications without prior knowledge or modifications.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决离散扩散模型的理论基础不完整的问题，这些模型在经验上表现出显著的成功。作者采用连续时间马尔可夫链（CTMC）框架分析基于得分的离散扩散模型的采样效率，特别关注$τ$-跳跃采样器。他们建立了在Kullback-Leibler散度中实现$\varepsilon$精度的尖锐收敛保证，证明了均匀离散扩散的$τ$-跳跃算法的迭代复杂度为$\tilde O(d/\varepsilon)$，改善了现有界限，并通过修改的采样器展示了在掩蔽离散扩散中的适应性，该采样器在没有先验知识的情况下对结构化数据实现了亚线性收敛速率。</div>
</details>
</div>
<div class="card">
<div class="title">Learning Rate Annealing Improves Tuning Robustness in Stochastic Optimization</div>
<div class="meta-line">Authors: Amit Attia, Tomer Koren</div>
<div class="meta-line">First: 2025-03-12T14:06:34+00:00 · Latest: 2026-02-16T18:47:51+00:00</div>
<div class="meta-line">Comments: 23 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.09411v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.09411v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The learning rate in stochastic gradient methods is a critical hyperparameter that is notoriously costly to tune via standard grid search, especially for training modern large-scale models with billions of parameters. We identify a theoretical advantage of learning rate annealing schemes that decay the learning rate to zero at a polynomial rate, such as the widely-used cosine schedule, by demonstrating their increased robustness to initial parameter misspecification due to a coarse grid search. We present an analysis in a stochastic convex optimization setup demonstrating that the convergence rate of stochastic gradient descent with annealed schedules depends sublinearly on the multiplicative misspecification factor $ρ$ (i.e., the grid resolution), achieving a rate of $O(ρ^{1/(2p+1)}/\sqrt{T})$ where $p$ is the degree of polynomial decay and $T$ is the number of steps. This is in contrast to the $O(ρ/\sqrt{T})$ rate obtained under the inverse-square-root and fixed stepsize schedules, which depend linearly on $ρ$. Experiments confirm the increased robustness compared to tuning with a fixed stepsize, that has significant implications for the computational overhead of hyperparameter search in practical training scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>学习率退火提高随机优化中的调优鲁棒性</div>
<div class="mono" style="margin-top:8px">随机梯度方法中的学习率是一个关键的超参数，通过标准网格搜索进行调优成本高昂，尤其是在训练具有数十亿参数的现代大规模模型时。我们识别出学习率退火方案的理论优势，这些方案以多项式速率将学习率衰减至零，例如广泛使用的余弦调度，证明了它们对初始参数错误指定的鲁棒性增强，这是由于粗糙的网格搜索。我们在随机凸优化设置中进行分析，表明使用退火调度的随机梯度下降的收敛速率在次线性上依赖于乘法错误指定因子 $ρ$（即网格分辨率），实现了 $O(ρ^{1/(2p+1)}/\sqrt{T})$ 的速率，其中 $p$ 是多项式衰减的度数，$T$ 是步骤数。这与在反平方根和固定步长调度下获得的 $O(ρ/\sqrt{T})$ 速率形成对比，后者在线性上依赖于 $ρ$。实验确认了与固定步长调优相比的鲁棒性增强，这对实际训练场景中的超参数搜索的计算开销具有重要影响。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is the challenge of tuning the learning rate in stochastic gradient methods, which is particularly difficult for large-scale models. The authors propose a method involving learning rate annealing, specifically using polynomial decay schedules like the cosine schedule, to enhance robustness against initial parameter misspecification. Their analysis shows that the convergence rate of stochastic gradient descent with these annealed schedules improves to a sublinear dependence on the misspecification factor, achieving a rate of O(ρ^{1/(2p+1)}/√T), compared to the linear dependence observed with fixed stepsize schedules, and experiments validate the method&#x27;s effectiveness in reducing hyperparameter tuning overhead in practical scenarios.</div>
<div class="mono" style="margin-top:8px">本研究解决了随机梯度方法中学习率调优的挑战，尤其是在大规模模型中尤为困难。作者提出使用学习率退火方案，以多项式速率将学习率降低到零，例如余弦调度，并分析其在随机凸优化背景下的理论优势。实验结果表明，与固定步长方法相比，这些退火调度在初始参数错误指定时的收敛速率更不敏感，表明其提高了鲁棒性并减少了模型训练过程中超参数调优的计算开销。</div>
</details>
</div>
<div class="card">
<div class="title">Distributed Quantum Gaussian Processes for Multi-Agent Systems</div>
<div class="meta-line">Authors: Meet Gandhi, George P. Kontoudis</div>
<div class="meta-line">Venue: 2026 International Conference on Autonomous Agents and Multiagent Systems</div>
<div class="meta-line">First: 2026-02-16T18:46:23+00:00 · Latest: 2026-02-16T18:46:23+00:00</div>
<div class="meta-line">Comments: 9 pages, 4 figures, accepted at AAMAS 2026 (International Conference on Autonomous Agents and Multiagent Systems)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15006v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15006v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Gaussian Processes (GPs) are a powerful tool for probabilistic modeling, but their performance is often constrained in complex, largescale real-world domains due to the limited expressivity of classical kernels. Quantum computing offers the potential to overcome this limitation by embedding data into exponentially large Hilbert spaces, capturing complex correlations that remain inaccessible to classical computing approaches. In this paper, we propose a Distributed Quantum Gaussian Process (DQGP) method in a multiagent setting to enhance modeling capabilities and scalability. To address the challenging non-Euclidean optimization problem, we develop a Distributed consensus Riemannian Alternating Direction Method of Multipliers (DR-ADMM) algorithm that aggregates local agent models into a global model. We evaluate the efficacy of our method through numerical experiments conducted on a quantum simulator in classical hardware. We use real-world, non-stationary elevation datasets of NASA&#x27;s Shuttle Radar Topography Mission and synthetic datasets generated by Quantum Gaussian Processes. Beyond modeling advantages, our framework highlights potential computational speedups that quantum hardware may provide, particularly in Gaussian processes and distributed optimization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多智能体系统的分布式量子高斯过程</div>
<div class="mono" style="margin-top:8px">高斯过程（GP）是概率建模的强大工具，但由于经典核的表达能力有限，其在复杂的大规模现实领域中的性能常常受到限制。量子计算提供了克服这一限制的潜力，通过将数据嵌入到指数级大的希尔伯特空间中，捕捉经典计算方法无法获取的复杂相关性。本文提出了一种在多智能体环境中增强建模能力和可扩展性的分布式量子高斯过程（DQGP）方法。为了解决具有挑战性的非欧几里得优化问题，我们开发了一种分布式共识黎曼交替方向乘子法（DR-ADMM）算法，将局部智能体模型聚合为全局模型。我们通过在经典硬件上的量子模拟器进行的数值实验评估了我们方法的有效性。我们使用了NASA的航天飞机雷达地形测量任务的真实非平稳高程数据集和由量子高斯过程生成的合成数据集。除了建模优势外，我们的框架还突出了量子硬件可能提供的计算加速，特别是在高斯过程和分布式优化中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitations of classical Gaussian Processes in modeling complex, large-scale real-world data due to the restricted expressivity of classical kernels. The authors propose a Distributed Quantum Gaussian Process (DQGP) method tailored for multi-agent systems, utilizing a Distributed consensus Riemannian Alternating Direction Method of Multipliers (DR-ADMM) algorithm to optimize the aggregation of local models into a global model. Experimental results demonstrate the effectiveness of the DQGP method using numerical simulations on a quantum simulator, showing improved modeling capabilities with real-world elevation data and highlighting potential computational advantages of quantum hardware in Gaussian processes and distributed optimization.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高高斯过程（GPs）在复杂的大规模现实应用中的性能，而经典核函数往往无法满足这一需求。作者提出了一种针对多智能体系统的分布式量子高斯过程（DQGP）方法，利用分布式共识黎曼交替方向乘法器（DR-ADMM）算法来优化将局部模型聚合为全局模型的过程。实验结果通过在量子模拟器上进行的数值模拟展示了DQGP方法的有效性，使用了NASA的真实地形数据集和合成数据集，揭示了在高斯过程和分布式优化中，量子硬件可能带来的显著建模改进和计算加速。</div>
</details>
</div>
<div class="card">
<div class="title">PDE foundation models are skillful AI weather emulators for the Martian atmosphere</div>
<div class="meta-line">Authors: Johannes Schmude, Sujit Roy, Liping Wang, Theodore van Kessel, Levente Klein, Marcus Freitag, Eloisa Bentivegna, Robert Manson-Sawko, Bjorn Lutjens, Manil Maskey, Campbell Watson, Rahul Ramachandran, Juan Bernabe-Moreno</div>
<div class="meta-line">First: 2026-02-16T18:44:46+00:00 · Latest: 2026-02-16T18:44:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15004v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15004v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We show that AI foundation models that are pretrained on numerical solutions to a diverse corpus of partial differential equations can be adapted and fine-tuned to obtain skillful predictive weather emulators for the Martian atmosphere. We base our work on the Poseidon PDE foundation model for two-dimensional systems. We develop a method to extend Poseidon from two to three dimensions while keeping the pretraining information. Moreover, we investigate the performance of the model in the presence of sparse initial conditions. Our results make use of four Martian years (approx.~34 GB) of training data and a median compute budget of 13 GPU hours. We find that the combination of pretraining and model extension yields a performance increase of 34.4\% on a held-out year. This shows that PDEs-FMs can not only approximate solutions to (other) PDEs but also anchor models for real-world problems with complex interactions that lack a sufficient amount of training data or a suitable compute budget.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>偏微分方程基础模型是火星大气的高效人工智能天气模拟器</div>
<div class="mono" style="margin-top:8px">我们展示了在多样的偏微分方程数值解上预训练的人工智能基础模型可以被调整和微调，以获得火星大气的高效预测天气模拟器。我们的工作基于二维系统的Poseidon PDE基础模型。我们开发了一种方法，将Poseidon从二维扩展到三维，同时保留预训练信息。此外，我们研究了模型在稀疏初始条件下的表现。我们的结果使用了四个火星年（约34 GB）的训练数据和中位计算预算为13 GPU小时。我们发现，预训练和模型扩展的结合在保留年份上提高了34.4%的性能。这表明，PDEs-FMs不仅可以近似（其他）PDE的解，还可以为缺乏足够训练数据或合适计算预算的复杂交互的现实问题提供模型支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for effective weather prediction models for the Martian atmosphere, leveraging AI foundation models pretrained on numerical solutions to partial differential equations (PDEs). The authors adapt the Poseidon PDE foundation model, originally designed for two-dimensional systems, to three dimensions while retaining pretraining information. Experimental results demonstrate a 34.4% performance improvement on a held-out year using approximately 34 GB of training data from four Martian years and a median compute budget of 13 GPU hours, indicating that PDE foundation models can effectively address real-world problems with complex interactions and limited training data.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于利用人工智能基础模型有效模拟火星大气的天气。作者将最初为二维系统设计的Poseidon PDE基础模型进行适应和微调，扩展到三维，同时保留预训练信息。实验结果表明，使用四个火星年的训练数据和中位计算预算为13个GPU小时的情况下，模型在保留年份上的性能提高了34.4%，这表明PDE基础模型能够有效解决具有复杂交互和有限训练数据的现实问题。</div>
</details>
</div>
<div class="card">
<div class="title">Boundary Point Jailbreaking of Black-Box LLMs</div>
<div class="meta-line">Authors: Xander Davies, Giorgi Giglemiani, Edmund Lau, Eric Winsor, Geoffrey Irving, Yarin Gal</div>
<div class="meta-line">First: 2026-02-16T18:29:09+00:00 · Latest: 2026-02-16T18:29:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15001v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.15001v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier LLMs are safeguarded against attempts to extract harmful information via adversarial prompts known as &quot;jailbreaks&quot;. Recently, defenders have developed classifier-based systems that have survived thousands of hours of human red teaming. We introduce Boundary Point Jailbreaking (BPJ), a new class of automated jailbreak attacks that evade the strongest industry-deployed safeguards. Unlike previous attacks that rely on white/grey-box assumptions (such as classifier scores or gradients) or libraries of existing jailbreaks, BPJ is fully black-box and uses only a single bit of information per query: whether or not the classifier flags the interaction. To achieve this, BPJ addresses the core difficulty in optimising attacks against robust real-world defences: evaluating whether a proposed modification to an attack is an improvement. Instead of directly trying to learn an attack for a target harmful string, BPJ converts the string into a curriculum of intermediate attack targets and then actively selects evaluation points that best detect small changes in attack strength (&quot;boundary points&quot;). We believe BPJ is the first fully automated attack algorithm that succeeds in developing universal jailbreaks against Constitutional Classifiers, as well as the first automated attack algorithm that succeeds against GPT-5&#x27;s input classifier without relying on human attack seeds. BPJ is difficult to defend against in individual interactions but incurs many flags during optimisation, suggesting that effective defence requires supplementing single-interaction methods with batch-level monitoring.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>黑箱大语言模型的边界点越狱</div>
<div class="mono" style="margin-top:8px">前沿的大语言模型通过对抗性提示（称为“越狱”）来防止提取有害信息的尝试。最近，防御者开发了基于分类器的系统，经过数千小时的人类红队测试仍然有效。我们介绍了边界点越狱（BPJ），这是一种新的自动化越狱攻击类别，可以规避最强的行业部署的防护。与依赖于白盒/灰盒假设（如分类器分数或梯度）或现有越狱库的先前攻击不同，BPJ 完全是黑箱的，每个查询仅使用一位信息：分类器是否标记了该交互。为此，BPJ 解决了针对强大现实世界防御优化攻击的核心难题：评估对攻击的提议修改是否是改进。BPJ 不直接尝试为目标有害字符串学习攻击，而是将字符串转换为中间攻击目标的课程，然后主动选择最佳检测攻击强度小变化的评估点（“边界点”）。我们相信，BPJ 是第一个成功开发针对宪法分类器的通用越狱的完全自动化攻击算法，也是第一个在不依赖人类攻击种子的情况下成功对抗 GPT-5 输入分类器的自动化攻击算法。BPJ 在单次交互中难以防御，但在优化过程中会产生许多标记，这表明有效防御需要将单次交互方法与批量级监控相结合。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the vulnerabilities of frontier large language models (LLMs) against adversarial prompts known as jailbreaks, which aim to extract harmful information. The authors introduce Boundary Point Jailbreaking (BPJ), a novel automated attack method that operates in a fully black-box manner, relying solely on whether the classifier flags the interaction, without needing prior knowledge of the system. The key findings indicate that BPJ successfully develops universal jailbreaks against Constitutional Classifiers and is the first automated attack to bypass GPT-5&#x27;s input classifier without human-generated attack seeds, highlighting the need for enhanced defense mechanisms that go beyond single-interaction methods to include batch-level monitoring due to the high number of flags generated during optimization.</div>
<div class="mono" style="margin-top:8px">本研究的动机是开发有效的自动化越狱攻击，以对抗前沿大型语言模型（LLM）中设计用来防止提取有害信息的强大保护措施。作者提出了边界点越狱（BPJ），这是一种新颖的黑箱攻击方法，仅利用分类器反馈中的最少信息来优化攻击策略。关键实验结果表明，BPJ成功创建了针对宪法分类器的通用越狱，并且能够在没有人工干预的情况下绕过GPT-5的输入分类器，这突显了由于该攻击在优化过程中倾向于触发多个标志，因此需要增强防御机制以纳入批量监控。</div>
</details>
</div>
<div class="card">
<div class="title">Spectral Convolution on Orbifolds for Geometric Deep Learning</div>
<div class="meta-line">Authors: Tim Mangliers, Bernhard Mössner, Benjamin Himpel</div>
<div class="meta-line">First: 2026-02-16T18:28:38+00:00 · Latest: 2026-02-16T18:28:38+00:00</div>
<div class="meta-line">Comments: 17 pages, 5 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14997v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14997v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Geometric deep learning (GDL) deals with supervised learning on data domains that go beyond Euclidean structure, such as data with graph or manifold structure. Due to the demand that arises from application-related data, there is a need to identify further topological and geometric structures with which these use cases can be made accessible to machine learning. There are various techniques, such as spectral convolution, that form the basic building blocks for some convolutional neural network-like architectures on non-Euclidean data. In this paper, the concept of spectral convolution on orbifolds is introduced. This provides a building block for making learning on orbifold structured data accessible using GDL. The theory discussed is illustrated using an example from music theory.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>几何深度学习中的 orbifold 谱卷积</div>
<div class="mono" style="margin-top:8px">几何深度学习（GDL）处理超越欧几里得结构的数据域上的监督学习，例如具有图或流形结构的数据。由于应用相关数据带来的需求，需要识别进一步的拓扑和几何结构，以使这些用例能够被机器学习所利用。有多种技术，例如谱卷积，构成了一些类似卷积神经网络架构在非欧几里得数据上的基本构建块。本文介绍了在 orbifold 上的谱卷积概念。这为使用 GDL 使 orbifold 结构数据的学习变得可访问提供了一个构建块。讨论的理论通过音乐理论中的一个例子进行了说明。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance geometric deep learning (GDL) by addressing the need for effective learning methods on non-Euclidean data structures, such as those found in various applications. The authors introduce the concept of spectral convolution on orbifolds as a novel approach to facilitate learning on orbifold-structured data. Key experimental findings demonstrate that this method serves as a foundational building block for convolutional neural network-like architectures, with practical implications illustrated through an example from music theory.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于通过解决机器学习技术处理复杂拓扑和几何结构（如 orbifold 数据）的需求，来增强几何深度学习（GDL）。作者提出了专为 orbifold 设计的谱卷积概念，作为开发适用于非欧几里得数据的卷积神经网络架构的基础元素。实验结果通过音乐理论的示例展示了该方法的有效性，表明谱卷积能够促进对 orbifold 结构数据的学习。</div>
</details>
</div>
<div class="card">
<div class="title">Robust Generalization with Adaptive Optimal Transport Priors for Decision-Focused Learning</div>
<div class="meta-line">Authors: Haixiang Sun, Andrew L. Liu</div>
<div class="meta-line">Venue: The 29th International Conference on Artificial Intelligence and Statistics (AISTATS), 2026</div>
<div class="meta-line">First: 2026-02-01T20:22:41+00:00 · Latest: 2026-02-16T18:27:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01427v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.01427v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Few-shot learning requires models to generalize under limited supervision while remaining robust to distribution shifts. Existing Sinkhorn Distributionally Robust Optimization (DRO) methods provide theoretical guarantees but rely on a fixed reference distribution, which limits their adaptability. We propose a Prototype-Guided Distributionally Robust Optimization (PG-DRO) framework that learns class-adaptive priors from abundant base data via hierarchical optimal transport and embeds them into the Sinkhorn DRO formulation. This design enables few-shot information to be organically integrated into producing class-specific robust decisions that are both theoretically grounded and efficient, and further aligns the uncertainty set with transferable structural knowledge. Experiments show that PG-DRO achieves stronger robust generalization in few-shot scenarios, outperforming both standard learners and DRO baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于自适应最优传输先验的决策导向学习的鲁棒泛化</div>
<div class="mono" style="margin-top:8px">少样本学习要求模型在有限监督下进行泛化，同时对分布变化保持鲁棒性。现有的Sinkhorn分布鲁棒优化（DRO）方法提供了理论保证，但依赖于固定的参考分布，限制了其适应性。我们提出了一种原型引导的分布鲁棒优化（PG-DRO）框架，通过层次最优传输从丰富的基础数据中学习类自适应先验，并将其嵌入Sinkhorn DRO公式中。这一设计使得少样本信息能够有机地整合到产生理论基础和高效的类特定鲁棒决策中，并进一步将不确定性集与可转移的结构知识对齐。实验表明，PG-DRO在少样本场景中实现了更强的鲁棒泛化，超越了标准学习者和DRO基线。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance few-shot learning by improving model generalization under limited supervision and robustness to distribution shifts. The authors introduce a Prototype-Guided Distributionally Robust Optimization (PG-DRO) framework that learns class-adaptive priors from abundant base data using hierarchical optimal transport, integrating these priors into the Sinkhorn DRO formulation. Experimental results demonstrate that PG-DRO significantly improves robust generalization in few-shot learning scenarios, outperforming both standard learners and existing DRO methods.</div>
<div class="mono" style="margin-top:8px">本研究解决了少样本学习的挑战，该领域要求模型在有限监督下有效泛化，同时对分布变化具有鲁棒性。作者提出了一种原型引导的分布鲁棒优化（PG-DRO）框架，该框架通过层次最优传输从丰富的基础数据中学习类别自适应先验，并将这些先验整合到Sinkhorn DRO公式中。实验结果表明，PG-DRO在少样本学习场景中显著增强了鲁棒泛化能力，优于标准学习方法和现有的DRO基线。</div>
</details>
</div>
<div class="card">
<div class="title">On the Semantics of Primary Cause in Hybrid Dynamic Domains</div>
<div class="meta-line">Authors: Shakil M. Khan, Asim Mehmood, Sandra Zilles</div>
<div class="meta-line">First: 2026-02-16T18:25:08+00:00 · Latest: 2026-02-16T18:25:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14994v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14994v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reasoning about actual causes of observed effects is fundamental to the study of rationality. This important problem has been studied since the time of Aristotle, with formal mathematical accounts emerging recently. We live in a world where change due to actions can be both discrete and continuous, that is, hybrid. Yet, despite extensive research on actual causation, only few recent studies looked into causation with continuous change. Building on recent progress, in this paper we propose two definitions of primary cause in a hybrid action-theoretic framework, namely the hybrid temporal situation calculus. One of these is foundational in nature while the other formalizes causation through contributions, which can then be verified from a counterfactual perspective using a modified ``but-for&#x27;&#x27; test. We prove that these two definitions are indeed equivalent. We then show that our definitions of causation have some intuitively justifiable properties.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>混合动态领域中主要原因的语义</div>
<div class="mono" style="margin-top:8px">推理观察到的效果的实际原因是理性研究的基础。这个重要问题自亚里士多德时代以来就一直在研究，最近出现了正式的数学论述。我们生活在一个由于行动而导致的变化可以是离散和连续的世界，即混合的。然而，尽管对实际因果关系进行了广泛研究，只有少数最近的研究关注连续变化下的因果关系。基于最近的进展，本文在混合行动理论框架下提出了主要原因的两个定义，即混合时间情境演算。其中一个是基础性的，而另一个通过贡献形式化因果关系，然后可以通过修改的“但为”测试从反事实的角度进行验证。我们证明这两个定义确实是等价的。然后我们展示了我们对因果关系的定义具有一些直观上合理的属性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the understanding of actual causes in hybrid dynamic domains, where changes can be both discrete and continuous. The authors propose two definitions of primary cause within a hybrid action-theoretic framework, specifically the hybrid temporal situation calculus, with one definition being foundational and the other formalizing causation through contributions that can be verified using a modified &#x27;but-for&#x27; test. The key experimental findings demonstrate that these two definitions are equivalent and exhibit intuitively justifiable properties.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于增强对混合动态领域中实际原因的理解，这一领域在连续变化方面的探索相对有限。作者在混合行动理论框架下提出了两种主要原因的定义，具体为混合时间情境演算，其中一种是基础性的，另一种通过贡献形式化因果关系，并通过修改后的“但为”测试进行验证。主要实验结果表明，这两种定义是等价的，并具有直观上合理的属性。</div>
</details>
</div>
<div class="card">
<div class="title">ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery</div>
<div class="meta-line">Authors: Ayush Shrivastava, Kirtan Gangani, Laksh Jain, Mayank Goel, Nipun Batra</div>
<div class="meta-line">First: 2026-02-16T18:16:19+00:00 · Latest: 2026-02-16T18:16:19+00:00</div>
<div class="meta-line">Comments: 8 Pages with 2 figures of main content. 2 pages of References. 10 pages of appendix with 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14989v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14989v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision language models (VLMs) achieve strong performance on RGB imagery, but they do not generalize to thermal images. Thermal sensing plays a critical role in settings where visible light fails, including nighttime surveillance, search and rescue, autonomous driving, and medical screening. Unlike RGB imagery, thermal images encode physical temperature rather than color or texture, requiring perceptual and reasoning capabilities that existing RGB-centric benchmarks do not evaluate. We introduce ThermEval-B, a structured benchmark of approximately 55,000 thermal visual question answering pairs designed to assess the foundational primitives required for thermal vision language understanding. ThermEval-B integrates public datasets with our newly collected ThermEval-D, the first dataset to provide dense per-pixel temperature maps with semantic body-part annotations across diverse indoor and outdoor environments. Evaluating 25 open-source and closed-source VLMs, we find that models consistently fail at temperature-grounded reasoning, degrade under colormap transformations, and default to language priors or fixed responses, with only marginal gains from prompting or supervised fine-tuning. These results demonstrate that thermal understanding requires dedicated evaluation beyond RGB-centric assumptions, positioning ThermEval as a benchmark to drive progress in thermal vision language modeling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ThermEval：热成像视觉语言模型评估的结构化基准</div>
<div class="mono" style="margin-top:8px">视觉语言模型（VLMs）在RGB图像上表现出色，但无法推广到热图像。热感知在可见光失效的环境中发挥着关键作用，包括夜间监控、搜索与救援、自动驾驶和医疗筛查。与RGB图像不同，热图像编码物理温度而非颜色或纹理，这需要现有RGB中心基准未评估的感知和推理能力。我们推出ThermEval-B，这是一个结构化基准，包含约55,000对热视觉问答对，旨在评估热视觉语言理解所需的基础原语。ThermEval-B整合了公共数据集和我们新收集的ThermEval-D，这是第一个提供密集每像素温度图和跨多种室内外环境的语义身体部位注释的数据集。评估25个开源和闭源的VLMs，我们发现模型在基于温度的推理上始终失败，在色彩图变换下性能下降，并默认使用语言先验或固定响应，仅在提示或监督微调中获得微小提升。这些结果表明，热理解需要超越RGB中心假设的专门评估，使ThermEval成为推动热视觉语言建模进展的基准。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the limitations of vision language models (VLMs) that perform well on RGB imagery but struggle with thermal images, which are crucial in various applications like surveillance and medical screening. The authors introduce ThermEval-B, a benchmark consisting of approximately 55,000 thermal visual question answering pairs, to evaluate the necessary capabilities for thermal vision language understanding. Experimental results reveal that 25 evaluated VLMs consistently fail in temperature-grounded reasoning and show degradation under colormap transformations, indicating that existing models rely on language priors rather than effectively processing thermal data, thus highlighting the need for dedicated evaluation frameworks like ThermEval to advance thermal vision language modeling.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决视觉语言模型（VLM）在RGB图像上表现良好但在热成像上存在局限性的问题，而热成像在监控和医疗筛查等多种应用中至关重要。作者提出了ThermEval-B，一个包含约55,000个热视觉问答对的基准，旨在评估理解热图像所需的能力。通过对25种不同的VLM进行测试，研究发现这些模型在温度基础推理方面普遍失败，在色彩图变换下性能下降，并且通常依赖语言先验或固定响应，表明热视觉语言理解需要专门的评估方法。</div>
</details>
</div>
<div class="card">
<div class="title">Method for noise-induced regularization in quantum neural networks</div>
<div class="meta-line">Authors: Viacheslav Kuzmin, Wilfrid Somogyi, Ekaterina Pankovets, Alexey Melnikov</div>
<div class="meta-line">Venue: Adv. Quantum Technol. 8(12), e00603 (2025)</div>
<div class="meta-line">First: 2024-10-25T18:29:42+00:00 · Latest: 2026-02-16T18:12:59+00:00</div>
<div class="meta-line">Comments: 12 pages, 5 figures, 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.19921v2">Abs</a> · <a href="https://arxiv.org/pdf/2410.19921v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In the current quantum computing paradigm, significant focus is placed on the reduction or mitigation of quantum decoherence. When designing new quantum processing units, the general objective is to reduce the amount of noise qubits are subject to, and in algorithm design, a large effort is underway to provide scalable error correction or mitigation techniques. Yet some previous work has indicated that certain classes of quantum algorithms, such as quantum machine learning, may, in fact, be intrinsically robust to or even benefit from the presence of a small amount of noise. Here, we demonstrate that noise levels in quantum hardware can be effectively tuned to enhance the ability of quantum neural networks to generalize data, acting akin to regularisation in classical neural networks. As an example, we consider two regression tasks, where, by tuning the noise level in the circuit, we demonstrated improvement of the validation mean squared error loss. Moreover, we demonstrate the method&#x27;s effectiveness by numerically simulating quantum neural network training on a realistic model of a noisy superconducting quantum computer.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>量子神经网络中的噪声诱导正则化方法</div>
<div class="mono" style="margin-top:8px">在当前的量子计算范式中，显著关注点放在减少或缓解量子退相干上。在设计新的量子处理单元时，普遍目标是减少量子比特所受的噪声量，而在算法设计中，正在进行大量努力以提供可扩展的错误修正或缓解技术。然而，一些先前的工作表明，某些类别的量子算法，例如量子机器学习，实际上可能对少量噪声具有内在的鲁棒性，甚至从中受益。在这里，我们展示了量子硬件中的噪声水平可以有效调节，以增强量子神经网络对数据的泛化能力，类似于经典神经网络中的正则化。作为示例，我们考虑了两个回归任务，通过调节电路中的噪声水平，我们展示了验证均方误差损失的改善。此外，我们通过在一个现实的噪声超导量子计算机模型上数值模拟量子神经网络训练，证明了该方法的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the potential benefits of noise in quantum neural networks, contrasting the typical focus on reducing quantum decoherence. The authors propose a method that tunes noise levels in quantum hardware to enhance the generalization capabilities of quantum neural networks, similar to regularization techniques in classical neural networks. Experimental results from two regression tasks show that adjusting the noise level leads to a reduction in validation mean squared error loss, and the method&#x27;s effectiveness is further validated through numerical simulations on a realistic model of a noisy superconducting quantum computer.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于探索噪声在量子神经网络中的潜在益处，这与量子计算中常见的减少量子退相干的目标形成对比。作者提出了一种方法，通过调节量子硬件中的噪声水平，增强量子神经网络的泛化能力，类似于经典神经网络中的正则化技术。关键实验结果表明，通过在训练过程中调整噪声水平，在两个回归任务中显著改善了验证均方误差损失，且通过对噪声超导量子计算机的真实模型进行数值模拟，证明了该方法的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Orthogonalized Multimodal Contrastive Learning with Asymmetric Masking for Structured Representations</div>
<div class="meta-line">Authors: Carolin Cissee, Raneen Younis, Zahra Ahmadi</div>
<div class="meta-line">First: 2026-02-16T18:06:53+00:00 · Latest: 2026-02-16T18:06:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14983v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14983v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal learning seeks to integrate information from heterogeneous sources, where signals may be shared across modalities, specific to individual modalities, or emerge only through their interaction. While self-supervised multimodal contrastive learning has achieved remarkable progress, most existing methods predominantly capture redundant cross-modal signals, often neglecting modality-specific (unique) and interaction-driven (synergistic) information. Recent extensions broaden this perspective, yet they either fail to explicitly model synergistic interactions or learn different information components in an entangled manner, leading to incomplete representations and potential information leakage. We introduce \textbf{COrAL}, a principled framework that explicitly and simultaneously preserves redundant, unique, and synergistic information within multimodal representations. COrAL employs a dual-path architecture with orthogonality constraints to disentangle shared and modality-specific features, ensuring a clean separation of information components. To promote synergy modeling, we introduce asymmetric masking with complementary view-specific patterns, compelling the model to infer cross-modal dependencies rather than rely solely on redundant cues. Extensive experiments on synthetic benchmarks and diverse MultiBench datasets demonstrate that COrAL consistently matches or outperforms state-of-the-art methods while exhibiting low performance variance across runs. These results indicate that explicitly modeling the full spectrum of multimodal information yields more stable, reliable, and comprehensive embeddings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>具有非对称掩蔽的正交多模态对比学习用于结构化表示</div>
<div class="mono" style="margin-top:8px">多模态学习旨在整合来自异构来源的信息，其中信号可能在模态之间共享、特定于单个模态，或仅通过它们的交互而出现。尽管自监督多模态对比学习取得了显著进展，但大多数现有方法主要捕捉冗余的跨模态信号，往往忽视模态特定（独特）和交互驱动（协同）信息。最近的扩展拓宽了这一视角，但它们要么未能明确建模协同交互，要么以纠缠的方式学习不同的信息组件，导致表示不完整和潜在的信息泄漏。我们引入了\textbf{COrAL}，一个原则性框架，明确且同时保留多模态表示中的冗余、独特和协同信息。COrAL采用具有正交约束的双路径架构，以解开共享和模态特定特征，确保信息组件的清晰分离。为了促进协同建模，我们引入了具有互补视图特定模式的非对称掩蔽，迫使模型推断跨模态依赖关系，而不仅仅依赖冗余线索。在合成基准和多样化的MultiBench数据集上的广泛实验表明，COrAL始终与最先进的方法相匹配或超越，同时在多次运行中表现出低性能方差。这些结果表明，明确建模多模态信息的全谱可以产生更稳定、可靠和全面的嵌入。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve multimodal learning by addressing the limitations of existing methods that often overlook unique and interaction-driven information in favor of redundant cross-modal signals. The authors propose a framework called COrAL, which utilizes a dual-path architecture with orthogonality constraints to effectively separate shared and modality-specific features, while also implementing asymmetric masking to enhance synergy modeling. Experimental results on synthetic benchmarks and various MultiBench datasets show that COrAL consistently matches or surpasses state-of-the-art methods, demonstrating lower performance variance and yielding more stable and comprehensive multimodal embeddings.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于通过有效捕捉不同模态中的独特和协同信息来改善多模态学习，而现有方法往往忽视这些信息。作者提出了一种名为COrAL的框架，该框架利用双路径架构和正交约束来分离多模态表示中的冗余、独特和协同信息。对合成基准和MultiBench数据集的实验结果表明，COrAL在性能上始终与最先进的方法相匹配或超越，并保持低性能方差，这表明全面建模多模态信息可以导致更稳定和可靠的嵌入。</div>
</details>
</div>
<div class="card">
<div class="title">Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</div>
<div class="meta-line">Authors: David P. Woodruff, Vincent Cohen-Addad, Lalit Jain, Jieming Mao, Song Zuo, MohammadHossein Bateni, Simina Branzei, Michael P. Brenner, Lin Chen, Ying Feng, Lance Fortnow, Gang Fu, Ziyi Guan, Zahra Hadizadeh, Mohammad T. Hajiaghayi, Mahdi JafariRaviz, Adel Javanmard, Karthik C. S., Ken-ichi Kawarabayashi, Ravi Kumar, Silvio Lattanzi, Euiwoong Lee, Yi Li, Ioannis Panageas, Dimitris Paparas, Benjamin Przybocki, Bernardo Subercaseaux, Ola Svensson, Shayan Taherijam, Xuan Wu, Eylon Yogev, Morteza Zadimoghaddam, Samson Zhou, Yossi Matias, James Manyika, Vahab Mirrokni</div>
<div class="meta-line">First: 2026-02-03T18:56:17+00:00 · Latest: 2026-02-16T18:02:06+00:00</div>
<div class="meta-line">Comments: Author list now includes Yossi Matias and James Manyika. Acknowledgements also updated. Added more general discussion to sections 1, 9.1, and 9.5. Discussed related work of Gurvits in section 4.3. Clarified closed form in section 6.1 and gave finite sum expansions for coefficients. Other minor formatting fixes</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03837v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.03837v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google&#x27;s Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a &quot;neuro-symbolic&quot; loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用Gemini加速科学研究：案例研究与常见技术</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）的最新进展为加速科学研究开辟了新途径。尽管这些模型在协助日常任务方面越来越有能力，但它们在新颖的专家级数学发现中的贡献能力尚不清楚。我们展示了一系列案例研究，证明研究人员如何成功与先进的AI模型（特别是基于谷歌Gemini的模型，尤其是Gemini Deep Think及其高级变体）合作，解决开放问题、反驳猜想，并在理论计算机科学及经济学、优化和物理等其他领域生成新证明。基于这些经验，我们提取了有效的人机协作在理论研究中的常见技术，如迭代优化、问题分解和跨学科知识转移。尽管我们的大部分结果源于这种互动对话的方法论，但我们也强调了一些超越标准聊天界面的具体实例。这些实例包括将模型作为严格的对抗审稿人，以检测现有证明中的细微缺陷，以及将其嵌入“神经符号”循环中，自动编写和执行代码以验证复杂推导。这些例子共同突显了AI不仅作为自动化工具的潜力，更是科学发现创造过程中的多功能、真实合作伙伴。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to explore how large language models (LLMs), particularly Google&#x27;s Gemini models, can enhance scientific research by contributing to expert-level mathematical discovery. The authors conducted case studies where researchers collaborated with these AI models to address open problems and generate new proofs in fields like theoretical computer science, economics, optimization, and physics. Key findings indicate that effective human-AI collaboration techniques, such as iterative refinement and problem decomposition, significantly improve research outcomes, with notable applications including the model acting as an adversarial reviewer and participating in a neuro-symbolic loop for code verification.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于探索大型语言模型（LLMs）在加速科学研究中的潜力，特别是在专家级数学发现方面。作者展示了研究人员如何与谷歌的Gemini模型合作，解决开放性问题、反驳猜想并在理论计算机科学、经济学、优化和物理等领域生成新证明的案例研究。主要发现包括有效的人机协作技术，如迭代精炼和问题分解，以及模型的创新应用，如将其用作对抗性审稿人和将其集成到神经符号循环中以实现自主代码验证。</div>
</details>
</div>
<div class="card">
<div class="title">Evolution Strategies at the Hyperscale</div>
<div class="meta-line">Authors: Bidipta Sarkar, Mattie Fellows, Juan Agustin Duque, Alistair Letcher, Antonio León Villares, Anya Sims, Clarisse Wibault, Dmitry Samsonov, Dylan Cope, Jarek Liesen, Kang Li, Lukas Seier, Theo Wolf, Uljad Berdica, Valentin Mohl, Alexander David Goldie, Aaron Courville, Karin Sevegnani, Shimon Whiteson, Jakob Nicolaus Foerster</div>
<div class="meta-line">First: 2025-11-20T18:56:05+00:00 · Latest: 2026-02-16T18:01:18+00:00</div>
<div class="meta-line">Comments: 76 pages, 15 figures, Website at https://eshyperscale.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.16652v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.16652v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://eshyperscale.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Evolution Strategies (ES) is a class of powerful black-box optimisation methods that are highly parallelisable and can handle non-differentiable and noisy objectives. However, naïve ES becomes prohibitively expensive at scale on GPUs due to the low arithmetic intensity of batched matrix multiplications with unstructured random perturbations. We introduce Evolution Guided GeneRal Optimisation via Low-rank Learning (EGGROLL), which improves arithmetic intensity by structuring individual perturbations as rank-$r$ matrices, resulting in a hundredfold increase in training speed for billion-parameter models at large population sizes, achieving up to 91% of the throughput of pure batch inference. We provide a rigorous theoretical analysis of Gaussian ES for high-dimensional parameter objectives, investigating conditions needed for ES updates to converge in high dimensions. Our results reveal a linearising effect, and proving consistency between EGGROLL and ES as parameter dimension increases. Our experiments show that EGGROLL: (1) enables the stable pretraining of nonlinear recurrent language models that operate purely in integer datatypes, (2) is competitive with GRPO for post-training LLMs on reasoning tasks, and (3) does not compromise performance compared to ES in tabula rasa RL settings, despite being faster.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超大规模下的进化策略</div>
<div class="mono" style="margin-top:8px">进化策略（ES）是一类强大的黑箱优化方法，具有高度的并行性，能够处理非可微和噪声目标。然而，简单的ES在GPU上规模化时变得极其昂贵，因为批量矩阵乘法与无结构随机扰动的算术强度较低。我们提出了通过低秩学习的进化引导通用优化（EGGROLL），通过将个体扰动结构化为秩-$r$ 矩阵来提高算术强度，从而在大规模人群中实现十倍的训练速度提升，达到纯批量推理的91%吞吐量。我们对高维参数目标的高斯ES进行了严格的理论分析，研究了ES更新在高维中收敛所需的条件。我们的结果揭示了线性化效应，并证明了EGGROLL与ES在参数维度增加时的一致性。我们的实验表明，EGGROLL：（1）能够稳定预训练仅使用整数数据类型的非线性递归语言模型，（2）在推理任务上与GRPO竞争，（3）在无知识强化学习设置中与ES相比没有性能损失，尽管速度更快。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of traditional Evolution Strategies (ES) in large-scale applications, particularly the inefficiencies in GPU performance due to low arithmetic intensity. The authors propose a novel method called Evolution Guided GeneRal Optimisation via Low-rank Learning (EGGROLL), which enhances arithmetic intensity by structuring perturbations as rank-$r$ matrices. Experimental results demonstrate that EGGROLL significantly increases training speed for billion-parameter models, achieving up to 91% of the throughput of pure batch inference, while also enabling stable pretraining of nonlinear recurrent language models, competing effectively with existing methods on reasoning tasks, and maintaining performance in reinforcement learning settings despite its increased speed.</div>
<div class="mono" style="margin-top:8px">本研究解决了传统进化策略（ES）在大规模GPU应用中的低效问题，特别是在批量矩阵乘法中，由于无结构随机扰动导致的低算术强度。作者提出了一种新方法，称为基于低秩学习的进化引导通用优化（EGGROLL），通过将扰动结构化为秩-$r$ 矩阵来增强算术强度。实验结果表明，EGGROLL在十亿参数模型的训练速度上提高了百倍，在推理任务中与GRPO的性能相当，并且在强化学习环境中保持了ES的有效性，同时实现了非线性递归语言模型的稳定预训练。</div>
</details>
</div>
<div class="card">
<div class="title">MacroGuide: Topological Guidance for Macrocycle Generation</div>
<div class="meta-line">Authors: Alicja Maksymiuk, Alexandre Duplessis, Michael Bronstein, Alexander Tong, Fernanda Duarte, İsmail İlkan Ceylan</div>
<div class="meta-line">First: 2026-02-16T18:00:53+00:00 · Latest: 2026-02-16T18:00:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14977v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14977v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Macrocycles are ring-shaped molecules that offer a promising alternative to small-molecule drugs due to their enhanced selectivity and binding affinity against difficult targets. Despite their chemical value, they remain underexplored in generative modeling, likely owing to their scarcity in public datasets and the challenges of enforcing topological constraints in standard deep generative models. We introduce MacroGuide: Topological Guidance for Macrocycle Generation, a diffusion guidance mechanism that uses Persistent Homology to steer the sampling of pretrained molecular generative models toward the generation of macrocycles, in both unconditional and conditional (protein pocket) settings. At each denoising step, MacroGuide constructs a Vietoris-Rips complex from atomic positions and promotes ring formation by optimizing persistent homology features. Empirically, applying MacroGuide to pretrained diffusion models increases macrocycle generation rates from 1% to 99%, while matching or exceeding state-of-the-art performance on key quality metrics such as chemical validity, diversity, and PoseBusters checks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MacroGuide：宏环生成的拓扑指导</div>
<div class="mono" style="margin-top:8px">宏环是环状分子，由于其对难以靶向的分子的增强选择性和结合亲和力，提供了小分子药物的有前景替代方案。尽管它们具有化学价值，但在生成建模中仍然未被充分探索，这可能是由于它们在公共数据集中的稀缺性以及在标准深度生成模型中强制执行拓扑约束的挑战。我们介绍了MacroGuide：宏环生成的拓扑指导，这是一种扩散指导机制，利用持久同调引导预训练分子生成模型的采样，以生成宏环，适用于无条件和条件（蛋白质口袋）设置。在每个去噪步骤中，MacroGuide从原子位置构建Vietoris-Rips复形，并通过优化持久同调特征促进环的形成。实证表明，将MacroGuide应用于预训练扩散模型将宏环生成率从1%提高到99%，同时在化学有效性、多样性和PoseBusters检查等关键质量指标上匹配或超过最先进的性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the generation of macrocycles, which are valuable for drug development but are underrepresented in generative modeling due to their scarcity in datasets and the difficulty of enforcing topological constraints. The authors introduce MacroGuide, a diffusion guidance mechanism that utilizes Persistent Homology to direct the sampling of pretrained molecular generative models towards macrocycle generation in both unconditional and conditional contexts. The experimental results demonstrate that MacroGuide significantly improves macrocycle generation rates from 1% to 99% and achieves or surpasses state-of-the-art performance in terms of chemical validity, diversity, and PoseBusters checks.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于宏环分子作为小分子药物的替代品的潜力，但由于数据集稀缺和拓扑约束，其生成建模受到限制。作者提出了MacroGuide，这是一种利用持久同调的扩散引导机制，旨在通过引导预训练的分子生成模型来增强宏环的生成。实验结果表明，MacroGuide显著提高了宏环的生成率，从1%提高到99%，同时在化学有效性、多样性和PoseBusters检查等关键质量指标上达到或超过了最先进的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Faster Molecular Dynamics with Neural Network Potentials via Distilled Multiple Time-Stepping and Non-Conservative Forces</div>
<div class="meta-line">Authors: Nicolaï Gouraud, Côme Cattin, Thomas Plé, Olivier Adjoua, Louis Lagardère, Jean-Philip Piquemal</div>
<div class="meta-line">First: 2026-02-16T17:59:44+00:00 · Latest: 2026-02-16T17:59:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14975v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14975v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Following our previous work (J. Phys. Chem. Lett., 2026, 17, 5, 1288-1295), we propose the DMTS-NC approach, a distilled multi-time-step (DMTS) strategy using non conservative (NC) forces to further accelerate atomistic molecular dynamics simulations using foundation neural network models. There, a dual-level reversible reference system propagator algorithm (RESPA) formalism couples a target accurate conservative potential to a simplified distilled representation optimized for the production of non-conservative forces. Despite being non-conservative, the distilled architecture is designed to enforce key physical priors, such as equivariance under rotation and cancellation of atomic force components. These choices facilitate the distillation process and therefore improve drastically the robustness of simulation, significantly limiting the &quot;holes&quot; in the simpler potential, thus achieving excellent agreement with the forces data. Overall, the DMTS-NC scheme is found to be more stable and efficient than its conservative counterpart with additional speedups reaching 15-30% over DMTS. Requiring no finetuning steps, it is easier to implement and can be pushed to the limit of the systems physical resonances to maintain accuracy while providing maximum efficiency. As for DMTS, DMTS-NC is applicable to any neural network potential.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过蒸馏多时间步和非保守力实现更快的分子动力学</div>
<div class="mono" style="margin-top:8px">在我们之前的工作基础上（J. Phys. Chem. Lett., 2026, 17, 5, 1288-1295），我们提出了DMTS-NC方法，这是一种使用非保守力的蒸馏多时间步（DMTS）策略，以进一步加速基于神经网络模型的原子分子动力学模拟。在此，双层可逆参考系统传播算法（RESPA）形式将目标精确的保守势能与优化的简化蒸馏表示相结合，以生成非保守力。尽管是非保守的，蒸馏架构旨在强制执行关键的物理先验，例如旋转下的等变性和原子力分量的抵消。这些选择促进了蒸馏过程，从而显著提高了模拟的稳健性，显著限制了简化势能中的“孔”，因此与力数据达成了良好的一致性。总体而言，DMTS-NC方案被发现比其保守对应物更稳定和高效，额外的加速达到15-30%。无需微调步骤，实施更为简便，并且可以推向系统物理共振的极限，以保持准确性，同时提供最大效率。与DMTS一样，DMTS-NC适用于任何神经网络势能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enhance the efficiency of atomistic molecular dynamics simulations by introducing the DMTS-NC approach, which utilizes distilled multi-time-stepping and non-conservative forces. The method employs a dual-level reversible reference system propagator algorithm (RESPA) that combines an accurate conservative potential with a simplified distilled representation optimized for non-conservative forces, while enforcing physical priors to improve robustness. Experimental results demonstrate that the DMTS-NC scheme achieves 15-30% speedups over traditional methods, showing greater stability and efficiency without requiring finetuning, making it easier to implement and effective across various neural network potentials.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于加速使用神经网络势的原子分子动力学模拟。作者提出了一种提炼的多时间步策略，结合了非保守力，利用双层可逆参考系统传播者算法将准确的保守势与优化的简化表示相结合，以适应非保守力。主要实验结果表明，DMTS-NC 方法比传统方法更稳定和高效，速度提升达到15-30%，且无需微调，同时通过强制物理先验（如旋转下的等变性）来保持模拟的准确性和鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Robust Multi-Objective Controlled Decoding of Large Language Models</div>
<div class="meta-line">Authors: Seongho Son, William Bankes, Sangwoong Yoon, Shyam Sundhar Ramesh, Xiaohang Tang, Ilija Bogunovic</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2025-03-11T18:15:26+00:00 · Latest: 2026-02-16T17:58:26+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.08796v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.08796v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce Robust Multi-Objective Decoding (RMOD), a novel inference-time algorithm that robustly aligns Large Language Models (LLMs) to multiple human objectives (e.g., instruction-following, helpfulness, safety) by maximizing the worst-case rewards. RMOD formulates the robust decoding problem as a maximin two-player game between adversarially computed reward weights and the sampling policy, solvable through a Nash equilibrium. We demonstrate that this game reduces to a convex optimization problem to identify the worst-case reward weights, with the optimal sampling policy analytically derived. For practical applications, we propose an efficient algorithm of RMOD tailored for contemporary LLMs, introducing minimal computational overhead compared to standard non-robust Controlled Decoding methods. Experimental results across a range of popular alignment datasets with up to 10 objectives show the effectiveness of RMOD and its distilled version, consistently outperforming baselines in worst-case rewards and win rates.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大型语言模型的鲁棒多目标控制解码</div>
<div class="mono" style="margin-top:8px">我们介绍了鲁棒多目标解码（RMOD），这是一种新颖的推理时算法，通过最大化最坏情况奖励，鲁棒地将大型语言模型（LLMs）对齐到多个人类目标（例如，遵循指令、帮助性、安全性）。RMOD将鲁棒解码问题表述为一个对抗性计算奖励权重和采样策略之间的最大最小双人游戏，可以通过纳什均衡求解。我们证明这个游戏简化为一个凸优化问题，以识别最坏情况奖励权重，并且最优采样策略可以通过分析推导得出。对于实际应用，我们提出了一种针对当代LLMs的高效RMOD算法，与标准非鲁棒控制解码方法相比，计算开销最小。针对多达10个目标的多种流行对齐数据集的实验结果显示，RMOD及其提炼版本的有效性，在最坏情况奖励和胜率上始终优于基线。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to align Large Language Models (LLMs) with multiple human objectives such as instruction-following, helpfulness, and safety. The authors propose a novel inference-time algorithm called Robust Multi-Objective Decoding (RMOD), which formulates the decoding problem as a maximin two-player game, solvable through a Nash equilibrium. Experimental results demonstrate that RMOD, along with its distilled version, effectively outperforms baseline methods in worst-case rewards and win rates across various alignment datasets with up to 10 objectives, while maintaining minimal computational overhead compared to standard non-robust methods.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于需要将大型语言模型（LLMs）与多个人工目标（如遵循指令、提供帮助和安全性）对齐。作者提出了鲁棒多目标解码（RMOD），这是一种推理时算法，将解码问题表述为可通过纳什均衡求解的最大最小双人博弈，最终简化为一个凸优化问题，以识别最坏情况下的奖励权重。实验结果表明，RMOD及其提炼版本在多达10个目标的各种对齐数据集上，在最坏情况下的奖励和胜率方面均优于基线方法，同时与标准方法相比，计算开销保持在最低水平。</div>
</details>
</div>
<div class="card">
<div class="title">Use What You Know: Causal Foundation Models with Partial Graphs</div>
<div class="meta-line">Authors: Arik Reuter, Anish Dhir, Cristiana Diaconu, Jake Robertson, Ole Ossen, Frank Hutter, Adrian Weller, Mark van der Wilk, Bernhard Schölkopf</div>
<div class="meta-line">First: 2026-02-16T17:56:37+00:00 · Latest: 2026-02-16T17:56:37+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.14972v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.14972v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discovery and inference in a single step. However, in their current state, they do not allow for the incorporation of any domain knowledge, which can lead to suboptimal predictions. We bridge this gap by introducing methods to condition CFMs on causal information, such as the causal graph or more readily available ancestral information. When access to complete causal graph information is too strict a requirement, our approach also effectively leverages partial causal information. We systematically evaluate conditioning strategies and find that injecting learnable biases into the attention mechanism is the most effective method to utilise full and partial causal information. Our experiments show that this conditioning allows a general-purpose CFM to match the performance of specialised models trained on specific causal structures. Overall, our approach addresses a central hurdle on the path towards all-in-one causal foundation models: the capability to answer causal queries in a data-driven manner while effectively leveraging any amount of domain expertise.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用已知信息：带部分图的因果基础模型</div>
<div class="mono" style="margin-top:8px">传统上，估计因果量依赖于针对特定假设量身定制的估计器。最近提出的因果基础模型（CFMs）通过在单一步骤中摊销因果发现和推断，承诺提供更统一的方法。然而，在当前状态下，它们不允许纳入任何领域知识，这可能导致次优预测。我们通过引入方法来基于因果信息（如因果图或更易获得的祖先信息）对CFMs进行条件化，从而弥补这一差距。当对完整因果图信息的访问要求过于严格时，我们的方法也有效利用部分因果信息。我们系统地评估了条件化策略，发现将可学习的偏差注入注意机制是利用完整和部分因果信息的最有效方法。我们的实验表明，这种条件化使得通用CFM能够匹配在特定因果结构上训练的专用模型的性能。总体而言，我们的方法解决了通往一体化因果基础模型的中心障碍：在数据驱动的方式下回答因果查询的能力，同时有效利用任何量的领域专业知识。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the predictive capabilities of Causal Foundation Models (CFMs) by integrating domain knowledge, which is often overlooked in traditional causal estimation methods. The authors propose a novel approach that conditions CFMs on causal information, including causal graphs and ancestral data, while also effectively utilizing partial causal information when complete graphs are unavailable. Experimental results demonstrate that incorporating learnable biases into the attention mechanism significantly improves the performance of CFMs, enabling them to achieve results comparable to specialized models designed for specific causal structures.</div>
<div class="mono" style="margin-top:8px">本研究的动机是通过引入领域知识来提高因果基础模型（CFMs）的性能，而传统的因果估计方法通常忽视这一点。作者提出了一种新方法，通过条件化CFMs以利用因果信息，包括因果图和祖先数据，同时在完整图不可用时有效利用部分因果信息。实验结果表明，将可学习的偏差整合到注意力机制中显著提高了模型利用完整和部分因果信息的能力，使得通用CFM的性能可与针对特定因果结构的专门模型相媲美。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260217_0341.html">20260217_0341</a>
<a href="archive/20260216_0336.html">20260216_0336</a>
<a href="archive/20260215_0334.html">20260215_0334</a>
<a href="archive/20260213_0357.html">20260213_0357</a>
<a href="archive/20260212_0403.html">20260212_0403</a>
<a href="archive/20260210_0412.html">20260210_0412</a>
<a href="archive/20260208_0334.html">20260208_0334</a>
<a href="archive/20260207_0346.html">20260207_0346</a>
<a href="archive/20260206_0346.html">20260206_0346</a>
<a href="archive/20260205_0348.html">20260205_0348</a>
<a href="archive/20260204_0354.html">20260204_0354</a>
<a href="archive/20260203_1224.html">20260203_1224</a>
<a href="archive/20260202_0334.html">20260202_0334</a>
<a href="archive/20260201_0330.html">20260201_0330</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0342.html">20260130_0342</a>
<a href="archive/20260129_0342.html">20260129_0342</a>
<a href="archive/20260128_0340.html">20260128_0340</a>
<a href="archive/20260127_0335.html">20260127_0335</a>
<a href="archive/20260126_0328.html">20260126_0328</a>
<a href="archive/20260125_0326.html">20260125_0326</a>
<a href="archive/20260124_0335.html">20260124_0335</a>
<a href="archive/20260123_0336.html">20260123_0336</a>
<a href="archive/20260122_0339.html">20260122_0339</a>
<a href="archive/20260121_0422.html">20260121_0422</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_0325.html">20260118_0325</a>
<a href="archive/20260117_0329.html">20260117_0329</a>
<a href="archive/20260116_0336.html">20260116_0336</a>
<a href="archive/20260115_0332.html">20260115_0332</a>
<a href="archive/20260114_0332.html">20260114_0332</a>
<a href="archive/20260113_0331.html">20260113_0331</a>
<a href="archive/20260112_0325.html">20260112_0325</a>
<a href="archive/20260111_0325.html">20260111_0325</a>
<a href="archive/20260110_0330.html">20260110_0330</a>
<a href="archive/20260109_0330.html">20260109_0330</a>
<a href="archive/20260108_0332.html">20260108_0332</a>
<a href="archive/20260107_0328.html">20260107_0328</a>
<a href="archive/20260106_1857.html">20260106_1857</a>
<a href="archive/20260106_1846.html">20260106_1846</a>
<a href="archive/20260106_0330.html">20260106_0330</a>
<a href="archive/20260105_0325.html">20260105_0325</a>
<a href="archive/20260104_2229.html">20260104_2229</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
