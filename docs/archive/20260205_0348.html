<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-05 03:48</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260205_0348</div>
    <div class="row"><div class="card">
<div class="title">PLATE: Plasticity-Tunable Efficient Adapters for Geometry-Aware Continual Learning</div>
<div class="meta-line">Authors: Romain Cosentino</div>
<div class="meta-line">First: 2026-02-03T18:59:42+00:00 · Latest: 2026-02-03T18:59:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03846v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03846v1">PDF</a> · <a href="https://github.com/SalesforceAIResearch/PLATE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We develop a continual learning method for pretrained models that \emph{requires no access to old-task data}, addressing a practical barrier in foundation model adaptation where pretraining distributions are often unavailable. Our key observation is that pretrained networks exhibit substantial \emph{geometric redundancy}, and that this redundancy can be exploited in two complementary ways. First, redundant neurons provide a proxy for dominant pretraining-era feature directions, enabling the construction of approximately protected update subspaces directly from pretrained weights. Second, redundancy offers a natural bias for \emph{where} to place plasticity: by restricting updates to a subset of redundant neurons and constraining the remaining degrees of freedom, we obtain update families with reduced functional drift on the old-data distribution and improved worst-case retention guarantees. These insights lead to \textsc{PLATE} (\textbf{Pla}sticity-\textbf{T}unable \textbf{E}fficient Adapters), a continual learning method requiring no past-task data that provides explicit control over the plasticity-retention trade-off. PLATE parameterizes each layer with a structured low-rank update $ΔW = B A Q^\top$, where $B$ and $Q$ are computed once from pretrained weights and kept frozen, and only $A$ is trained on the new task. The code is available at https://github.com/SalesforceAIResearch/PLATE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PLATE：可调塑性高效适配器用于几何感知的持续学习</div>
<div class="mono" style="margin-top:8px">我们开发了一种针对预训练模型的持续学习方法，该方法\emph{不需要访问旧任务数据}，解决了基础模型适应中预训练分布通常不可用的实际障碍。我们的关键观察是，预训练网络表现出显著的\emph{几何冗余}，这种冗余可以通过两种互补方式加以利用。首先，冗余神经元为主导的预训练特征方向提供了一个代理，使得可以直接从预训练权重构建大致受保护的更新子空间。其次，冗余为\emph{在哪里}放置塑性提供了自然的偏置：通过将更新限制在冗余神经元的子集上并约束其余自由度，我们获得了在旧数据分布上功能漂移减少和最坏情况保留保证改善的更新族。这些见解导致了\textsc{PLATE}（\textbf{Pla}sticity-\textbf{T}unable \textbf{E}fficient Adapters），这是一种不需要过去任务数据的持续学习方法，提供了对塑性-保留权衡的明确控制。PLATE通过结构化低秩更新$ΔW = B A Q^\top$对每一层进行参数化，其中$B$和$Q$从预训练权重中计算一次并保持不变，只有$A$在新任务上进行训练。代码可在https://github.com/SalesforceAIResearch/PLATE获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to develop a continual learning method for pretrained models that does not require access to old-task data, addressing challenges in adapting foundation models where pretraining distributions are often unavailable. The authors introduce PLATE, which leverages geometric redundancy in pretrained networks by constructing protected update subspaces from pretrained weights and selectively updating a subset of redundant neurons to minimize functional drift and enhance retention of old-task performance. Experimental results demonstrate that PLATE effectively controls the plasticity-retention trade-off, leading to improved performance on new tasks while preserving knowledge from previous tasks without needing past data.</div>
<div class="mono" style="margin-top:8px">本研究解决了在预训练模型中进行持续学习的挑战，而无需访问旧任务数据，这在实际应用中通常是不可用的。作者利用预训练网络中存在的几何冗余，通过从预训练权重构建受保护的更新子空间，并选择性地更新一部分冗余神经元。实验结果表明，他们提出的方法PLATE有效减少了旧数据分布上的功能漂移，并改善了保留保证，从而在持续学习场景中允许对可塑性与保留之间的权衡进行明确控制。</div>
</details>
</div>
<div class="card">
<div class="title">Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes</div>
<div class="meta-line">Authors: Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie</div>
<div class="meta-line">First: 2026-01-26T18:57:00+00:00 · Latest: 2026-02-03T18:58:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18795v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18795v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>重用你的FLOPs：通过条件化非常离政策前缀在困难问题上扩展强化学习</div>
<div class="mono" style="margin-top:8px">典型的强化学习（RL）方法在大语言模型推理中对困难问题的计算资源浪费严重，因为正确的在政策轨迹稀少，策略梯度消失，学习停滞。为了启动更高效的RL，我们考虑以离政策轨迹的形式重用旧的采样FLOPs（来自先前的推理或RL训练）。标准的离政策方法对离政策数据进行监督，导致RL优化过程中的不稳定性。我们引入了PrefixRL，通过条件化成功的离政策轨迹的前缀并运行在政策RL来完成它们，从而规避离政策的不稳定性。PrefixRL通过调节问题的难度（通过离政策前缀长度）来增强困难问题上的学习信号。我们证明了PrefixRL目标不仅与标准RL目标一致，而且更具样本效率。从经验上看，我们发现了反向泛化：仅在前缀问题上训练可以推广到分布外的无前缀性能，学习的策略往往与前缀中的策略不同。在我们的实验中，我们通过拒绝采样与基础模型源源不断地获取离政策轨迹，创建了一个自我改进循环。在困难推理问题上，PrefixRL以比最强基线（在离政策数据上进行SFT然后RL）快2倍的速度达到相同的训练奖励，即使考虑到初始拒绝采样所花费的计算资源，并且最终奖励增加了3倍。这些收益转移到保留的基准上，并且当离政策轨迹来自不同模型家族时，PrefixRL仍然有效，验证了其在实际环境中的灵活性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the efficiency of reinforcement learning (RL) methods for large language models (LLMs) when tackling hard problems, where traditional approaches often struggle due to the scarcity of correct on-policy traces and vanishing policy gradients. The authors introduce PrefixRL, a novel method that reuses old sampling FLOPs from prior inference or RL training by conditioning on successful off-policy traces, thereby avoiding instabilities associated with standard off-policy methods. Experimental results show that PrefixRL significantly accelerates learning on challenging tasks, achieving the same training reward twice as fast as the strongest baseline while also tripling the final reward, with the benefits extending to out-of-distribution scenarios and demonstrating flexibility across different model families.</div>
<div class="mono" style="margin-top:8px">本研究解决了典型强化学习（RL）方法在处理困难问题时的低效性，尤其是在正确的在线轨迹稀缺且学习常常停滞的情况下。作者提出了一种新方法PrefixRL，通过对成功的离线轨迹进行条件化，重用先前推理或RL训练中的旧采样FLOPs，以增强在线RL性能。实验结果表明，PrefixRL加速了学习，以两倍于最强基线的速度实现相同的训练奖励，同时最终奖励增加了三倍，且对分布外基准的好处也得以延续，并在不同模型系列中保持有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Investigating Quantum Circuit Designs Using Neuro-Evolution</div>
<div class="meta-line">Authors: Devroop Kar, Daniel Krutz, Travis Desell</div>
<div class="meta-line">First: 2026-02-03T18:57:39+00:00 · Latest: 2026-02-03T18:57:39+00:00</div>
<div class="meta-line">Comments: Submitted to The Genetic and Evolutionary Computation Conference (GECCO) 2026. Under Review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03840v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03840v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Designing effective quantum circuits remains a central challenge in quantum computing, as circuit structure strongly influences expressivity, trainability, and hardware feasibility. Current approaches, whether using manually designed circuit templates, fixed heuristics, or automated rules, face limitations in scalability, flexibility, and adaptability, often producing circuits that are poorly matched to the specific problem or quantum hardware. In this work, we propose the Evolutionary eXploration of Augmenting Quantum Circuits (EXAQC), an evolutionary approach to the automated design and training of parameterized quantum circuits (PQCs) which leverages and extends on strategies from neuroevolution and genetic programming. The proposed method jointly searches over gate types, qubit connectivity, parameterization, and circuit depth while respecting hardware and noise constraints. The method supports both Qiskit and Pennylane libraries, allowing the user to configure every aspect. This work highlights evolutionary search as a critical tool for advancing quantum machine learning and variational quantum algorithms, providing a principled pathway toward scalable, problem-aware, and hardware-efficient quantum circuit design. Preliminary results demonstrate that circuits evolved on classification tasks are able to achieve over 90% accuracy on most of the benchmark datasets with a limited computational budget, and are able to emulate target circuit quantum states with high fidelity scores.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用神经进化研究量子电路设计</div>
<div class="mono" style="margin-top:8px">设计有效的量子电路仍然是量子计算中的一个核心挑战，因为电路结构强烈影响表达能力、可训练性和硬件可行性。目前的方法，无论是使用手动设计的电路模板、固定启发式方法还是自动化规则，都在可扩展性、灵活性和适应性方面面临限制，常常产生与特定问题或量子硬件不匹配的电路。在这项工作中，我们提出了增强量子电路的进化探索（EXAQC），这是一种自动设计和训练参数化量子电路（PQC）的进化方法，利用并扩展了神经进化和遗传编程的策略。该方法在尊重硬件和噪声约束的同时，联合搜索门类型、量子比特连接性、参数化和电路深度。该方法支持Qiskit和Pennylane库，允许用户配置每个方面。这项工作强调进化搜索作为推动量子机器学习和变分量子算法的重要工具，为可扩展、问题感知和硬件高效的量子电路设计提供了原则性路径。初步结果表明，在分类任务上进化的电路能够在大多数基准数据集上以有限的计算预算实现超过90%的准确率，并能够以高保真度模拟目标电路的量子态。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges in designing effective quantum circuits, which significantly impact expressivity, trainability, and hardware feasibility. The authors propose a novel method called Evolutionary eXploration of Augmenting Quantum Circuits (EXAQC), which utilizes an evolutionary approach to automate the design and training of parameterized quantum circuits by integrating strategies from neuroevolution and genetic programming. Experimental results indicate that the evolved circuits for classification tasks achieve over 90% accuracy on various benchmark datasets while efficiently emulating target circuit quantum states with high fidelity scores, demonstrating the method&#x27;s potential for scalable and adaptable quantum circuit design.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决有效量子电路设计中的挑战，这对表达能力、可训练性和硬件可行性有重大影响。作者提出了一种名为EXAQC的进化方法，该方法通过利用神经进化和遗传编程技术，自动化参数化量子电路的设计和训练。主要实验结果表明，进化出的电路在各种分类任务中能够以有限的计算资源实现超过90%的准确率，并能够高保真度地模拟目标电路的量子态。</div>
</details>
</div>
<div class="card">
<div class="title">Polynomial Neural Sheaf Diffusion: A Spectral Filtering Approach on Cellular Sheaves</div>
<div class="meta-line">Authors: Alessio Borgi, Fabrizio Silvestri, Pietro Liò</div>
<div class="meta-line">Venue: ICML 2026</div>
<div class="meta-line">First: 2025-11-28T23:10:54+00:00 · Latest: 2026-02-03T18:57:37+00:00</div>
<div class="meta-line">Comments: Under Review at ICML 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.00242v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.00242v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sheaf Neural Networks equip graph structures with a cellular sheaf: a geometric structure which assigns local vector spaces (stalks) and a linear learnable restriction/transport maps to nodes and edges, yielding an edge-aware inductive bias that handles heterophily and limits oversmoothing. However, common Neural Sheaf Diffusion implementations rely on SVD-based sheaf normalization and dense per-edge restriction maps, which scale with stalk dimension, require frequent Laplacian rebuilds, and yield brittle gradients. To address these limitations, we introduce Polynomial Neural Sheaf Diffusion (PolyNSD), a new sheaf diffusion approach whose propagation operator is a degree-K polynomial in a normalised sheaf Laplacian, evaluated via a stable three-term recurrence on a spectrally rescaled operator. This provides an explicit K-hop receptive field in a single layer (independently of the stalk dimension), with a trainable spectral response obtained as a convex mixture of K+1 orthogonal polynomial basis responses. PolyNSD enforces stability via convex mixtures, spectral rescaling, and residual/gated paths, reaching new state-of-the-art results on both homophilic and heterophilic benchmarks, inverting the Neural Sheaf Diffusion trend by obtaining these results with just diagonal restriction maps, decoupling performance from large stalk dimension, while reducing runtime and memory requirements.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多项式神经层扩散：一种基于谱滤波的细胞层方法</div>
<div class="mono" style="margin-top:8px">层神经网络为图结构配备了细胞层：一种几何结构，为节点和边分配局部向量空间（茎）和可学习的线性限制/传输映射，从而产生一种边感知的归纳偏置，处理异质性并限制过平滑。然而，常见的神经层扩散实现依赖于基于SVD的层归一化和密集的每边限制映射，这些方法随着茎维度的增加而扩展，需要频繁重建拉普拉斯算子，并产生脆弱的梯度。为了解决这些限制，我们引入了多项式神经层扩散（PolyNSD），这是一种新的层扩散方法，其传播算子是归一化层拉普拉斯算子的K阶多项式，通过在谱重缩放算子上稳定的三项递归进行评估。这在单层中提供了明确的K跳接收场（与茎维度无关），并通过K+1个正交多项式基响应的凸混合获得可训练的谱响应。PolyNSD通过凸混合、谱重缩放和残差/门控路径强制稳定，在同质和异质基准上达到新的最先进结果，逆转了神经层扩散的趋势，仅通过对角限制映射获得这些结果，将性能与大茎维度解耦，同时减少运行时间和内存需求。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve the limitations of existing Neural Sheaf Diffusion methods, which struggle with scalability and gradient stability due to reliance on SVD-based normalization and dense restriction maps. The authors propose a new approach called Polynomial Neural Sheaf Diffusion (PolyNSD), which utilizes a degree-K polynomial in a normalized sheaf Laplacian and employs a stable three-term recurrence for evaluation. Experimental results demonstrate that PolyNSD achieves state-of-the-art performance on both homophilic and heterophilic benchmarks, effectively using only diagonal restriction maps and significantly reducing runtime and memory requirements while maintaining stability and performance regardless of stalk dimension.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于现有神经层扩散方法的局限性，这些方法通常依赖于基于奇异值分解的归一化和稠密边限制映射，导致可扩展性问题和不稳定的梯度。作者提出了一种新方法，称为多项式神经层扩散（PolyNSD），该方法利用归一化层拉普拉斯算子的K阶多项式，并通过稳定的三项递归进行评估。实验结果表明，PolyNSD在同质和异质基准测试中均实现了最先进的性能，有效减少了运行时间和内存需求，同时在仅使用对角限制映射的情况下保持性能，与层的维度无关。</div>
</details>
</div>
<div class="card">
<div class="title">Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</div>
<div class="meta-line">Authors: Erfan Miahi, Eugene Belilovsky</div>
<div class="meta-line">First: 2026-02-03T18:56:48+00:00 · Latest: 2026-02-03T18:56:48+00:00</div>
<div class="meta-line">Comments: 32 pages, 14 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03839v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03839v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fraction of model parameters, these observations are typically based on coarse checkpoint differences. We present a systematic empirical study of weight-update sparsity at both step-level and multi-step granularities, examining its evolution across training dynamics, off-policy delay, and model scale. We find that update sparsity is consistently high, frequently exceeding 99% across practically relevant settings. Leveraging this structure, we propose PULSE (Patch Updates via Lossless Sparse Encoding), a simple yet highly efficient lossless weight synchronization method that transmits only the indices and values of modified parameters. PULSE is robust to transmission errors and avoids floating-point drift inherent in additive delta schemes. In bandwidth-constrained decentralized environments, our approach achieves over 100x (14 GB to ~108 MB) communication reduction while maintaining bit-identical training dynamics and performance compared to full weight synchronization. By exploiting this structure, PULSE enables decentralized RL training to approach centralized throughput, reducing the bandwidth required for weight synchronization from 20 Gbit/s to 0.2 Gbit/s to maintain high GPU utilization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>理解和利用权重更新稀疏性以实现通信高效的分布式强化学习</div>
<div class="mono" style="margin-top:8px">强化学习（RL）是后训练大型语言模型（LLMs）的关键组成部分。然而，在带宽受限的分布式RL中，扩展性通常受到从训练者到推理工作者的策略权重同步的瓶颈，特别是在普通网络或去中心化环境中。尽管最近的研究表明，RL更新仅修改模型参数的一小部分，但这些观察通常基于粗略的检查点差异。我们对权重更新稀疏性进行了系统的实证研究，涵盖了步骤级和多步骤粒度，考察了其在训练动态、离线策略延迟和模型规模中的演变。我们发现更新稀疏性始终很高，在实际相关的设置中经常超过99%。利用这一结构，我们提出了PULSE（通过无损稀疏编码的补丁更新），这是一种简单但高效的无损权重同步方法，仅传输修改参数的索引和值。PULSE对传输错误具有鲁棒性，避免了加法增量方案中固有的浮点漂移。在带宽受限的去中心化环境中，我们的方法实现了超过100倍（从14 GB减少到约108 MB）的通信减少，同时保持与完全权重同步相同的比特相同的训练动态和性能。通过利用这一结构，PULSE使去中心化RL训练接近集中式吞吐量，将权重同步所需的带宽从20 Gbit/s减少到0.2 Gbit/s，以保持高GPU利用率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the scalability issues in bandwidth-constrained distributed reinforcement learning (RL), particularly the synchronization of policy weights in large language models (LLMs). The authors conducted a systematic empirical study to analyze weight-update sparsity at both step-level and multi-step granularities, revealing that update sparsity often exceeds 99% across various training scenarios. To leverage this sparsity, they introduced PULSE (Patch Updates via Lossless Sparse Encoding), a communication-efficient method that transmits only the indices and values of modified parameters, achieving over 100x reduction in communication while maintaining identical training dynamics and performance compared to traditional full weight synchronization methods.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决带宽受限的分布式强化学习（RL）中的可扩展性问题，特别是在大型语言模型（LLMs）中策略权重的同步。作者进行了系统的实证研究，分析了在步骤级和多步骤粒度下的权重更新稀疏性，发现更新稀疏性在各种训练条件下通常超过99%。他们提出了PULSE，这是一种通信高效的方法，利用无损稀疏编码仅传输修改参数的索引和值，实现了通信需求超过100倍的减少，同时保持了训练动态和性能，从而显著降低了去中心化环境中权重同步所需的带宽。</div>
</details>
</div>
<div class="card">
<div class="title">MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE</div>
<div class="meta-line">Authors: Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong</div>
<div class="meta-line">First: 2025-07-29T13:40:09+00:00 · Latest: 2026-02-03T18:56:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.21802v4">Abs</a> · <a href="https://arxiv.org/pdf/2507.21802v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO and DanceGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose $\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of stochastic differential equations (SDE) and ordinary differential equations (ODE). This streamlines the optimization process within the MDP to improve efficiency and boost performance. Specifically, MixGRPO introduces a sliding window mechanism, using SDE sampling and GRPO-guided optimization only within the window, while applying ODE sampling outside. This design confines sampling randomness to the time-steps within the window, thereby reducing the optimization overhead, and allowing for more focused gradient updates to accelerate convergence. Additionally, as time-steps beyond the sliding window are not involved in optimization, higher-order solvers are supported for faster sampling. So we present a faster variant, termed $\textbf{MixGRPO-Flash}$, which further improves training efficiency while achieving comparable performance. MixGRPO exhibits substantial gains across multiple dimensions of human preference alignment, outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50% lower training time. Notably, MixGRPO-Flash further reduces training time by 71%.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MixGRPO：通过混合ODE-SDE解锁基于流的GRPO效率</div>
<div class="mono" style="margin-top:8px">尽管GRPO在图像生成的人类偏好对齐中显著增强了流匹配模型，但由于需要在马尔可夫决策过程（MDP）指定的所有去噪步骤上进行采样和优化，FlowGRPO和DanceGRPO等方法仍然表现出低效。本文提出了$\textbf{MixGRPO}$，一个新颖的框架，通过整合随机微分方程（SDE）和常微分方程（ODE）利用混合采样策略的灵活性。这简化了MDP中的优化过程，以提高效率和提升性能。具体而言，MixGRPO引入了滑动窗口机制，仅在窗口内使用SDE采样和GRPO引导的优化，而在外部应用ODE采样。该设计将采样随机性限制在窗口内的时间步，从而减少优化开销，并允许更集中地进行梯度更新以加速收敛。此外，由于滑动窗口之外的时间步不参与优化，因此支持更高阶的求解器以实现更快的采样。因此，我们提出了一个更快的变体，称为$\textbf{MixGRPO-Flash}$，在实现可比性能的同时进一步提高了训练效率。MixGRPO在多个维度的人类偏好对齐中表现出显著提升，在有效性和效率上均优于DanceGRPO，训练时间减少近50%。值得注意的是，MixGRPO-Flash进一步将训练时间减少了71%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the inefficiencies in existing flow matching models for human preference alignment in image generation, specifically those seen in FlowGRPO and DanceGRPO due to their reliance on extensive sampling and optimization processes. The authors propose MixGRPO, a framework that combines stochastic differential equations (SDE) and ordinary differential equations (ODE) to streamline the optimization process within the Markov Decision Process (MDP). The key experimental findings indicate that MixGRPO significantly enhances efficiency and performance, achieving nearly 50% lower training time compared to DanceGRPO, while MixGRPO-Flash further accelerates training by 71% without sacrificing performance.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决现有流匹配模型在图像生成中的人类偏好对齐效率低下的问题，特别是像FlowGRPO和DanceGRPO这样需要大量采样和优化的方法。作者提出了MixGRPO，一个结合随机微分方程（SDE）和常微分方程（ODE）的框架，以简化马尔可夫决策过程（MDP）中的优化过程。实验结果表明，MixGRPO显著提高了效率和性能，与DanceGRPO相比，训练时间减少近50%，而更快的变体MixGRPO-Flash则在不影响效果的情况下将训练时间减少了71%。</div>
</details>
</div>
<div class="card">
<div class="title">Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</div>
<div class="meta-line">Authors: David P. Woodruff, Vincent Cohen-Addad, Lalit Jain, Jieming Mao, Song Zuo, MohammadHossein Bateni, Simina Branzei, Michael P. Brenner, Lin Chen, Ying Feng, Lance Fortnow, Gang Fu, Ziyi Guan, Zahra Hadizadeh, Mohammad T. Hajiaghayi, Mahdi JafariRaviz, Adel Javanmard, Karthik C. S., Ken-ichi Kawarabayashi, Ravi Kumar, Silvio Lattanzi, Euiwoong Lee, Yi Li, Ioannis Panageas, Dimitris Paparas, Benjamin Przybocki, Bernardo Subercaseaux, Ola Svensson, Shayan Taherijam, Xuan Wu, Eylon Yogev, Morteza Zadimoghaddam, Samson Zhou, Vahab Mirrokni</div>
<div class="meta-line">First: 2026-02-03T18:56:17+00:00 · Latest: 2026-02-03T18:56:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03837v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03837v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google&#x27;s Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a &quot;neuro-symbolic&quot; loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用Gemini加速科学研究：案例研究与常见技术</div>
<div class="mono" style="margin-top:8px">最近大型语言模型（LLMs）的进展为加速科学研究开辟了新途径。尽管这些模型在协助日常任务方面越来越有能力，但它们在新颖的专家级数学发现中的贡献能力尚不清楚。我们展示了一系列案例研究，证明研究人员如何成功与先进的AI模型（特别是基于谷歌Gemini的模型，尤其是Gemini Deep Think及其高级变体）合作，解决开放问题、反驳猜想，并在理论计算机科学及经济学、优化和物理等其他领域生成新证明。基于这些经验，我们提取了有效的人机协作在理论研究中的常见技术，如迭代优化、问题分解和跨学科知识转移。尽管我们的大多数结果源于这种互动对话的方法论，但我们也强调了一些超越标准聊天界面的具体实例。这些实例包括将模型作为严格的对抗性审稿人，以检测现有证明中的微妙缺陷，以及将其嵌入“神经符号”循环中，自动编写和执行代码以验证复杂推导。这些例子共同突显了AI不仅作为自动化工具的潜力，更作为科学发现创造过程中的多功能、真实合作伙伴。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to explore how large language models (LLMs), particularly Google&#x27;s Gemini models, can enhance scientific research by contributing to expert-level mathematical discovery. The authors present case studies where researchers collaborated with Gemini models to address open problems, refute conjectures, and generate new proofs in fields such as theoretical computer science, economics, optimization, and physics. Key findings include effective techniques for human-AI collaboration, such as iterative refinement and problem decomposition, as well as innovative applications like using the model as an adversarial reviewer and in a neuro-symbolic loop for code verification, demonstrating the potential of AI as a creative partner in scientific discovery.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于探索大型语言模型（LLMs），特别是谷歌的Gemini模型，如何通过贡献于专家级数学发现来增强科学研究。作者展示了研究人员与这些AI模型合作的案例研究，以解决开放问题并在理论计算机科学、经济学、优化和物理等领域生成新证明。主要发现包括识别有效的人机协作技术，如迭代优化和问题分解，以及创新应用，如将模型用作对抗性审稿人和将其集成到神经符号循环中进行代码验证。</div>
</details>
</div>
<div class="card">
<div class="title">AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations</div>
<div class="meta-line">Authors: Minjun Zhu, Zhen Lin, Yixuan Weng, Panzhong Lu, Qiujie Xie, Yifan Wei, Sifan Liu, Qiyao Sun, Yue Zhang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-02-03T18:41:43+00:00 · Latest: 2026-02-03T18:41:43+00:00</div>
<div class="meta-line">Comments: Accepted at the ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03828v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03828v1">PDF</a> · <a href="https://github.com/ResearAI/AutoFigure">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AutoFigure：生成和完善出版准备的科学插图</div>
<div class="mono" style="margin-top:8px">高质量的科学插图对于有效传达复杂的科学和技术概念至关重要，但其手动创建仍然是学术界和工业界公认的瓶颈。我们提出了FigureBench，这是第一个用于从长篇科学文本生成科学插图的大规模基准。它包含3300对高质量的科学文本-插图对，涵盖来自科学论文、调查、博客和教科书的多样化文本到插图任务。此外，我们提出了AutoFigure，这是第一个基于长篇科学文本自动生成高质量科学插图的代理框架。具体而言，在渲染最终结果之前，AutoFigure进行广泛的思考、重组和验证，以生成结构合理且美观的布局，输出既具结构完整性又具美学吸引力的科学插图。利用FigureBench的高质量数据，我们进行了广泛的实验，以测试AutoFigure与各种基线方法的性能。结果表明，AutoFigure始终超越所有基线方法，生成出版准备的科学插图。代码、数据集和huggingface空间已发布在https://github.com/ResearAI/AutoFigure。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the bottleneck in the manual creation of high-quality scientific illustrations, which are essential for communicating complex concepts. The authors introduce FigureBench, a large-scale benchmark comprising 3,300 text-figure pairs from various scientific sources, and propose AutoFigure, an automated framework that generates refined scientific illustrations from long-form texts. Experimental results show that AutoFigure outperforms all baseline methods, consistently producing illustrations that are both structurally complete and aesthetically appealing, suitable for publication.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决高质量科学插图的手动创建瓶颈，这对于传达复杂的科学概念至关重要。作者介绍了FigureBench，这是一个包含3300对文本-插图的规模庞大的基准，并提出了AutoFigure，一个创新框架，能够从长篇文本中自动生成科学插图。实验结果表明，AutoFigure在所有基线方法中表现优异，持续生成结构完整且美观的插图，适合发表。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading</div>
<div class="meta-line">Authors: Hoang-Dung Bui, Erion Plaku, Gregoy J. Stein</div>
<div class="meta-line">First: 2025-01-06T05:21:18+00:00 · Latest: 2026-02-03T18:36:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.02770v5">Abs</a> · <a href="https://arxiv.org/pdf/2501.02770v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper proposes a novel planning framework to handle a multi-agent pathfinding problem under team-connected communication constraint, where all agents must have a connected communication channel to the rest of the team during their entire movements. Standard multi-agent path finding approaches (e.g., priority-based search) have potential in this domain but fail when neighboring configurations at start and goal differ. Their single-expansion approach -- computing each agent&#x27;s path from the start to the goal in just a single expansion -- cannot reliably handle planning under communication constraints for agents as their neighbors change during navigating. Similarly, leader-follower approaches (e.g., platooning) are effective at maintaining team communication, but fixing the leader at the outset of planning can cause planning to become stuck in dense-clutter environments, limiting their practical utility. To overcome this limitation, we propose a novel two-level multi-agent pathfinding framework that integrates two techniques: adaptive path expansion to expand agent paths to their goals in multiple stages; and dynamic leading technique that enables the reselection of the leading agent during each agent path expansion whenever progress cannot be made. Simulation experiments show the efficiency of our planners, which can handle up to 25 agents across five environment types under a limited communication range constraint and up to 11-12 agents on three environment types under line-of-sight communication constraint, exceeding 90% success-rate where baselines routinely fail.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在团队连接通信约束下的多智能体路径规划：自适应路径扩展与动态领导</div>
<div class="mono" style="margin-top:8px">本文提出了一种新颖的规划框架，以处理在团队连接通信约束下的多智能体路径规划问题，其中所有智能体在整个移动过程中必须与团队的其余部分保持连接的通信通道。标准的多智能体路径规划方法（例如基于优先级的搜索）在这一领域具有潜力，但在起始和目标的邻近配置不同的情况下失败。它们的单次扩展方法——仅通过一次扩展计算每个智能体从起点到目标的路径——无法可靠地处理在邻居变化时的通信约束规划。同样，领导-跟随方法（例如编队）在维护团队通信方面有效，但在规划开始时固定领导者可能导致规划在密集环境中陷入困境，限制了其实际效用。为克服这一限制，我们提出了一种新颖的两级多智能体路径规划框架，集成了两种技术：自适应路径扩展以分阶段扩展智能体路径到其目标；以及动态领导技术，在每次智能体路径扩展时，当无法取得进展时，允许重新选择领导智能体。仿真实验表明，我们的规划者效率高，能够在有限通信范围约束下处理多达25个智能体，涵盖五种环境类型，并在视线通信约束下处理多达11-12个智能体，在基线方法常常失败的情况下成功率超过90%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of multi-agent pathfinding under team-connected communication constraints, which is critical for ensuring that all agents maintain a connected communication channel during their movements. The authors propose a two-level planning framework that combines adaptive path expansion and dynamic leading techniques to overcome limitations of existing methods that struggle with varying neighbor configurations and fixed leadership in dense environments. Experimental results demonstrate that the proposed approach can efficiently manage up to 25 agents in various environments under limited communication constraints, achieving over 90% success rates where traditional methods typically fail.</div>
<div class="mono" style="margin-top:8px">本研究解决了在团队连接通信约束下的多智能体路径规划问题，要求智能体在整个移动过程中保持连接的通信通道。作者提出了一种两级规划框架，结合了自适应路径扩展（允许智能体分阶段导航）和动态领导技术（在复杂环境中避免卡住，能够重新选择领导智能体）。实验结果表明，该方法能够有效管理多达25个智能体在不同环境中的路径规划，并在类似条件下实现超过90%的成功率，显著优于传统方法。</div>
</details>
</div>
<div class="card">
<div class="title">ME-IGM: Individual-Global-Max in Maximum Entropy Multi-Agent Reinforcement Learning</div>
<div class="meta-line">Authors: Wen-Tse Chen, Yuxuan Li, Shiyu Huang, Jiayu Chen, Jeff Schneider</div>
<div class="meta-line">Venue: Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25 - 29, 2026, IFAAMAS, 19 pages</div>
<div class="meta-line">First: 2024-06-20T01:55:08+00:00 · Latest: 2026-02-03T18:35:29+00:00</div>
<div class="meta-line">Comments: Published in the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2406.13930v4">Abs</a> · <a href="https://arxiv.org/pdf/2406.13930v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent credit assignment is a fundamental challenge for cooperative multi-agent reinforcement learning (MARL), where a team of agents learn from shared reward signals. The Individual-Global-Max (IGM) condition is a widely used principle for multi-agent credit assignment, requiring that the joint action determined by individual Q-functions maximizes the global Q-value. Meanwhile, the principle of maximum entropy has been leveraged to enhance exploration in MARL. However, we identify a critical limitation in existing maximum entropy MARL methods: a misalignment arises between local policies and the joint policy that maximizes the global Q-value, leading to violations of the IGM condition. To address this misalignment, we propose an order-preserving transformation. Building on it, we introduce ME-IGM, a novel maximum entropy MARL algorithm compatible with any credit assignment mechanism that satisfies the IGM condition while enjoying the benefits of maximum entropy exploration. We empirically evaluate two variants of ME-IGM: ME-QMIX and ME-QPLEX, in non-monotonic matrix games, and demonstrate their state-of-the-art performance across 17 scenarios in SMAC-v2 and Overcooked.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ME-IGM：最大熵多智能体强化学习中的个体-全局-最大</div>
<div class="mono" style="margin-top:8px">多智能体信用分配是合作多智能体强化学习（MARL）中的一个基本挑战，其中一组智能体从共享的奖励信号中学习。个体-全局-最大（IGM）条件是多智能体信用分配中广泛使用的原则，要求由个体Q函数确定的联合行动最大化全局Q值。同时，最大熵原则被利用来增强MARL中的探索。然而，我们发现现有最大熵MARL方法存在一个关键限制：局部策略与最大化全局Q值的联合策略之间出现不一致，导致IGM条件的违反。为了解决这一不一致，我们提出了一种保持顺序的变换。在此基础上，我们引入了ME-IGM，一种新颖的最大熵MARL算法，兼容任何满足IGM条件的信用分配机制，同时享受最大熵探索的好处。我们在非单调矩阵游戏中对ME-IGM的两个变体：ME-QMIX和ME-QPLEX进行了实证评估，并展示了它们在SMAC-v2和Overcooked的17个场景中的最先进性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenge of multi-agent credit assignment in cooperative multi-agent reinforcement learning (MARL), particularly the misalignment between local policies and the joint policy that maximizes global Q-value. The authors propose a novel algorithm called ME-IGM, which incorporates an order-preserving transformation to align local and global policies while leveraging maximum entropy for enhanced exploration. Experimental results show that two variants of ME-IGM, ME-QMIX and ME-QPLEX, achieve state-of-the-art performance across 17 scenarios in non-monotonic matrix games, specifically in the SMAC-v2 and Overcooked environments.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决合作多智能体强化学习（MARL）中的多智能体信用分配挑战，特别是局部策略与最大化全局Q值的联合策略之间的错位。作者提出了一种新算法ME-IGM，采用顺序保持变换来对齐局部和全局策略，同时利用最大熵原则增强探索。实验结果表明，ME-IGM的两个变体ME-QMIX和ME-QPLEX在非单调矩阵游戏中的17个场景中表现出最先进的性能，包括SMAC-v2和Overcooked。</div>
</details>
</div>
<div class="card">
<div class="title">Continuous Control of Editing Models via Adaptive-Origin Guidance</div>
<div class="meta-line">Authors: Alon Wolf, Chen Katzir, Kfir Aberman, Or Patashnik</div>
<div class="meta-line">First: 2026-02-03T18:33:39+00:00 · Latest: 2026-02-03T18:33:39+00:00</div>
<div class="meta-line">Comments: Project page at https://adaor-paper.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03826v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03826v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://adaor-paper.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过自适应原点引导实现编辑模型的连续控制</div>
<div class="mono" style="margin-top:8px">基于扩散的编辑模型已成为语义图像和视频处理的强大工具。然而，现有模型缺乏平滑控制文本引导编辑强度的机制。在标准的文本条件生成中，无分类器引导（CFG）影响提示遵循，暗示其作为编辑模型中编辑强度的潜在控制。然而，我们表明在这些模型中缩放CFG并未产生输入与编辑结果之间的平滑过渡。我们将这种行为归因于无条件预测，它作为引导原点并在低引导尺度下主导生成，同时代表对输入内容的任意操控。为了实现连续控制，我们引入了自适应原点引导（AdaOr），该方法使用与身份操控相对应的身份指令调整标准引导原点。通过根据编辑强度将此身份预测与标准无条件预测进行插值，我们确保从输入到编辑结果的连续过渡。我们在图像和视频编辑任务上评估了我们的方法，证明其提供了比当前基于滑块的编辑方法更平滑和一致的控制。我们的方法将身份指令纳入标准训练框架，使得在推理时能够进行细粒度控制，而无需每次编辑程序或依赖专门的数据集。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the limitations of existing diffusion-based editing models, which struggle with smoothly controlling the intensity of text-guided edits. The authors propose a novel method called Adaptive-Origin Guidance (AdaOr), which modifies the standard guidance origin by incorporating an identity-conditioned adaptive origin. This approach allows for a continuous transition between the input and the edited result by interpolating identity predictions with unconditional predictions based on edit strength. Experimental results show that AdaOr provides smoother and more consistent control in image and video editing tasks compared to traditional slider-based methods.</div>
<div class="mono" style="margin-top:8px">本研究解决了现有扩散基础编辑模型在文本引导编辑强度控制方面的局限性。作者提出了一种新方法，称为自适应原点引导（AdaOr），该方法通过引入身份条件自适应原点来修改标准引导原点。该方法通过根据编辑强度插值身份预测与无条件预测，允许在原始和编辑图像或视频之间实现连续过渡。实验结果表明，AdaOr在图像和视频编辑任务中提供了比传统滑块方法更平滑和一致的控制。</div>
</details>
</div>
<div class="card">
<div class="title">Robust Intervention Learning from Emergency Stop Interventions</div>
<div class="meta-line">Authors: Ethan Pronovost, Khimya Khetarpal, Siddhartha Srinivasa</div>
<div class="meta-line">First: 2026-02-03T18:33:21+00:00 · Latest: 2026-02-03T18:33:21+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03825v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03825v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Human interventions are a common source of data in autonomous systems during testing. These interventions provide an important signal about where the current policy needs improvement, but are often noisy and incomplete. We define Robust Intervention Learning (RIL) as the problem of learning from intervention data while remaining robust to the quality and informativeness of the intervention signal. In the best case, interventions are precise and avoiding them is sufficient to solve the task, but in many realistic settings avoiding interventions is necessary but not sufficient for achieving good performance. We study robust intervention learning in the context of emergency stop interventions and propose Residual Intervention Fine-Tuning (RIFT), a residual fine-tuning algorithm that treats intervention feedback as an incomplete learning signal and explicitly combines it with a prior policy. By framing intervention learning as a fine-tuning problem, our approach leverages structure encoded in the prior policy to resolve ambiguity when intervention signals under-specify the task. We provide theoretical analysis characterizing conditions under which this formulation yields principled policy improvement, and identify regimes where intervention learning is expected to fail. Our experiments reveal that residual fine-tuning enables robust and consistent policy improvement across a range of intervention strategies and prior policy qualities, and highlight robust intervention learning as a promising direction for future work.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从紧急停止干预中学习的鲁棒干预学习</div>
<div class="mono" style="margin-top:8px">人类干预是在测试期间自主系统中常见的数据来源。这些干预提供了关于当前策略需要改进的地方的重要信号，但通常是嘈杂和不完整的。我们将鲁棒干预学习（RIL）定义为在干预数据中学习的问题，同时保持对干预信号的质量和信息量的鲁棒性。在最佳情况下，干预是精确的，避免干预足以解决任务，但在许多现实环境中，避免干预是必要的，但不足以实现良好的性能。我们在紧急停止干预的背景下研究鲁棒干预学习，并提出残差干预微调（RIFT），这是一种将干预反馈视为不完整学习信号的残差微调算法，并将其与先前策略显式结合。通过将干预学习框架化为微调问题，我们的方法利用先前策略中编码的结构来解决干预信号在任务下指定不足时的模糊性。我们提供了理论分析，表征在何种条件下该公式产生原则性的策略改进，并识别出干预学习预期失败的情况。我们的实验表明，残差微调能够在多种干预策略和先前策略质量下实现鲁棒和一致的策略改进，并强调鲁棒干预学习是未来工作的一个有前景的方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve learning from human interventions in autonomous systems, which often provide noisy and incomplete data. The authors propose a method called Residual Intervention Fine-Tuning (RIFT), which treats intervention feedback as an incomplete learning signal and combines it with a prior policy to enhance learning. Experimental results demonstrate that RIFT enables robust and consistent policy improvement across various intervention strategies and qualities of prior policies, suggesting that robust intervention learning is a viable avenue for future research.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于通过有效利用人类干预数据来改善自主系统的学习过程，而这些数据通常是嘈杂和不完整的。作者提出了一种名为残差干预微调（RIFT）的方法，该方法将干预反馈视为不完整的学习信号，并与先前的策略相结合，以增强学习效果。实验结果表明，RIFT在各种干预策略和先前策略质量下促进了稳健和一致的策略改进，表明稳健干预学习可能是该领域未来研究的有价值方法。</div>
</details>
</div>
<div class="card">
<div class="title">Deep-learning-based pan-phenomic data reveals the explosive evolution of avian visual disparity</div>
<div class="meta-line">Authors: Jiao Sun</div>
<div class="meta-line">First: 2026-02-03T18:32:15+00:00 · Latest: 2026-02-03T18:32:15+00:00</div>
<div class="meta-line">Comments: Readers from the field of computer science may be interested in section 2.1, 2.2, 3.1, 4.1, 4.2. These sections discussed the interpretability and representation learning, especially the texture vs shape problem, highlighting our model&#x27;s ability of overcoming the texture biases and capturing overall shape features. (Although they&#x27;re put here to prove the biological validity of the model.)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03824v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03824v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The evolution of biological morphology is critical for understanding the diversity of the natural world, yet traditional analyses often involve subjective biases in the selection and coding of morphological traits. This study employs deep learning techniques, utilising a ResNet34 model capable of recognising over 10,000 bird species, to explore avian morphological evolution. We extract weights from the model&#x27;s final fully connected (fc) layer and investigate the semantic alignment between the high-dimensional embedding space learned by the model and biological phenotypes. The results demonstrate that the high-dimensional embedding space encodes phenotypic convergence. Subsequently, we assess the morphological disparity among various taxa and evaluate the association between morphological disparity and species richness, demonstrating that species richness is the primary driver of morphospace expansion. Moreover, the disparity-through-time analysis reveals a visual &quot;early burst&quot; after the K-Pg extinction.
  While mainly aimed at evolutionary analysis, this study also provides insights into the interpretability of Deep Neural Networks. We demonstrate that hierarchical semantic structures (biological taxonomy) emerged in the high-dimensional embedding space despite being trained on flat labels. Furthermore, through adversarial examples, we provide evidence that our model in this task can overcome texture bias and learn holistic shape representations (body plans), challenging the prevailing view that CNNs rely primarily on local textures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于深度学习的全表型数据揭示鸟类视觉差异的爆炸性演化</div>
<div class="mono" style="margin-top:8px">生物形态的演化对于理解自然界的多样性至关重要，但传统分析往往涉及在选择和编码形态特征时的主观偏见。本研究采用深度学习技术，利用能够识别超过10,000种鸟类的ResNet34模型，探索鸟类形态演化。我们从模型的最终全连接层提取权重，并研究模型学习的高维嵌入空间与生物表型之间的语义对齐。结果表明，高维嵌入空间编码了表型收敛。随后，我们评估了不同分类群之间的形态差异，并评估了形态差异与物种丰富度之间的关联，证明物种丰富度是形态空间扩展的主要驱动因素。此外，时间上的差异分析揭示了K-Pg灭绝后视觉上的“早期爆发”。虽然主要针对进化分析，本研究还提供了对深度神经网络可解释性的见解。我们证明了尽管在平面标签上训练，但高维嵌入空间中出现了层次语义结构（生物分类）。此外，通过对抗样本，我们提供了证据表明我们的模型在此任务中能够克服纹理偏见并学习整体形状表示（体型规划），挑战了CNN主要依赖局部纹理的普遍观点。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the evolution of avian morphology to address biases in traditional analyses of biological traits. Utilizing a ResNet34 deep learning model that recognizes over 10,000 bird species, the researchers extract weights from the model&#x27;s final layer to analyze the relationship between high-dimensional embeddings and biological phenotypes. The findings indicate that the embedding space reflects phenotypic convergence, with species richness identified as a key factor driving morphospace expansion, and an &#x27;early burst&#x27; of visual disparity observed following the K-Pg extinction event. Additionally, the study highlights the model&#x27;s ability to learn holistic shape representations, challenging existing notions about texture bias in CNNs.</div>
<div class="mono" style="margin-top:8px">本研究利用深度学习探讨鸟类形态演化，以解决传统生物特征分析中的偏见。研究人员采用能够识别超过10,000种鸟类的ResNet34模型，从模型的最终层提取权重，以分析学习到的高维嵌入空间与生物表型之间的关系。研究结果表明，该嵌入空间捕捉了表型收敛，并揭示物种丰富度显著推动形态空间扩展，且在K-Pg灭绝后，形态差异出现了显著的视觉“早期爆发”，同时提供了对深度神经网络可解释性的见解，表明尽管在平面标签上训练，学习到的表示中仍然出现了层次结构。</div>
</details>
</div>
<div class="card">
<div class="title">Preference-based Conditional Treatment Effects and Policy Learning</div>
<div class="meta-line">Authors: Dovid Parnas, Mathieu Even, Julie Josse, Uri Shalit</div>
<div class="meta-line">First: 2026-02-03T18:31:26+00:00 · Latest: 2026-02-03T18:31:26+00:00</div>
<div class="meta-line">Comments: Accepted to AISTATS 2026; 10 pages + appendix</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03823v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03823v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce a new preference-based framework for conditional treatment effect estimation and policy learning, built on the Conditional Preference-based Treatment Effect (CPTE). CPTE requires only that outcomes be ranked under a preference rule, unlocking flexible modeling of heterogeneous effects with multivariate, ordinal, or preference-driven outcomes. This unifies applications such as conditional probability of necessity and sufficiency, conditional Win Ratio, and Generalized Pairwise Comparisons. Despite the intrinsic non-identifiability of comparison-based estimands, CPTE provides interpretable targets and delivers new identifiability conditions for previous unidentifiable estimands. We present estimation strategies via matching, quantile, and distributional regression, and further design efficient influence-function estimators to correct plug-in bias and maximize policy value. Synthetic and semi-synthetic experiments demonstrate clear performance gains and practical impact.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于偏好的条件处理效应与政策学习</div>
<div class="mono" style="margin-top:8px">我们引入了一种新的基于偏好的框架，用于条件处理效应估计和政策学习，基于条件偏好处理效应（CPTE）。CPTE 仅要求在偏好规则下对结果进行排序，从而解锁对异质效应的灵活建模，适用于多变量、有序或基于偏好的结果。这统一了诸如必要性和充分性的条件概率、条件胜率和广义成对比较等应用。尽管基于比较的估计量本质上是不可识别的，CPTE 提供了可解释的目标，并为以前不可识别的估计量提供了新的可识别性条件。我们通过匹配、分位数和分布回归提出了估计策略，并进一步设计了高效的影响函数估计器，以纠正插件偏差并最大化政策价值。合成和半合成实验展示了明显的性能提升和实际影响。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for a flexible framework to estimate conditional treatment effects and inform policy learning, particularly when dealing with heterogeneous outcomes. The authors introduce the Conditional Preference-based Treatment Effect (CPTE), which allows for ranking outcomes under a preference rule and unifies various applications in treatment effect estimation. Key experimental results show that CPTE not only provides interpretable targets and new identifiability conditions for previously unidentifiable estimands but also demonstrates significant performance improvements through synthetic and semi-synthetic experiments using matching, quantile, and distributional regression methods, along with efficient influence-function estimators to enhance policy value.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于需要一个灵活的框架来估计条件处理效应并指导政策学习，特别是在处理异质效应和基于偏好的结果时。作者提出了条件偏好处理效应（CPTE）框架，该框架允许在偏好规则下对结果进行排序，并为先前不可识别的估计量提供新的可识别性条件。来自合成和半合成数据的实验结果表明，所提出的方法，包括匹配、分位数和分布回归，显著提高了性能，并在政策价值最大化方面具有实际意义。</div>
</details>
</div>
<div class="card">
<div class="title">Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion</div>
<div class="meta-line">Authors: Oscar Ovanger, Levi Harris, Timothy H. Keitt</div>
<div class="meta-line">First: 2026-02-03T18:21:13+00:00 · Latest: 2026-02-03T18:21:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03817v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03817v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Many machine learning systems have access to multiple sources of evidence for the same prediction target, yet these sources often differ in reliability and informativeness across inputs. In bioacoustic classification, species identity may be inferred both from the acoustic signal and from spatiotemporal context such as location and season; while Bayesian inference motivates multiplicative evidence combination, in practice we typically only have access to discriminative predictors rather than calibrated generative models. We introduce \textbf{F}usion under \textbf{IN}dependent \textbf{C}onditional \textbf{H}ypotheses (\textbf{FINCH}), an adaptive log-linear evidence fusion framework that integrates a pre-trained audio classifier with a structured spatiotemporal predictor. FINCH learns a per-sample gating function that estimates the reliability of contextual information from uncertainty and informativeness statistics. The resulting fusion family \emph{contains} the audio-only classifier as a special case and explicitly bounds the influence of contextual evidence, yielding a risk-contained hypothesis class with an interpretable audio-only fallback. Across benchmarks, FINCH consistently outperforms fixed-weight fusion and audio-only baselines, improving robustness and error trade-offs even when contextual information is weak in isolation. We achieve state-of-the-art performance on CBI and competitive or improved performance on several subsets of BirdSet using a lightweight, interpretable, evidence-based approach. Code is available: \texttt{\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md}{anonymous-repository}}</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>音频时空融合的自适应证据加权</div>
<div class="mono" style="margin-top:8px">许多机器学习系统可以访问多个证据来源以预测同一目标，但这些来源在输入间的可靠性和信息量上往往存在差异。在生物声学分类中，物种身份可以通过声学信号和时空上下文（如位置和季节）推断；虽然贝叶斯推断激励了乘法证据组合，但在实践中我们通常只能访问判别预测器，而不是经过校准的生成模型。我们引入了独立条件假设下的融合（FINCH），这是一个自适应对数线性证据融合框架，整合了预训练的音频分类器和结构化的时空预测器。FINCH学习每个样本的门控函数，估计上下文信息的可靠性，基于不确定性和信息量统计。最终的融合家族包含音频单一分类器作为特例，并明确限制上下文证据的影响，从而产生一个风险受限的假设类，具有可解释的音频单一回退。在基准测试中，FINCH始终优于固定权重融合和音频单一基线，即使在上下文信息孤立时较弱，也提高了鲁棒性和错误权衡。我们在CBI上实现了最先进的性能，并在BirdSet的多个子集上实现了竞争性或改进的性能，采用轻量级、可解释的基于证据的方法。代码可用：匿名仓库</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve the reliability and informativeness of evidence sources in bioacoustic classification, where species identity can be inferred from both acoustic signals and spatiotemporal context. The authors propose a novel framework called Fusion under Independent Conditional Hypotheses (FINCH), which combines a pre-trained audio classifier with a structured spatiotemporal predictor using an adaptive log-linear evidence fusion method. Experimental results demonstrate that FINCH outperforms fixed-weight fusion and audio-only baselines across various benchmarks, achieving state-of-the-art performance on the CBI dataset and competitive results on subsets of BirdSet, while maintaining robustness even with weak contextual information.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高生物声学分类中预测的可靠性和信息量，其中多个证据源（如声学信号和时空上下文）在有效性上可能存在差异。作者提出了一种新颖的框架，称为独立条件假设下的融合（FINCH），该框架使用自适应对数线性证据融合方法，将预训练的音频分类器与结构化的时空预测器结合起来。实验结果表明，FINCH在多个基准测试中始终优于传统的固定权重融合和仅音频分类器，在CBI数据集上实现了最先进的性能，并在BirdSet的多个子集上取得了竞争性结果，从而增强了鲁棒性和错误管理，即使在上下文信息较弱时也能有效工作。</div>
</details>
</div>
<div class="card">
<div class="title">SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving</div>
<div class="meta-line">Authors: Yesom Park, Annie C. Lu, Shao-Ching Huang, Qiyang Hu, Y. Sungtaek Ju, Stanley Osher</div>
<div class="meta-line">First: 2026-02-03T18:18:30+00:00 · Latest: 2026-02-03T18:18:30+00:00</div>
<div class="meta-line">Comments: 27 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03816v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03816v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer that models hierarchical symbolic dependencies via tree-relative self-attention and enforces syntactic validity through grammar-constrained autoregressive decoding, overcoming the limited expressivity of sequence-based generators. Unlike numerical and neural approaches that approximate solutions in discretized or implicit function spaces, SymPlex operates directly in symbolic expression space, enabling interpretable and human-readable solutions that naturally represent non-smooth behavior and explicit parametric dependence. Empirical results demonstrate exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SymPlex：一种结构感知的变换器用于符号偏微分方程求解</div>
<div class="mono" style="margin-top:8px">我们提出了SymPlex，一个强化学习框架，用于发现偏微分方程（PDE）的解析符号解，而无需访问真实表达式。SymPlex将符号PDE求解形式化为树结构决策，并仅使用PDE及其边界条件优化候选解。其核心是SymFormer，一种结构感知的变换器，通过树相对自注意力建模层次符号依赖，并通过语法约束的自回归解码强制语法有效性，克服了基于序列的生成器的有限表达能力。与在离散或隐式函数空间中近似解的数值和神经方法不同，SymPlex直接在符号表达空间中操作，使得可解释和人类可读的解自然表示非光滑行为和显式参数依赖。实证结果表明，使用基于深度学习的符号方法可以精确恢复非光滑和参数PDE解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research motivation behind this study is to develop a method for discovering analytical symbolic solutions to partial differential equations (PDEs) without relying on ground-truth expressions. The authors introduce SymPlex, a reinforcement learning framework that treats symbolic PDE solving as a tree-structured decision-making problem, utilizing a structure-aware Transformer called SymFormer to model hierarchical symbolic dependencies and ensure syntactic validity. Experimental results show that SymPlex can exactly recover non-smooth and parametric PDE solutions, demonstrating its effectiveness compared to traditional numerical and neural approaches that operate in discretized or implicit function spaces.</div>
<div class="mono" style="margin-top:8px">本研究的动机是开发一种方法，以在不依赖真实表达式的情况下发现偏微分方程（PDE）的解析符号解。作者提出了SymPlex，这是一种强化学习框架，将符号PDE求解视为树结构决策问题，利用一种名为SymFormer的结构感知变换器，仅基于PDE及其边界条件来优化候选解。实验结果表明，SymPlex能够精确恢复非光滑和参数化的PDE解，证明其相较于在离散或隐式函数空间中操作的数值和神经方法的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning</div>
<div class="meta-line">Authors: Dingkun Zhang, Shuhan Qi, Yulin Wu, Xinyu Xiao, Xuan Wang, Long Chen</div>
<div class="meta-line">First: 2026-02-03T18:18:11+00:00 · Latest: 2026-02-03T18:18:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03815v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03815v1">PDF</a> · <a href="https://github.com/dingkun-zhang/DualSpeed">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model&#x27;s behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过视觉标记修剪实现多模态大语言模型的快速-慢速高效训练</div>
<div class="mono" style="margin-top:8px">多模态大语言模型（MLLMs）面临严重的训练效率问题，这与其庞大的模型规模和视觉标记数量有关。现有的高效训练工作主要集中在减少模型规模或可训练参数。受到视觉标记修剪（VTP）在提高推理效率方面成功的启发，我们正在探索通过减少视觉标记来实现高效训练的另一个重要研究方向。然而，在训练阶段应用VTP会导致训练与推理不匹配：修剪训练的模型在非修剪的完整视觉标记序列上推理表现不佳。为了解决这一问题，我们提出了DualSpeed，一个用于MLLMs高效训练的快-慢框架。快模式是主要模式，结合现有的VTP方法作为插件以减少视觉标记，并配备模式隔离器以隔离模型的行为。慢模式是辅助模式，模型在完整视觉序列上进行训练，以保持训练与推理的一致性。为了提升其训练效果，慢模式进一步利用自蒸馏从充分训练的快模式中学习。通过结合，DualSpeed可以实现训练效率和性能不下降。实验表明，DualSpeed将LLaVA-1.5的训练加速了2.1$\times$，将LLaVA-NeXT的训练加速了4.0$\times$，并保持了超过99%的性能。代码：https://github.com/dingkun-zhang/DualSpeed</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the training inefficiency of Multimodal Large Language Models (MLLMs) caused by their large model sizes and the number of visual tokens. The authors propose a method called DualSpeed, which consists of a fast-slow framework that integrates Visual Token Pruning (VTP) to reduce visual tokens during training while maintaining consistency with inference. Experimental results demonstrate that DualSpeed significantly accelerates the training process, achieving a 2.1x speedup for LLaVA-1.5 and a 4.0x speedup for LLaVA-NeXT, while preserving over 99% of the model&#x27;s performance.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决多模态大型语言模型（MLLMs）因模型规模和视觉标记数量庞大而导致的训练低效问题。作者提出了一种新方法DualSpeed，该方法结合了视觉标记修剪（VTP）和模式隔离器，构建了一个快慢框架，以提高训练效率，同时保持训练和推理之间的一致性。实验结果表明，DualSpeed显著加快了训练过程，LLaVA-1.5的训练速度提高了2.1倍，LLaVA-NeXT的训练速度提高了4.0倍，同时保持了超过99%的模型性能。</div>
</details>
</div>
<div class="card">
<div class="title">Conformal Thinking: Risk Control for Reasoning on a Compute Budget</div>
<div class="meta-line">Authors: Xi Wang, Anushri Suresh, Alvin Zhang, Rishi More, William Jurayj, Benjamin Van Durme, Mehrdad Farajtabar, Daniel Khashabi, Eric Nalisnick</div>
<div class="meta-line">First: 2026-02-03T18:17:22+00:00 · Latest: 2026-02-03T18:17:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03814v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03814v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>符合思维：计算预算下的风险控制推理</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）使得测试时的扩展成为可能，随着令牌预算的增加，数据集级别的准确性提高，这激励了自适应推理——在提高可靠性时花费令牌，并在额外计算不太可能有帮助时提前停止。然而，设置令牌预算以及自适应推理的阈值是一个实际挑战，涉及基本的风险-准确性权衡。我们将预算设置问题重新框定为风险控制，限制错误率，同时最小化计算。我们的框架引入了一个上限阈值，当模型有信心时停止推理（冒着输出不正确的风险），以及一个新颖的参数下限阈值，预先停止无法解决的实例（冒着过早停止的风险）。给定目标风险和验证集，我们使用无分布风险控制来最优地指定这些停止机制。对于具有多个预算控制标准的场景，我们结合效率损失以选择最具计算效率的退出机制。跨多种推理任务和模型的实证结果证明了我们风险控制方法的有效性，展示了通过下限阈值和集成停止机制获得的计算效率提升，同时遵循用户指定的风险目标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to address the challenges of setting token budgets and thresholds for adaptive reasoning in Large Language Models (LLMs), which can improve accuracy but also involve a risk-accuracy trade-off. The authors propose a framework that reframes the budget setting problem as risk control, introducing upper and lower thresholds to manage reasoning processes based on model confidence and the likelihood of solving instances. Experimental results show that this risk control approach enhances computational efficiency across various reasoning tasks and models, effectively balancing the trade-off between risk and computation while meeting user-defined risk targets.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于通过解决设置令牌预算和自适应推理阈值的挑战，来提高大型语言模型（LLMs）推理的效率，这涉及风险与准确性之间的权衡。作者提出了一种风险控制框架，引入了基于模型置信度和解决实例的可能性分别停止推理的上限和下限阈值。各种推理任务的实验证明，该方法有效提高了计算效率，同时保持了所需的风险水平，特别是通过使用下限阈值和集成停止机制。</div>
</details>
</div>
<div class="card">
<div class="title">Antidistillation Fingerprinting</div>
<div class="meta-line">Authors: Yixuan Even Xu, John Kirchenbauer, Yash Savani, Asher Trockman, Alexander Robey, Tom Goldstein, Fei Fang, J. Zico Kolter</div>
<div class="meta-line">First: 2026-02-03T18:15:50+00:00 · Latest: 2026-02-03T18:15:50+00:00</div>
<div class="meta-line">Comments: 26 pages, 11 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03812v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03812v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Model distillation enables efficient emulation of frontier large language models (LLMs), creating a need for robust mechanisms to detect when a third-party student model has trained on a teacher model&#x27;s outputs. However, existing fingerprinting techniques that could be used to detect such distillation rely on heuristic perturbations that impose a steep trade-off between generation quality and fingerprinting strength, often requiring significant degradation of utility to ensure the fingerprint is effectively internalized by the student. We introduce antidistillation fingerprinting (ADFP), a principled approach that aligns the fingerprinting objective with the student&#x27;s learning dynamics. Building upon the gradient-based framework of antidistillation sampling, ADFP utilizes a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint in the student after fine-tuning, rather than relying on the incidental absorption of the un-targeted biases of a more naive watermark. Experiments on GSM8K and OASST1 benchmarks demonstrate that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, yielding stronger detection confidence with minimal impact on utility, even when the student model&#x27;s architecture is unknown.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>反蒸馏指纹识别</div>
<div class="mono" style="margin-top:8px">模型蒸馏使得高效模拟前沿大型语言模型（LLMs）成为可能，这就需要强大的机制来检测第三方学生模型是否在教师模型的输出上进行了训练。然而，现有的指纹识别技术依赖于启发式扰动，这在生成质量和指纹强度之间存在陡峭的权衡，通常需要显著降低效用以确保指纹被学生有效内化。我们提出了反蒸馏指纹识别（ADFP），这是一种将指纹识别目标与学生学习动态对齐的原则性方法。基于反蒸馏采样的梯度框架，ADFP利用代理模型识别和采样直接最大化学生在微调后指纹预期可检测性的标记，而不是依赖于更简单水印的无目标偏差的偶然吸收。在GSM8K和OASST1基准上的实验表明，ADFP在最先进的基线中实现了显著的帕累托改进，在效用影响最小的情况下，提供了更强的检测信心，即使学生模型的架构未知。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to develop effective methods for detecting when a student model has been trained on the outputs of a teacher model, particularly in the context of model distillation for large language models. The authors propose a novel approach called antidistillation fingerprinting (ADFP), which aligns the fingerprinting objective with the learning dynamics of the student model, utilizing a proxy model to sample tokens that enhance the detectability of the fingerprint. Experimental results on the GSM8K and OASST1 benchmarks show that ADFP significantly outperforms existing techniques, achieving stronger detection confidence with minimal degradation of the model&#x27;s utility, even when the architecture of the student model is not known.</div>
<div class="mono" style="margin-top:8px">本研究的动机是开发有效的方法来检测学生模型是否在教师模型的输出上进行训练，这在模型蒸馏的背景下对于维护大型语言模型的完整性至关重要。作者提出了一种新方法，称为抗蒸馏指纹（ADFP），该方法通过使用代理模型采样增强指纹可检测性的标记，将指纹目标与学生模型的学习动态对齐。对GSM8K和OASST1基准的实验结果表明，ADFP显著优于现有技术，在模型效用下降最小的情况下提供更强的检测信心，即使学生模型的架构未知。</div>
</details>
</div>
<div class="card">
<div class="title">Progressive Checkerboards for Autoregressive Multiscale Image Generation</div>
<div class="meta-line">Authors: David Eigen</div>
<div class="meta-line">First: 2026-02-03T18:15:27+00:00 · Latest: 2026-02-03T18:15:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03811v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03811v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A key challenge in autoregressive image generation is to efficiently sample independent locations in parallel, while still modeling mutual dependencies with serial conditioning. Some recent works have addressed this by conditioning between scales in a multiscale pyramid. Others have looked at parallelizing samples in a single image using regular partitions or randomized orders. In this work we examine a flexible, fixed ordering based on progressive checkerboards for multiscale autoregressive image generation. Our ordering draws samples in parallel from evenly spaced regions at each scale, maintaining full balance in all levels of a quadtree subdivision at each step. This enables effective conditioning both between and within scales. Intriguingly, we find evidence that in our balanced setting, a wide range of scale-up factors lead to similar results, so long as the total number of serial steps is constant. On class-conditional ImageNet, our method achieves competitive performance compared to recent state-of-the-art autoregressive systems with like model capacity, using fewer sampling steps.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>自回归多尺度图像生成的渐进棋盘</div>
<div class="mono" style="margin-top:8px">自回归图像生成中的一个关键挑战是高效地并行采样独立位置，同时仍然通过串行条件建模相互依赖关系。一些近期的工作通过在多尺度金字塔中进行尺度间的条件处理来解决这个问题。其他研究则关注于使用规则分区或随机顺序在单个图像中并行化样本。在本研究中，我们考察了一种基于渐进棋盘的灵活固定排序，用于多尺度自回归图像生成。我们的排序在每个尺度上从均匀间隔的区域并行抽样，保持在每一步的四叉树细分的所有层级中的完全平衡。这使得在尺度之间和尺度内部的有效条件处理成为可能。有趣的是，我们发现，在我们的平衡设置中，只要串行步骤的总数保持不变，广泛的放大因子会导致类似的结果。在类条件的ImageNet上，我们的方法在与近期最先进的自回归系统（具有相似模型容量）相比时，使用更少的采样步骤实现了具有竞争力的性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenge of efficiently sampling independent locations in parallel while maintaining mutual dependencies in autoregressive image generation. The authors propose a method utilizing progressive checkerboards for multiscale autoregressive image generation, which allows for parallel sampling from evenly spaced regions at each scale while ensuring balanced quadtree subdivisions. The key experimental findings indicate that this balanced approach yields competitive performance on class-conditional ImageNet, achieving results comparable to state-of-the-art autoregressive systems with similar model capacity, but requiring fewer sampling steps.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决自回归图像生成中有效并行采样独立位置的挑战，同时建模相互依赖关系。作者提出了一种基于渐进棋盘的固定顺序的方法，用于多尺度自回归图像生成，允许在每个尺度上从均匀间隔的区域进行并行采样，同时保持四叉树细分的平衡。实验结果表明，该方法在条件分类的ImageNet上实现了与最新自回归系统相当的竞争性能，同时需要更少的采样步骤，并且显示出只要总的串行步骤数保持不变，各种尺度放大因子会产生相似的结果。</div>
</details>
</div>
<div class="card">
<div class="title">Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network</div>
<div class="meta-line">Authors: Abdul Joseph Fofanah, Lian Wen, David Chen, Shaoyang Zhang</div>
<div class="meta-line">First: 2026-02-03T18:10:40+00:00 · Latest: 2026-02-03T18:10:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03808v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03808v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model&#x27;s step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过课程引导特征学习和三阶段注意力网络增强不平衡节点分类</div>
<div class="mono" style="margin-top:8px">图神经网络（GNNs）中的不平衡节点分类发生在某些标签远比其他标签更常见时，这导致模型学习不公平，并在不常见类别上表现不佳。为了解决这个问题，我们提出了一种课程引导特征学习和三阶段注意力网络（CL3AN-GNN），该学习网络使用类似于人类学习的三步注意力系统（参与、实施、嵌入）。模型首先与结构上更简单的特征进行交互，这些特征定义为（1）局部邻域模式（1-hop），（2）低度节点属性，以及（3）通过初始图卷积网络和图注意力网络（GCN和GAT）嵌入识别的类可分节点对。这个基础使得尽管标签偏斜，早期学习仍然稳定。实施阶段随后解决复杂方面：（1）需要多步的连接，（2）连接不同类型节点的边，以及（3）位于少数类边缘的节点，使用可调的注意力权重。最后，嵌入通过迭代消息传递和课程对齐的损失加权来巩固这些特征。我们在八个开放图基准数据集上评估CL3AN-GNN，这些数据集涵盖社交、生命科学和引用网络。实验显示，在所有数据集上，准确性、F1分数和AUC均比最近的最先进方法有一致的提升。模型的逐步方法在不同类型的图数据集上表现良好，显示出比一次性训练更快的结果，对新的不平衡图表现更好，并通过梯度稳定性和注意力相关学习曲线清晰解释每一步。该工作为GNN中的课程学习提供了理论基础框架，并通过指标、收敛速度和泛化测试验证了其对不平衡的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of imbalanced node classification in graph neural networks, where certain labels dominate and lead to poor performance on less common classes. The proposed method, Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), employs a structured three-step attention system that mimics human learning by first focusing on simpler features before tackling more complex connections. Experimental results across eight Open Graph Benchmark datasets demonstrate that CL3AN-GNN consistently outperforms recent state-of-the-art methods in accuracy, F1-score, and AUC, while also providing faster convergence and clearer interpretability of the learning process.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决图神经网络中节点分类不平衡的问题，即某些标签占主导地位，导致对不常见类别的性能较差。作者提出了一种新模型，称为课程引导特征学习和三阶段注意力网络（CL3AN-GNN），该模型采用模仿人类学习的结构化三步注意力机制。实验结果表明，CL3AN-GNN在八个开放图基准数据集上始终优于最新的技术，显示出准确性、F1分数和AUC的改善，同时通过梯度稳定性和注意力相关学习曲线提供更快的收敛速度和更清晰的学习过程可解释性。</div>
</details>
</div>
<div class="card">
<div class="title">Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation</div>
<div class="meta-line">Authors: Ziru Chen, Dongdong Chen, Ruinan Jin, Yingbin Liang, Yujia Xie, Huan Sun</div>
<div class="meta-line">First: 2026-02-03T18:08:41+00:00 · Latest: 2026-02-03T18:08:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03806v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03806v1">PDF</a> · <a href="https://github.com/OSU-NLP-Group/cobalt">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs&#x27; in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在线与离线强化学习的桥梁：多轮代码生成的上下文赌博学习</div>
<div class="mono" style="margin-top:8px">最近，针对在现实任务上使用强化学习（RL）训练大型语言模型（LLM）的研究兴趣显著增加，例如多轮代码生成。尽管在线RL的表现通常优于离线RL，但其更高的训练成本和不稳定性阻碍了广泛应用。本文基于多轮代码生成可以被表述为一步可恢复的马尔可夫决策过程的观察，提出了结合在线和离线RL优点的上下文赌博学习方法（Cobalt）。Cobalt首先使用参考LLM收集代码生成轨迹，并将其划分为部分轨迹作为上下文提示。然后，在在线赌博学习过程中，LLM通过单步代码生成来完成每个部分轨迹提示。Cobalt在基于GRPO和VeRPO的两个多轮在线RL基准上表现优于，并在LiveCodeBench上将R1-Distill 8B和Qwen3 8B的绝对Pass@1分数分别提高了最多9.0和6.2。此外，我们分析了LLM的上下文奖励黑客行为，并通过扰动轨迹增强Cobalt训练以缓解此问题。总体而言，我们的结果表明Cobalt是多轮代码生成等迭代决策任务的有前景的解决方案。我们的代码和数据可在https://github.com/OSU-NLP-Group/cobalt获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve the training of large language models (LLMs) for multi-turn code generation by addressing the limitations of online and offline reinforcement learning (RL). The authors propose a new method called contextual bandit learning with offline trajectories (Cobalt), which formulates multi-turn code generation as a one-step recoverable Markov decision process. Experimental results show that Cobalt significantly outperforms two multi-turn online RL baselines, achieving improvements of up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench for R1-Distill 8B and Qwen3 8B models, respectively, while also addressing in-context reward hacking through the use of perturbed trajectories.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于通过解决在线和离线强化学习（RL）的局限性，提升大语言模型（LLM）在多轮代码生成中的训练效果。作者提出了一种新方法，称为基于离线轨迹的上下文赌博学习（Cobalt），将多轮代码生成公式化为一步可恢复的马尔可夫决策过程。实验结果表明，Cobalt显著优于两个多轮在线RL基线，在LiveCodeBench上R1-Distill 8B和Qwen3 8B的绝对Pass@1分数分别提高了最多9.0和6.2，同时通过轨迹扰动解决了上下文奖励黑客行为的问题。</div>
</details>
</div>
<div class="card">
<div class="title">Measuring Agents in Production</div>
<div class="meta-line">Authors: Melissa Z. Pan, Negar Arabzadeh, Riccardo Cogo, Yuxuan Zhu, Alexander Xiong, Lakshya A Agrawal, Huanzhi Mao, Emma Shen, Sid Pallerla, Liana Patel, Shu Liu, Tianneng Shi, Xiaoyuan Liu, Jared Quincy Davis, Emmanuele Lacavalla, Alessandro Basile, Shuyi Yang, Paul Castro, Daniel Kang, Joseph E. Gonzalez, Koushik Sen, Dawn Song, Ion Stoica, Matei Zaharia, Marquita Ellis</div>
<div class="meta-line">First: 2025-12-02T16:45:10+00:00 · Latest: 2026-02-03T18:06:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.04123v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.04123v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agents already operate in production across many industries, yet we lack an understanding of what technical methods make deployments successful. We present the first systematic study of Measuring Agents in Production, MAP, using first-hand data from agent developers. We conducted 20 case studies via in-depth interviews and surveyed 306 practitioners across 26 domains. We investigate why organizations build agents, how they build them, how they evaluate them, and their top development challenges. Our study finds that production agents are built using simple, controllable approaches: 68% execute at most 10 steps before human intervention, 70% rely on prompting off-the-shelf models instead of weight tuning, and 74% depend primarily on human evaluation. Reliability (consistent correct behavior over time) remains the top development challenge, which practitioners currently address through systems-level design. MAP documents the current state of production agents, providing the research community with visibility into deployment realities and under-explored research avenues.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>生产中的代理测量</div>
<div class="mono" style="margin-top:8px">基于LLM的代理已经在多个行业中投入生产，但我们对哪些技术方法使部署成功缺乏理解。我们提出了第一个系统性研究《生产中的代理测量》（MAP），使用来自代理开发者的一手数据。我们通过深入访谈进行了20个案例研究，并对26个领域的306名从业者进行了调查。我们研究了组织为何构建代理、如何构建、如何评估以及他们面临的主要开发挑战。我们的研究发现，生产代理采用简单、可控的方法构建：68%的代理在人工干预前最多执行10个步骤，70%依赖现成模型的提示而非权重调优，74%主要依赖人工评估。可靠性（长期一致的正确行为）仍然是最大的开发挑战，实践者目前通过系统级设计来应对。MAP记录了生产代理的当前状态，为研究界提供了对部署现实和未充分探索的研究途径的可见性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this study is to understand the technical methods that contribute to the successful deployment of LLM-based agents in various industries. The researchers conducted a systematic investigation called Measuring Agents in Production (MAP), which included 20 case studies through in-depth interviews and a survey of 306 practitioners across 26 domains. The findings reveal that production agents typically utilize straightforward methods, with 68% executing no more than 10 steps before requiring human intervention, 70% relying on off-the-shelf models rather than weight tuning, and 74% primarily depending on human evaluation, while reliability remains the foremost challenge addressed through systems-level design.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于了解促成LLM基础代理在各行业成功部署的技术方法，因为目前在这一领域缺乏全面的知识。该研究采用系统的方法，通过深入访谈进行20个案例研究，并对来自26个领域的306名从业者进行调查，以收集代理开发者的第一手数据。主要发现表明，生产代理通常采用简单且可控的方法，其中68%的代理在需要人工干预之前最多执行10个步骤，70%依赖现成模型而非权重调整，74%主要依赖人工评估，而可靠性仍然是通过系统级设计来解决的主要开发挑战。</div>
</details>
</div>
<div class="card">
<div class="title">Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF</div>
<div class="meta-line">Authors: Aidan Furlong, Robert Salko, Xingang Zhao, Xu Wu</div>
<div class="meta-line">First: 2026-02-03T18:05:16+00:00 · Latest: 2026-02-03T18:05:16+00:00</div>
<div class="meta-line">Comments: Submitted to the 2026 American Nuclear Society Annual Meeting</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03805v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03805v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous work developed and deployed tube-based pure and hybrid ML models in the CTF subchannel code, however, full-scale reactor core simulations require the use of rod bundle geometries. Unlike isolated subchannels, rod bundles experience complex thermal hydraulic phenomena such as channel crossflow, spacer grid losses, and effects from unheated conductors. This study investigates the generalization of ML-based CHF prediction models in rod bundles after being trained on tube-based CHF data. A purely data-driven DNN and two hybrid bias-correction models were implemented in the CTF subchannel code and used to predict CHF location and magnitude in the Combustion Engineering 5-by-5 bundle CHF test series. The W-3 correlation, Bowring correlation, and Groeneveld LUT were used as baseline comparators. On average, all three ML-based approaches produced magnitude and location predictions more accurate than the baseline models, with the hybrid LUT model exhibiting the most favorable performance metrics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用基于管道的混合机器学习模型预测束状棒中的临界热流</div>
<div class="mono" style="margin-top:8px">近年来，使用机器学习（ML）方法预测临界热流（CHF）已成为一个高度活跃的研究领域，其目标是构建比当前传统方法（如经验相关或查找表（LUT））更准确的模型。之前的工作在CTF子通道代码中开发并部署了基于管道的纯ML和混合ML模型，但全规模反应堆核心模拟需要使用束状棒几何形状。与孤立子通道不同，束状棒经历复杂的热水力现象，如通道交叉流、间隔网损失和未加热导体的影响。本研究探讨了在基于管道的CHF数据训练后，基于ML的CHF预测模型在束状棒中的泛化。一个纯数据驱动的DNN和两个混合偏差校正模型在CTF子通道代码中实现，并用于预测燃烧工程5x5束CHF测试系列中的CHF位置和大小。W-3相关性、Bowring相关性和Groeneveld LUT被用作基线比较。平均而言，所有三种基于ML的方法在大小和位置预测上都比基线模型更准确，其中混合LUT模型表现出最有利的性能指标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve the prediction of critical heat flux (CHF) in rod bundles, which are subject to complex thermal hydraulic phenomena, using machine learning (ML) methods that outperform traditional empirical correlations and lookup tables. The study employs a purely data-driven deep neural network (DNN) and two hybrid bias-correction models, trained on tube-based CHF data, and integrates them into the CTF subchannel code to predict CHF location and magnitude in a 5-by-5 rod bundle test series. The results indicate that all three ML-based approaches yield more accurate predictions of both magnitude and location compared to baseline models, with the hybrid lookup table model demonstrating the best performance metrics.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高对束状燃料元件中临界热通量（CHF）的预测准确性，这对反应堆核心模拟至关重要，而目前的传统方法存在局限性。研究采用纯数据驱动的深度神经网络（DNN）和两种混合偏差校正模型，基于管道的CHF数据进行训练，以预测在燃烧工程5×5束状CHF测试系列中的CHF位置和大小，使用CTF子通道代码。研究结果表明，所有三种机器学习方法的预测准确性均优于传统模型，其中混合LUT模型的性能指标最佳。</div>
</details>
</div>
<div class="card">
<div class="title">Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods</div>
<div class="meta-line">Authors: Grigory Begunov, Alexander Tyurin</div>
<div class="meta-line">First: 2026-02-03T18:02:14+00:00 · Latest: 2026-02-03T18:02:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03802v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03802v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>我们需要异步SGD吗？关于同步方法的近似最优性</div>
<div class="mono" style="margin-top:8px">现代分布式优化方法主要依赖于传统的同步方法，尽管异步优化最近取得了显著进展。我们重新审视同步SGD及其稳健变体$m$-同步SGD，并理论上证明它们在许多异构计算场景中几乎是最优的，这有些出乎意料。我们在随机计算时间和对抗性部分参与的工人下分析同步方法，并证明它们在许多实际情况下的时间复杂度是最优的，最多到对数因子。虽然同步方法不是通用解决方案，并且存在一些任务可能需要异步方法，但我们表明它们对于许多现代异构计算场景是足够的。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to evaluate the effectiveness of synchronous optimization methods in the context of modern distributed optimization, particularly in light of advancements in asynchronous approaches. The authors analyze Synchronous SGD and its robust variant, $m$-Synchronous SGD, under conditions of random computation times and adversarial partial participation of workers. They demonstrate that these synchronous methods achieve nearly optimal time complexities in various heterogeneous computation scenarios, suggesting that while asynchronous methods may be necessary for certain tasks, synchronous methods are adequate for many practical applications.</div>
<div class="mono" style="margin-top:8px">本研究的动机是评估同步优化方法在现代分布式优化中的有效性，而异步方法则引起了关注。作者分析了同步SGD及其稳健变体$m$-同步SGD，利用理论框架评估它们在随机计算时间和对抗性工人参与的异构计算环境中的表现。主要发现表明，这些同步方法在多种实际场景中表现出近乎最优的时间复杂度，表明尽管某些任务可能需要异步方法，但同步方法对于许多现代应用是足够的。</div>
</details>
</div>
<div class="card">
<div class="title">Conformal Reachability for Safe Control in Unknown Environments</div>
<div class="meta-line">Authors: Xinhang Ma, Junlin Wu, Yiannis Kantaros, Yevgeniy Vorobeychik</div>
<div class="meta-line">First: 2026-02-03T18:01:38+00:00 · Latest: 2026-02-03T18:01:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03799v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03799v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Designing provably safe control is a core problem in trustworthy autonomy. However, most prior work in this regard assumes either that the system dynamics are known or deterministic, or that the state and action space are finite, significantly limiting application scope. We address this limitation by developing a probabilistic verification framework for unknown dynamical systems which combines conformal prediction with reachability analysis. In particular, we use conformal prediction to obtain valid uncertainty intervals for the unknown dynamics at each time step, with reachability then verifying whether safety is maintained within the conformal uncertainty bounds. Next, we develop an algorithmic approach for training control policies that optimize nominal reward while also maximizing the planning horizon with sound probabilistic safety guarantees. We evaluate the proposed approach in seven safe control settings spanning four domains -- cartpole, lane following, drone control, and safe navigation -- for both affine and nonlinear safety specifications. Our experiments show that the policies we learn achieve the strongest provable safety guarantees while still maintaining high average reward.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>未知环境中安全控制的符合性可达性</div>
<div class="mono" style="margin-top:8px">设计可证明安全的控制是可信自主的核心问题。然而，以往的大多数研究假设系统动态是已知的或确定的，或者状态和动作空间是有限的，这大大限制了应用范围。我们通过开发一个针对未知动态系统的概率验证框架来解决这一限制，该框架结合了符合性预测和可达性分析。具体而言，我们使用符合性预测在每个时间步获得未知动态的有效不确定性区间，然后通过可达性验证安全性是否在符合性不确定性范围内得到保持。接下来，我们开发了一种算法方法来训练控制策略，优化名义奖励，同时最大化具有可靠概率安全保证的规划范围。我们在四个领域的七个安全控制设置中评估了所提出的方法——包括倒立摆、车道跟随、无人机控制和安全导航——针对仿射和非线性安全规范。我们的实验表明，我们学习的策略在保持高平均奖励的同时，实现了最强的可证明安全保证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the safety of control systems in unknown environments, addressing limitations in prior work that often assumes known dynamics or finite state spaces. The authors develop a probabilistic verification framework that integrates conformal prediction with reachability analysis to provide valid uncertainty intervals for unknown dynamics and verify safety within these bounds. Experimental results demonstrate that the proposed approach achieves strong provable safety guarantees while optimizing control policies for high average reward across various settings, including cartpole, lane following, drone control, and safe navigation.</div>
<div class="mono" style="margin-top:8px">本研究的动机是提高不确定环境中控制系统的安全性，因为现有方法通常依赖已知的动态或有限的状态空间，这限制了其适用性。作者开发了一种将保形预测与可达性分析相结合的概率验证框架，以解决这些限制，使得在每个时间步长上能够为未知动态提供有效的不确定性区间。实验结果表明，所提出的方法在包括倒立摆、车道跟随、无人机控制和安全导航等多种控制设置中，实现了强有力的可证明安全保证，同时优化了高平均奖励。</div>
</details>
</div>
<div class="card">
<div class="title">FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation</div>
<div class="meta-line">Authors: Zimu Lu, Houxing Ren, Yunqiao Yang, Ke Wang, Zhuofan Zong, Mingjie Zhan, Hongsheng Li</div>
<div class="meta-line">First: 2026-02-03T18:01:34+00:00 · Latest: 2026-02-03T18:01:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03798v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03798v1">PDF</a> · <a href="https://github.com/mnluzimu/FullStack-Agent">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing, codebase navigation, and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend, backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend, backend, and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FullStack-Agent：通过面向开发的测试和代码库反向翻译增强代理全栈网页编码</div>
<div class="mono" style="margin-top:8px">帮助非专业用户开发复杂的交互式网站已成为基于大型语言模型的代码代理的热门任务。然而，现有的代码代理往往只生成前端网页，掩盖了缺乏真正全栈数据处理和存储的问题。值得注意的是，构建生产级全栈网页应用程序远比仅生成前端网页更具挑战性，需要对数据流进行仔细控制，全面理解不断更新的包和依赖关系，并准确定位代码库中的模糊错误。为了解决这些困难，我们引入了FullStack-Agent，一个统一的全栈代理编码系统，由三个部分组成：(1) FullStack-Dev，一个具有强大规划、代码编辑、代码库导航和错误定位能力的多代理框架。(2) FullStack-Learn，一种创新的数据扩展和自我改进方法，通过反向翻译抓取和合成的网站代码库来提升FullStack-Dev的基础大型语言模型。(3) FullStack-Bench，一个全面的基准，系统地测试生成网站的前端、后端和数据库功能。我们的FullStack-Dev在前端、后端和数据库测试用例上分别比之前的最先进方法提高了8.7%、38.2%和15.9%。此外，FullStack-Learn通过自我改进将一个30B模型在三组测试用例上的性能提高了9.7%、9.5%和2.8%，证明了我们方法的有效性。代码已发布在https://github.com/mnluzimu/FullStack-Agent。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to assist non-expert users in developing complex interactive websites, as existing code agents primarily focus on frontend generation, neglecting full-stack capabilities. The authors introduce FullStack-Agent, a comprehensive system that includes FullStack-Dev for planning and debugging, FullStack-Learn for enhancing the model through back-translation of website repositories, and FullStack-Bench for evaluating the full-stack functionalities. Experimental results show that FullStack-Dev surpasses previous methods by 8.7%, 38.2%, and 15.9% in frontend, backend, and database tests, respectively, while FullStack-Learn improves a 30B model&#x27;s performance by 9.7%, 9.5%, and 2.8% across the same test sets, validating the effectiveness of their approach.</div>
<div class="mono" style="margin-top:8px">本研究的动机是帮助非专业用户开发复杂的交互式网站，因为现有的代码代理主要集中在前端生成，忽视了全栈能力。作者提出了FullStack-Agent，这是一个综合系统，包括用于规划和错误定位的FullStack-Dev、通过网站仓库的反向翻译来改进模型的FullStack-Learn，以及用于基准测试功能的FullStack-Bench。实验结果表明，FullStack-Dev在前端、后端和数据库测试中分别超越了之前的方法8.7%、38.2%和15.9%，而FullStack-Learn则在同一测试集上提升了30B模型的性能9.7%、9.5%和2.8%，显示了其方法的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Manifold Random Features</div>
<div class="meta-line">Authors: Ananya Parashar, Derek Long, Dwaipayan Saha, Krzysztof Choromanski</div>
<div class="meta-line">First: 2026-02-03T18:00:01+00:00 · Latest: 2026-02-03T18:00:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03797v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03797v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a new paradigm for creating random features to approximate bi-variate functions (in particular, kernels) defined on general manifolds. This new mechanism of Manifold Random Features (MRFs) leverages discretization of the manifold and the recently introduced technique of Graph Random Features (GRFs) to learn continuous fields on manifolds. Those fields are used to find continuous approximation mechanisms that otherwise, in general scenarios, cannot be derived analytically. MRFs provide positive and bounded features, a key property for accurate, low-variance approximation. We show deep asymptotic connection between GRFs, defined on discrete graph objects, and continuous random features used for regular kernels. As a by-product of our method, we re-discover recently introduced mechanism of Gaussian kernel approximation applied in particular to improve linear-attention Transformers, considering simple random walks on graphs and by-passing original complex mathematical computations. We complement our algorithm with a rigorous theoretical analysis and verify in thorough experimental studies.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>流形随机特征</div>
<div class="mono" style="margin-top:8px">我们提出了一种新的范式，用于创建随机特征以近似定义在一般流形上的双变量函数（特别是核）。这种流形随机特征（MRFs）的新机制利用了流形的离散化和最近引入的图随机特征（GRFs）技术，以学习流形上的连续场。这些场用于寻找连续近似机制，而在一般情况下，这些机制无法通过解析方法推导。MRFs提供正值和有界特征，这是准确、低方差近似的关键属性。我们展示了定义在离散图对象上的GRFs与用于常规核的连续随机特征之间的深层渐近联系。作为我们方法的副产品，我们重新发现了最近引入的高斯核近似机制，特别应用于改善线性注意力Transformer，考虑图上的简单随机游走，并绕过原始复杂的数学计算。我们用严格的理论分析补充了我们的算法，并在全面的实验研究中进行了验证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for effective methods to approximate bi-variate functions on general manifolds, particularly through the use of kernels. The authors introduce Manifold Random Features (MRFs), which utilize discretization of the manifold and Graph Random Features (GRFs) to learn continuous fields, enabling the development of continuous approximation mechanisms that are typically analytically intractable. Experimental results demonstrate that MRFs yield positive and bounded features, leading to accurate and low-variance approximations, and the study also reveals a deep asymptotic connection between GRFs and continuous random features, while providing a new perspective on Gaussian kernel approximation for enhancing linear-attention Transformers.</div>
<div class="mono" style="margin-top:8px">本研究的动机是开发一种新方法，用于在一般流形上近似双变量函数，特别是核函数，采用一种称为流形随机特征（MRFs）的新方法。该方法涉及对流形进行离散化，并利用图随机特征（GRFs）学习连续场，这有助于推导通常在解析上不可处理的连续近似机制。主要实验结果表明，MRFs产生正值和有界特征，这对于实现准确且低方差的近似至关重要，同时研究还揭示了GRFs与连续随机特征之间的深层渐近联系，并提供了增强线性注意力变换器的高斯核近似的见解。</div>
</details>
</div>
<div class="card">
<div class="title">Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</div>
<div class="meta-line">Authors: Yingxuan Yang, Chengrui Qu, Muning Wen, Laixi Shi, Ying Wen, Weinan Zhang, Adam Wierman, Shangding Gu</div>
<div class="meta-line">First: 2026-02-03T17:58:10+00:00 · Latest: 2026-02-03T17:58:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03794v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03794v1">PDF</a> · <a href="https://github.com/SafeRL-Lab/Agent-Scaling">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过多样性理解基于LLM的多智能体系统中的代理扩展</div>
<div class="mono" style="margin-top:8px">基于LLM的多智能体系统（MAS）已成为解决个体LLM难以处理的复杂任务的有前景的方法。一个自然的策略是通过增加代理数量来提升性能；然而，我们发现这种扩展在同质环境中表现出强烈的收益递减，而引入异质性（例如，不同的模型、提示或工具）仍然能带来显著的收益。这引发了一个根本性的问题：是什么限制了扩展，为什么多样性有帮助？我们提出了一个信息论框架，表明MAS性能受内在任务不确定性的限制，而不是代理数量。我们推导出与架构无关的界限，表明改进取决于系统访问的有效通道数量。同质代理因其输出高度相关而早期饱和，而异质代理则提供互补证据。我们进一步引入$K^*$，一个有效通道计数，量化没有真实标签的有效通道数量。实证结果表明，异质配置始终优于同质扩展：2个多样化代理的性能可以匹配或超过16个同质代理的性能。我们的结果为通过关注多样性设计构建高效且稳健的MAS提供了原则性指导。代码和数据集可在以下链接获取：https://github.com/SafeRL-Lab/Agent-Scaling。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the limitations of scaling performance in LLM-based multi-agent systems (MAS) and the role of diversity in enhancing effectiveness. The authors employ an information-theoretic framework to analyze how task uncertainty constrains MAS performance, revealing that the number of effective communication channels is more critical than the number of agents. Experimental results demonstrate that heterogeneous agent configurations significantly outperform homogeneous ones, with two diverse agents achieving performance comparable to that of sixteen homogeneous agents, thus providing insights for designing more efficient MAS.</div>
<div class="mono" style="margin-top:8px">本研究探讨了LLM基础的多智能体系统（MAS）在性能扩展中的限制以及多样性在提高有效性方面的作用。作者采用信息论框架证明，MAS的性能受内在任务不确定性的限制，而非智能体数量。实验结果显示，异质配置（如使用多样化的智能体）显著优于同质配置，两名多样化智能体的表现可与十六名同质智能体相媲美，从而为通过关注多样性设计更高效的MAS提供了见解。</div>
</details>
</div>
<div class="card">
<div class="title">BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks</div>
<div class="meta-line">Authors: Yixiang Chen, Peiyan Li, Jiabing Yang, Keji He, Xiangnan Wu, Yuan Xu, Kai Wang, Jing Liu, Nianfeng Liu, Yan Huang, Liang Wang</div>
<div class="meta-line">First: 2026-02-03T17:56:28+00:00 · Latest: 2026-02-03T17:56:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03793v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03793v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://BridgeV2W.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Embodied world models have emerged as a promising paradigm in robotics, most of which leverage large-scale Internet videos or pretrained video generation models to enrich visual and motion priors. However, they still face key challenges: a misalignment between coordinate-space actions and pixel-space videos, sensitivity to camera viewpoint, and non-unified architectures across embodiments. To this end, we present BridgeV2W, which converts coordinate-space actions into pixel-aligned embodiment masks rendered from the URDF and camera parameters. These masks are then injected into a pretrained video generation model via a ControlNet-style pathway, which aligns the action control signals with predicted videos, adds view-specific conditioning to accommodate camera viewpoints, and yields a unified world model architecture across embodiments. To mitigate overfitting to static backgrounds, BridgeV2W further introduces a flow-based motion loss that focuses on learning dynamic and task-relevant regions. Experiments on single-arm (DROID) and dual-arm (AgiBot-G1) datasets, covering diverse and challenging conditions with unseen viewpoints and scenes, show that BridgeV2W improves video generation quality compared to prior state-of-the-art methods. We further demonstrate the potential of BridgeV2W on downstream real-world tasks, including policy evaluation and goal-conditioned planning. More results can be found on our project website at https://BridgeV2W.github.io .</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BridgeV2W：通过体现掩码将视频生成模型与具身世界模型连接起来</div>
<div class="mono" style="margin-top:8px">具身世界模型已成为机器人技术中一种有前景的范式，其中大多数利用大规模互联网视频或预训练的视频生成模型来丰富视觉和运动先验。然而，它们仍面临关键挑战：坐标空间动作与像素空间视频之间的不对齐、对相机视角的敏感性以及跨体现的不统一架构。为此，我们提出了BridgeV2W，它将坐标空间动作转换为从URDF和相机参数渲染的像素对齐体现掩码。这些掩码随后通过ControlNet风格的路径注入到预训练的视频生成模型中，使动作控制信号与预测视频对齐，添加特定视角的条件以适应相机视角，并在各体现之间产生统一的世界模型架构。为了减轻对静态背景的过拟合，BridgeV2W进一步引入了一种基于流的运动损失，专注于学习动态和任务相关区域。在单臂（DROID）和双臂（AgiBot-G1）数据集上的实验，涵盖了具有未见视角和场景的多样且具有挑战性的条件，显示BridgeV2W在视频生成质量上优于先前的最先进方法。我们进一步展示了BridgeV2W在下游现实任务中的潜力，包括策略评估和目标条件规划。更多结果可以在我们的项目网站 https://BridgeV2W.github.io 上找到。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges faced by embodied world models in robotics, particularly the misalignment between coordinate-space actions and pixel-space videos, sensitivity to camera viewpoints, and the lack of unified architectures. The authors propose BridgeV2W, which transforms coordinate-space actions into pixel-aligned embodiment masks using URDF and camera parameters, and integrates these masks into a pretrained video generation model through a ControlNet-style pathway. Experimental results demonstrate that BridgeV2W enhances video generation quality on single-arm and dual-arm datasets under diverse conditions, and shows promise for real-world applications such as policy evaluation and goal-conditioned planning.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决机器人中体现世界模型面临的挑战，特别是坐标空间动作与像素空间视频之间的不对齐、对相机视角的敏感性以及缺乏统一架构的问题。作者提出了BridgeV2W，该方法利用URDF和相机参数将坐标空间动作转换为像素对齐的体现掩码，并通过ControlNet风格的路径将这些掩码集成到预训练的视频生成模型中。实验结果表明，BridgeV2W在单臂和双臂数据集上在多样化条件下提高了视频生成质量，并在政策评估和目标导向规划等实际应用中显示出潜力。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260204_0354.html">20260204_0354</a>
<a href="archive/20260203_1224.html">20260203_1224</a>
<a href="archive/20260202_0334.html">20260202_0334</a>
<a href="archive/20260201_0330.html">20260201_0330</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0342.html">20260130_0342</a>
<a href="archive/20260129_0342.html">20260129_0342</a>
<a href="archive/20260128_0340.html">20260128_0340</a>
<a href="archive/20260127_0335.html">20260127_0335</a>
<a href="archive/20260126_0328.html">20260126_0328</a>
<a href="archive/20260125_0326.html">20260125_0326</a>
<a href="archive/20260124_0335.html">20260124_0335</a>
<a href="archive/20260123_0336.html">20260123_0336</a>
<a href="archive/20260122_0339.html">20260122_0339</a>
<a href="archive/20260121_0422.html">20260121_0422</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_0325.html">20260118_0325</a>
<a href="archive/20260117_0329.html">20260117_0329</a>
<a href="archive/20260116_0336.html">20260116_0336</a>
<a href="archive/20260115_0332.html">20260115_0332</a>
<a href="archive/20260114_0332.html">20260114_0332</a>
<a href="archive/20260113_0331.html">20260113_0331</a>
<a href="archive/20260112_0325.html">20260112_0325</a>
<a href="archive/20260111_0325.html">20260111_0325</a>
<a href="archive/20260110_0330.html">20260110_0330</a>
<a href="archive/20260109_0330.html">20260109_0330</a>
<a href="archive/20260108_0332.html">20260108_0332</a>
<a href="archive/20260107_0328.html">20260107_0328</a>
<a href="archive/20260106_1857.html">20260106_1857</a>
<a href="archive/20260106_1846.html">20260106_1846</a>
<a href="archive/20260106_0330.html">20260106_0330</a>
<a href="archive/20260105_0325.html">20260105_0325</a>
<a href="archive/20260104_2229.html">20260104_2229</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
