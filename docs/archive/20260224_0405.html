<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-24 04:05</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260224_0405</div>
    <div class="row"><div class="card">
<div class="title">Assigning Confidence: K-partition Ensembles</div>
<div class="meta-line">Authors: Aggelos Semoglou, John Pavlopoulos</div>
<div class="meta-line">First: 2026-02-20T18:59:53+00:00 · Latest: 2026-02-20T18:59:53+00:00</div>
<div class="meta-line">Comments: 31 pages including appendix</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18435v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18435v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>赋予信心：K-划分集成</div>
<div class="mono" style="margin-top:8px">聚类广泛用于无监督结构发现，但它对每个单独分配的可靠性提供的洞察有限。诊断信息，如收敛行为或目标值，可能反映全局质量，但并不指示特定实例是否被自信地分配，尤其是对于像k-means这样对初始化敏感的算法。这种分配级别的不稳定性可能会削弱准确性和鲁棒性。集成方法通过聚合多次运行来提高全局一致性，但通常缺乏量化逐点信心的工具，这种量化结合了跨运行的一致性和从学习到的聚类结构中获得的几何支持。我们引入CAKE（通过K-划分集成评估分配的信心），这是一个使用在聚类集成上计算的两个互补统计量来评估每个点的框架：分配稳定性和局部几何拟合的一致性。这些被组合成一个在[0,1]范围内的单一可解释分数。我们的理论分析表明，CAKE在噪声下仍然有效，并能区分稳定点和不稳定点。对合成和真实世界数据集的实验表明，CAKE有效地突出模糊点和稳定核心成员，提供可以指导过滤或优先级排序以提高聚类质量的信心排名。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the reliability of clustering assignments, particularly in algorithms like k-means that are sensitive to initialization. The authors propose a novel framework called CAKE (Confidence in Assignments via K-partition Ensembles), which evaluates each data point&#x27;s assignment confidence using two statistics: assignment stability and local geometric fit consistency, ultimately producing a score between 0 and 1. Experimental results on both synthetic and real-world datasets demonstrate that CAKE effectively identifies ambiguous points and stable core members, thereby providing a useful confidence ranking that can improve clustering quality through better filtering and prioritization.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决聚类方法的局限性，特别是在评估无监督学习中个别分配的可靠性方面。作者提出了一种新框架CAKE（通过K-分区集成分配信心），该框架通过评估聚类集成中的分配稳定性和局部几何拟合，为每个数据点提供信心分数。对合成数据和真实世界数据集的实验结果表明，CAKE成功识别模糊点和稳定核心成员，提供的信心排名通过指导过滤和优先级设置来提高聚类质量。</div>
</details>
</div>
<div class="card">
<div class="title">Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory</div>
<div class="meta-line">Authors: Vatsal Agarwal, Saksham Suri, Matthew Gwilliam, Pulkit Kumar, Abhinav Shrivastava</div>
<div class="meta-line">First: 2026-02-20T18:59:50+00:00 · Latest: 2026-02-20T18:59:50+00:00</div>
<div class="meta-line">Comments: Project page: see https://vatsalag99.github.io/memstream/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18434v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18434v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://vatsalag99.github.io/memstream/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>走进记忆之路：使用动态KV缓存内存扩展视频流理解的令牌</div>
<div class="mono" style="margin-top:8px">流媒体视频理解要求模型能够稳健地编码、存储和检索来自连续视频流的信息，以支持准确的视频问答（VQA）。现有的最先进方法依赖于键值缓存来随着时间积累帧级信息，但每帧使用的令牌数量有限，导致细粒度视觉细节的丢失。在本研究中，我们提出扩展令牌预算，以实现更细粒度的时空理解和推理。首先，我们发现当前方法无法有效处理密集流：它们的特征编码导致查询帧相似度分数随时间增加，偏向于后期帧的检索。为了解决这个问题，我们引入了一种自适应选择策略，减少令牌冗余，同时保留局部时空信息。我们进一步提出了一种无训练的检索专家混合模型，利用外部模型更好地识别相关帧。我们的方法MemStream在CG-Bench上提高了8.0%，在LVBench上提高了8.5%，在VideoMME（长）上提高了2.4%，相较于ReKV和Qwen2.5-VL-7B。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve video stream understanding for accurate video question answering by addressing the limitations of existing key-value caching methods that use a restricted number of tokens per frame, which results in the loss of fine-grained visual details. The authors propose a method called MemStream that scales the token budget to enhance spatiotemporal understanding and reasoning, introducing an adaptive selection strategy to minimize token redundancy while maintaining local information. Experimental results demonstrate that MemStream outperforms previous methods, achieving improvements of +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) compared to ReKV with Qwen2.5-VL-7B.</div>
<div class="mono" style="margin-top:8px">本研究的动机是通过改善连续视频流中信息的编码、存储和检索，来增强视频流理解，以实现准确的视频问答。作者提出了一种名为MemStream的方法，该方法扩大了令牌预算，以允许更详细的时空理解和推理，解决了现有方法在令牌冗余和偏向后期帧检索方面的局限性。实验结果表明，MemStream在CG-Bench上提高了8.0%，在LVBench上提高了8.5%，在VideoMME（长）上提高了2.4%，超越了最先进的ReKV方法，使用的是Qwen2.5-VL-7B模型。</div>
</details>
</div>
<div class="card">
<div class="title">Online Smoothed Demand Management</div>
<div class="meta-line">Authors: Adam Lechowicz, Nicolas Christianson, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy</div>
<div class="meta-line">First: 2025-11-23T17:59:51+00:00 · Latest: 2026-02-20T18:59:32+00:00</div>
<div class="meta-line">Comments: Accepted to SIGMETRICS &#x27;26. 65 pages, 11 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.18554v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.18554v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce and study a class of online problems called online smoothed demand management $(\texttt{OSDM})$, motivated by paradigm shifts in grid integration and energy storage for large energy consumers such as data centers. In $\texttt{OSDM}$, an operator makes two decisions at each time step: an amount of energy to be purchased, and an amount of energy to be delivered (i.e., used for computation). The difference between these decisions charges (or discharges) the operator&#x27;s energy storage (e.g., a battery). Two types of demand arrive online: base demand, which must be covered at the current time, and flexible demand, which can be satisfied at any time before a demand-specific deadline $Δ_t$. The operator&#x27;s goal is to minimize a cost (subject to above constraints) that combines a cost of purchasing energy, a cost for delivering energy (if applicable), and smoothness penalties on the purchasing and delivery rates to discourage fluctuations and encourage ``grid healthy&#x27;&#x27; decisions. $\texttt{OSDM}$ generalizes several problems in the online algorithms literature while being the first to fully model applications of interest. We propose a competitive algorithm for $\texttt{OSDM}$ called $\texttt{PAAD}$ (partitioned accounting &amp; aggregated decisions) and show it achieves the optimal competitive ratio. To overcome the pessimism typical of worst-case analysis, we also propose a novel learning framework that provides guarantees on the worst-case competitive ratio (i.e., to provide robustness against nonstationarity) while allowing end-to-end differentiable learning of the best algorithm on historical instances of the problem. We evaluate our algorithms in a case study of a grid-integrated data center with battery storage, showing that $\texttt{PAAD}$ effectively solves the problem and end-to-end learning achieves substantial performance improvements compared to $\texttt{PAAD}$.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在线平滑需求管理</div>
<div class="mono" style="margin-top:8px">我们介绍并研究了一类称为在线平滑需求管理（\texttt{OSDM}）的在线问题，这一问题受到大能源消费者（如数据中心）在电网集成和能源存储方面的范式转变的启发。在\texttt{OSDM}中，操作员在每个时间步做出两个决策：购买的能源量和交付的能源量（即用于计算的能源）。这两个决策之间的差异会对操作员的能源存储（例如电池）进行充电（或放电）。有两种类型的需求在线到达：基础需求，必须在当前时间得到满足；灵活需求，可以在特定的截止时间$Δ_t$之前的任何时间得到满足。操作员的目标是最小化一个成本（在上述约束条件下），该成本结合了购买能源的成本、交付能源的成本（如适用）以及对购买和交付速率的平滑惩罚，以抑制波动并鼓励“电网健康”的决策。\texttt{OSDM}概括了在线算法文献中的几个问题，同时首次全面建模了感兴趣的应用。我们提出了一种名为\texttt{PAAD}（分区会计与聚合决策）的\texttt{OSDM}竞争算法，并证明其达到了最佳竞争比率。为了克服最坏情况分析的悲观性，我们还提出了一种新颖的学习框架，该框架提供了对最坏情况竞争比率的保证（即提供对非平稳性的鲁棒性），同时允许对历史实例问题的最佳算法进行端到端可微学习。我们在一个具有电池存储的电网集成数据中心的案例研究中评估了我们的算法，显示\texttt{PAAD}有效地解决了该问题，并且端到端学习相比于\texttt{PAAD}实现了显著的性能提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for effective energy management in large consumers like data centers, particularly in the context of grid integration and energy storage. The authors introduce a new online problem called online smoothed demand management (OSDM), where operators must decide on energy purchases and deliveries while managing base and flexible demand. They propose a competitive algorithm named PAAD, which achieves the optimal competitive ratio, and introduce a learning framework that enhances performance by adapting to historical data. Experimental results demonstrate that PAAD effectively addresses the OSDM challenges, and the learning approach significantly improves performance outcomes compared to PAAD alone.</div>
<div class="mono" style="margin-top:8px">本研究的动机是为了在大型能源消费者（如数据中心）中有效管理能源，特别是在电网集成和能源存储的背景下。作者提出了一类新的在线问题，称为在线平滑需求管理（OSDM），其中操作员必须在每个时间步骤决定购买和交付多少能源，同时管理基础和灵活需求。他们提出了一种名为PAAD的竞争算法，达到了最佳竞争比，并引入了一种学习框架，通过适应历史数据来提高性能。实验结果表明，PAAD有效解决了OSDM问题，而学习方法相比单独的PAAD带来了显著的性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">The Geometry of Noise: Why Diffusion Models Don&#x27;t Need Noise Conditioning</div>
<div class="meta-line">Authors: Mojtaba Sahraee-Ardakan, Mauricio Delbracio, Peyman Milanfar</div>
<div class="meta-line">First: 2026-02-20T18:49:00+00:00 · Latest: 2026-02-20T18:49:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18428v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18428v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\text{marg}}(\mathbf{u}) = -\log p(\mathbf{u})$, where $p(\mathbf{u}) = \int p(\mathbf{u}|t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap&#x27;&#x27; in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>噪声的几何：扩散模型为何不需要噪声条件</div>
<div class="mono" style="margin-top:8px">自主（无噪声依赖）生成模型，如平衡匹配和盲扩散，通过学习一个单一的、时间不变的向量场来挑战标准范式，该向量场在没有显式噪声水平条件的情况下运行。尽管最近的研究表明，高维浓度使这些模型能够从受损观测中隐式估计噪声水平，但一个根本的悖论仍然存在：当噪声水平被视为随机变量时，优化的基础景观是什么，以及一个有界的、无噪声依赖的网络如何在梯度通常发散的数据流形附近保持稳定？我们通过形式化边际能量 $E_{\text{marg}}(\mathbf{u}) = -\log p(\mathbf{u})$ 来解决这个悖论，其中 $p(\mathbf{u}) = \int p(\mathbf{u}|t)p(t)dt$ 是在未知噪声水平的先验分布下对噪声数据的边际密度的积分。我们证明，使用自主模型的生成不仅仅是盲去噪，而是这种边际能量上的一种特定形式的黎曼梯度流。通过一种新颖的相对能量分解，我们展示了虽然原始边际能量景观在数据流形上具有 $1/t^p$ 的奇点，但学习到的时间不变场隐式地包含了一个局部共形度量，完美抵消了几何奇点，将一个无限深的势阱转化为一个稳定的吸引子。我们还建立了使用自主模型进行采样的结构稳定性条件。我们识别出噪声预测参数化中的“詹森间隙”，它作为估计误差的高增益放大器，解释了在确定性盲模型中观察到的灾难性失败。相反，我们证明基于速度的参数化本质上是稳定的，因为它们满足一个有界增益条件，将后验不确定性吸收到平滑的几何漂移中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the stability and optimization landscape of noise-agnostic generative models, which operate without explicit noise-level conditioning. The authors formalize Marginal Energy and demonstrate that generation using these models is a form of Riemannian gradient flow on this energy landscape. Key findings reveal that the learned time-invariant vector field can stabilize the model near the data manifold, counteracting singularities in the Marginal Energy landscape, and they identify structural stability conditions for sampling, highlighting the advantages of velocity-based parameterizations over deterministic blind models in mitigating estimation errors.</div>
<div class="mono" style="margin-top:8px">本研究探讨了自主生成模型的能力，这些模型在没有显式噪声水平条件的情况下运行，以理解其优化景观和在数据流形附近的稳定性。作者形式化了边际能量，并证明这些模型的生成代表了一种特定形式的黎曼梯度流，从而解决了将噪声水平视为随机变量的悖论。主要发现包括在边际能量景观中识别出一个奇点，该奇点被学习的时间不变场所抵消，导致采样的结构稳定性，以及发现的“詹森间隙”，该间隙解释了确定性模型中的失败，同时强调了基于速度的参数化的稳定性。</div>
</details>
</div>
<div class="card">
<div class="title">Spatio-Spectroscopic Representation Learning using Unsupervised Convolutional Long-Short Term Memory Networks</div>
<div class="meta-line">Authors: Kameswara Bharadwaj Mantha, Lucy Fortson, Ramanakumar Sankar, Claudia Scarlata, Chris Lintott, Sandor Kruk, Mike Walmsley, Hugh Dickinson, Karen Masters, Brooke Simmons, Rebecca Smethurst</div>
<div class="meta-line">Venue: ICML</div>
<div class="meta-line">First: 2026-02-20T18:48:36+00:00 · Latest: 2026-02-20T18:48:36+00:00</div>
<div class="meta-line">Comments: This manuscript was previously submitted to ICML for peer review. Reviewers noted that while the underlying VAE-based architecture builds on established methods, its application to spatially-resolved IFS data is promising for unsupervised representation learning in astronomy. This version is released for community visibility. Reviewer decisions: Weak accept and Weak reject (Final: Reject)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18426v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18426v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Integral Field Spectroscopy (IFS) surveys offer a unique new landscape in which to learn in both spatial and spectroscopic dimensions and could help uncover previously unknown insights into galaxy evolution. In this work, we demonstrate a new unsupervised deep learning framework using Convolutional Long-Short Term Memory Network Autoencoders to encode generalized feature representations across both spatial and spectroscopic dimensions spanning $19$ optical emission lines (3800A $&lt; λ&lt;$ 8000A) among a sample of $\sim 9000$ galaxies from the MaNGA IFS survey. As a demonstrative exercise, we assess our model on a sample of $290$ Active Galactic Nuclei (AGN) and highlight scientifically interesting characteristics of some highly anomalous AGN.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>使用无监督卷积长短期记忆网络的时空光谱表示学习</div>
<div class="mono" style="margin-top:8px">积分场光谱（IFS）调查提供了一个独特的新视角，可以在空间和光谱维度上进行学习，并可能帮助揭示关于星系演化的未知见解。在这项工作中，我们展示了一种新的无监督深度学习框架，使用卷积长短期记忆网络自编码器对来自MaNGA IFS调查的约9000个星系中跨越19条光学发射线（3800A &lt; λ &lt; 8000A）的空间和光谱维度进行广义特征表示编码。作为演示练习，我们在290个活动星系核（AGN）样本上评估我们的模型，并突出一些高度异常的AGN的科学兴趣特征。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to leverage Integral Field Spectroscopy (IFS) surveys to gain insights into galaxy evolution by learning from both spatial and spectroscopic dimensions. The authors propose a novel unsupervised deep learning framework utilizing Convolutional Long-Short Term Memory Network Autoencoders to encode feature representations across 19 optical emission lines from approximately 9000 galaxies in the MaNGA IFS survey. The experimental results demonstrate the model&#x27;s effectiveness by analyzing a subset of 290 Active Galactic Nuclei (AGN), revealing scientifically significant characteristics of certain anomalous AGN.</div>
<div class="mono" style="margin-top:8px">本研究的动机是利用积分场光谱（IFS）调查，通过学习空间和光谱维度的特征，深入了解星系演化。作者开发了一种无监督深度学习框架，利用卷积长短期记忆网络自编码器对来自约9000个MaNGA IFS调查星系的19条光学发射线的特征表示进行编码。实验结果在290个活动星系核（AGN）样本上进行演示，揭示了一些异常AGN的科学特征，展示了该方法在天体物理学中发现新见解的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation</div>
<div class="meta-line">Authors: Xia Su, Ruiqi Chen, Benlin Liu, Jingwei Ma, Zonglin Di, Ranjay Krishna, Jon Froehlich</div>
<div class="meta-line">First: 2026-02-20T18:46:27+00:00 · Latest: 2026-02-20T18:46:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18424v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18424v1">PDF</a> · <a href="https://github.com/makeabilitylab/CapNav">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent&#x27;s mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent&#x27;s specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM&#x27;s navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CapNav：基于能力条件的室内导航视觉语言模型基准测试</div>
<div class="mono" style="margin-top:8px">视觉语言模型（VLMs）在视觉语言导航（VLN）方面取得了显著进展，为导航决策提供了新的可能性，既有利于机器人平台，也有利于人类用户。然而，现实世界的导航本质上受到代理人移动能力的限制。例如，扫地机器人无法上下楼梯，而四足机器人可以。我们引入了能力条件导航（CapNav），这是一个旨在评估VLMs在给定代理人特定物理和操作能力的情况下，如何在复杂室内空间中导航的基准。CapNav定义了五种代表性的人类和机器人代理，每种代理都有物理尺寸、移动能力和环境交互能力的描述。CapNav提供了45个真实室内场景、473个导航任务和2365个问答对，以测试VLMs是否能够根据代理能力穿越室内环境。我们评估了13个现代VLMs，发现当前VLM的导航性能在移动限制加剧时急剧下降，甚至最先进的模型在处理需要空间维度推理的障碍类型时也面临困难。最后，我们讨论了能力感知导航的影响以及未来VLMs在具身空间推理方面的进展机会。基准测试可在https://github.com/makeabilitylab/CapNav获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to evaluate how well Vision-Language Models (VLMs) can perform navigation tasks while considering the mobility constraints of different agents. The authors introduce a benchmark called Capability-Conditioned Navigation (CapNav), which assesses VLMs&#x27; navigation abilities in complex indoor environments based on specific physical and operational capabilities of agents. Through testing 13 modern VLMs across 45 real-world indoor scenes and 473 navigation tasks, the study finds that the navigation performance of these models significantly declines as mobility constraints become stricter, with even advanced models struggling with obstacles that require spatial reasoning.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于评估视觉语言模型（VLMs）在考虑不同代理的移动限制时在室内环境中的导航有效性。作者提出了能力条件导航（CapNav），这是一个基准，用于根据各种代理的具体物理和操作能力评估VLMs，包括人类和机器人。该研究使用45个真实室内场景和473个导航任务评估了13个现代VLMs，结果显示这些模型的导航性能在移动限制加紧时显著下降，尤其是在面对需要空间推理的障碍时。这些发现强调了能力感知导航的必要性，并建议了未来VLMs在增强具身空间推理方面的改进方向。</div>
</details>
</div>
<div class="card">
<div class="title">Benchmarking Graph Neural Networks in Solving Hard Constraint Satisfaction Problems</div>
<div class="meta-line">Authors: Geri Skenderi, Lorenzo Buffoni, Francesco D&#x27;Amico, David Machado, Raffaele Marino, Matteo Negri, Federico Ricci-Tersenghi, Carlo Lucibello, Maria Chiara Angelini</div>
<div class="meta-line">First: 2026-02-20T18:41:48+00:00 · Latest: 2026-02-20T18:41:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18419v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18419v1">PDF</a> · <a href="https://github.com/ArtLabBocconi/RandCSPBench">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graph neural networks (GNNs) are increasingly applied to hard optimization problems, often claiming superiority over classical heuristics. However, such claims risk being unsolid due to a lack of standard benchmarks on truly hard instances. From a statistical physics perspective, we propose new hard benchmarks based on random problems. We provide these benchmarks, along with performance results from both classical heuristics and GNNs. Our fair comparison shows that classical algorithms still outperform GNNs. We discuss the challenges for neural networks in this domain. Future claims of superiority can be made more robust using our benchmarks, available at https://github.com/ArtLabBocconi/RandCSPBench.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在解决困难约束满足问题中的图神经网络基准测试</div>
<div class="mono" style="margin-top:8px">图神经网络（GNN）越来越多地应用于困难的优化问题，常常声称优于经典启发式算法。然而，由于缺乏真正困难实例的标准基准，这些声称可能不够可靠。从统计物理的角度出发，我们提出了基于随机问题的新困难基准。我们提供这些基准，以及经典启发式算法和GNN的性能结果。我们的公平比较显示，经典算法仍然优于GNN。我们讨论了神经网络在这一领域面临的挑战。未来的优越性声明可以通过使用我们的基准变得更加稳健，基准可在https://github.com/ArtLabBocconi/RandCSPBench获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the increasing application of graph neural networks (GNNs) to hard optimization problems and the need for standard benchmarks to validate their claimed superiority over classical heuristics. The authors propose new hard benchmarks based on random problems from a statistical physics perspective and provide performance results for both classical algorithms and GNNs. The findings indicate that classical algorithms still outperform GNNs, highlighting the challenges faced by neural networks in this area and suggesting that future claims of superiority should rely on these newly established benchmarks.</div>
<div class="mono" style="margin-top:8px">本研究的动机是图神经网络（GNN）在解决困难优化问题中的应用日益增加，以及需要标准基准来验证其相对于经典启发式算法的优越性。作者从统计物理的角度提出了基于随机问题的新基准，并提供了经典算法和GNN的性能结果。研究结果表明，经典算法仍然优于GNN，突显了神经网络在这一领域面临的挑战，并建议未来的优越性声明应依赖于这些已建立的基准。</div>
</details>
</div>
<div class="card">
<div class="title">Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures</div>
<div class="meta-line">Authors: Joshua Nunley</div>
<div class="meta-line">First: 2026-02-20T18:35:43+00:00 · Latest: 2026-02-20T18:35:43+00:00</div>
<div class="meta-line">Comments: 12 pages, 3 figures, 8 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18417v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18417v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>U(d) 的子群诱导自然 RNN 和 Transformer 架构</div>
<div class="mono" style="margin-top:8px">本文提出了一个直接的框架，用于在 U(d) 的闭子群上进行具有隐状态的序列模型。我们使用最小公理设置，从一个共享的骨架中推导出递归和变换模板，其中子群选择作为状态空间、切线投影和更新映射的替代。然后我们专门研究 O(d)，并在参数匹配的设置下评估正交状态 RNN 和 Transformer 模型在 Tiny Shakespeare 和 Penn Treebank 上的表现。我们还报告了一个在切线空间中的一般线性混合扩展，适用于不同的子群选择，并改善了当前 O(d) 实验中的有限预算性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to develop a framework for sequence models that utilizes closed subgroups of U(d) to enhance the design of recurrent and transformer architectures. The authors employ a minimal axiomatic approach to derive templates for these models, where the choice of subgroup serves as a substitute for various components such as state space and update maps. The experimental results demonstrate that the orthogonal-state RNN and transformer models, when evaluated on the Tiny Shakespeare and Penn Treebank datasets under parameter-matched conditions, show improved performance, particularly with the introduction of a general linear-mixing extension in tangent space that enhances finite-budget performance across different subgroup choices.</div>
<div class="mono" style="margin-top:8px">本研究的动机是开发一个利用闭合U(d)子群的隐藏状态的序列模型框架。作者采用最小公理方法，从一个共同的框架中推导出递归和变换器架构，其中子群的选择作为状态空间和更新映射等各种组件的替代。实验结果表明，在参数匹配条件下，正交状态RNN和变换器模型在Tiny Shakespeare和Penn Treebank数据集上的表现有所改善，特别是通过切空间中的一般线性混合扩展，增强了不同子群选择下的有限预算性能。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Generative model that uses physical quantities to generate and retrieve solar magnetic active regions</div>
<div class="meta-line">Authors: Subhamoy Chatterjee, Andres Munoz-Jaramillo, Anna Malanushenko</div>
<div class="meta-line">First: 2025-02-07T21:44:01+00:00 · Latest: 2026-02-20T18:35:16+00:00</div>
<div class="meta-line">Comments: 14 pages, 9 figures, accepted for publication in ApJS</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.05351v2">Abs</a> · <a href="https://arxiv.org/pdf/2502.05351v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep generative models have shown immense potential in generating unseen data that has properties of real data. These models learn complex data-generating distributions starting from a smaller set of latent dimensions. However, generative models have encountered great skepticism in scientific domains due to the disconnection between generative latent vectors and scientifically relevant quantities. In this study, we integrate three types of machine learning models to generate solar magnetic patches in a physically interpretable manner and use those as a query to find matching patches in real observations. We use the magnetic field measurements from Space-weather HMI Active Region Patches (SHARPs) to train a Generative Adversarial Network (GAN). We connect the physical properties of GAN-generated images with their latent vectors to train Support Vector Machines (SVMs) that do mapping between physical and latent spaces. These produce directions in the GAN latent space along which known physical parameters of the SHARPs change. We train a self-supervised learner (SSL) to make queries with generated images and find matches from real data. We find that the GAN-SVM combination enables users to produce high-quality patches that change smoothly only with a prescribed physical quantity, making generative models physically interpretable. We also show that GAN outputs can be used to retrieve real data that shares the same physical properties as the generated query. This elevates Generative Artificial Intelligence (AI) from a means-to-produce artificial data to a novel tool for scientific data interrogation, supporting its applicability beyond the domain of heliophysics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用物理量生成和检索太阳磁活跃区的深度生成模型</div>
<div class="mono" style="margin-top:8px">深度生成模型在生成具有真实数据特性的未见数据方面展现了巨大的潜力。这些模型从较小的潜在维度集开始学习复杂的数据生成分布。然而，由于生成潜在向量与科学相关量之间的脱节，生成模型在科学领域遭遇了巨大的怀疑。在本研究中，我们整合了三种类型的机器学习模型，以物理可解释的方式生成太阳磁斑，并将其用作查询以在真实观测中找到匹配的斑点。我们使用来自空间天气HMI活跃区斑点（SHARPs）的磁场测量来训练生成对抗网络（GAN）。我们将GAN生成图像的物理属性与其潜在向量连接，以训练支持向量机（SVM），实现物理空间与潜在空间之间的映射。这些产生了GAN潜在空间中的方向，沿着这些方向SHARPs的已知物理参数发生变化。我们训练了一个自监督学习者（SSL），使用生成的图像进行查询，并从真实数据中找到匹配项。我们发现GAN-SVM组合使用户能够生成仅随规定物理量平滑变化的高质量斑点，使生成模型具有物理可解释性。我们还表明，GAN输出可以用于检索与生成查询具有相同物理特性的真实数据。这将生成人工智能（AI）从生产人工数据的手段提升为科学数据询问的新工具，支持其在日光物理学领域之外的适用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the interpretability of deep generative models in scientific applications, specifically in generating solar magnetic active regions. The authors employ a combination of Generative Adversarial Networks (GANs) and Support Vector Machines (SVMs) to create solar magnetic patches that are physically interpretable and to map the latent vectors to relevant physical quantities. The key findings indicate that the GAN-SVM framework allows for the generation of high-quality magnetic patches that vary smoothly with specific physical parameters, and it enables the retrieval of real observational data that shares similar physical properties with the generated images, thus demonstrating the potential of generative models as tools for scientific data analysis beyond heliophysics.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高深度生成模型在科学应用中的可解释性，特别是在生成太阳磁活跃区方面。作者将生成对抗网络（GAN）与支持向量机（SVM）和自监督学习者（SSL）结合，创建一个基于物理属性生成太阳磁斑并检索匹配真实观测结果的系统。主要发现表明，GAN-SVM框架能够生成高质量的太阳磁斑，这些斑块随着特定物理参数的变化而平滑变化，证明了生成模型可以有效用于科学数据的探究，超越传统应用。</div>
</details>
</div>
<div class="card">
<div class="title">Learning Performance Maximizing Ensembles with Explainability Guarantees</div>
<div class="meta-line">Authors: Vincent Pisztora, Jia Li</div>
<div class="meta-line">First: 2023-12-20T02:21:26+00:00 · Latest: 2026-02-20T18:33:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2312.12715v3">Abs</a> · <a href="https://arxiv.org/pdf/2312.12715v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper we propose a method for the optimal allocation of observations between an intrinsically explainable glass box model and a black box model. An optimal allocation being defined as one which, for any given explainability level (i.e. the proportion of observations for which the explainable model is the prediction function), maximizes the performance of the ensemble on the underlying task, and maximizes performance of the explainable model on the observations allocated to it, subject to the maximal ensemble performance condition. The proposed method is shown to produce such explainability optimal allocations on a benchmark suite of tabular datasets across a variety of explainable and black box model types. These learned allocations are found to consistently maintain ensemble performance at very high explainability levels (explaining $74\%$ of observations on average), and in some cases even outperforming both the component explainable and black box models while improving explainability.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>最大化学习性能的可解释性保证集成方法</div>
<div class="mono" style="margin-top:8px">本文提出了一种在内在可解释的玻璃盒模型和黑盒模型之间进行观察最优分配的方法。最优分配被定义为在任何给定的可解释性水平（即可解释模型作为预测函数的观察比例）下，最大化集成在基础任务上的性能，并在分配给可解释模型的观察上最大化其性能，同时满足最大集成性能条件。所提方法在各种可解释和黑盒模型类型的基准表格数据集上显示出能够产生这样的可解释性最优分配。这些学习到的分配在非常高的可解释性水平下（平均解释$74\%$的观察）始终保持集成性能，在某些情况下甚至超越了组件可解释模型和黑盒模型，同时提高了可解释性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the challenge of optimizing the allocation of observations between an explainable glass box model and a black box model to enhance learning performance while ensuring explainability. The authors propose a method that defines optimal allocation based on maximizing ensemble performance and the performance of the explainable model for a given level of explainability. Experimental results demonstrate that the method achieves high explainability levels, averaging 74% of observations explained, while maintaining or even surpassing the performance of both individual models on a benchmark suite of tabular datasets.</div>
<div class="mono" style="margin-top:8px">本研究的动机是提高模型集成的性能，同时确保高水平的可解释性。作者提出了一种方法，旨在在可解释的玻璃盒模型和黑箱模型之间优化观察数据的分配，以最大化集成性能和可解释模型在其分配观察数据上的性能。实验结果表明，该方法在各种表格数据集上实现了可解释性最优分配，保持了高集成性能，平均解释了74%的观察数据，并且在某些情况下超越了两个单独模型的性能，同时提高了可解释性。</div>
</details>
</div>
<div class="card">
<div class="title">Expressiveness of Multi-Neuron Convex Relaxations in Neural Network Certification</div>
<div class="meta-line">Authors: Yuhao Mao, Yani Zhang, Martin Vechev</div>
<div class="meta-line">Venue: ICLR</div>
<div class="meta-line">First: 2024-10-09T12:14:24+00:00 · Latest: 2026-02-20T18:28:54+00:00</div>
<div class="meta-line">Comments: ICLR&#x27;26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.06816v4">Abs</a> · <a href="https://arxiv.org/pdf/2410.06816v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural network certification methods heavily rely on convex relaxations to provide robustness guarantees. However, these relaxations are often imprecise: even the most accurate single-neuron relaxation is incomplete for general ReLU networks, a limitation known as the *single-neuron convex barrier*. While multi-neuron relaxations have been heuristically applied to address this issue, two central questions arise: (i) whether they overcome the convex barrier, and if not, (ii) whether they offer theoretical capabilities beyond those of single-neuron relaxations. In this work, we present the first rigorous analysis of the expressiveness of multi-neuron relaxations. Perhaps surprisingly, we show that they are inherently incomplete, even when allocated sufficient resources to capture finitely many neurons and layers optimally. This result extends the single-neuron barrier to a *universal convex barrier* for neural network certification. On the positive side, we show that completeness can be achieved by either (i) augmenting the network with a polynomial number of carefully designed ReLU neurons or (ii) partitioning the input domain into convex sub-polytopes, thereby distinguishing multi-neuron relaxations from single-neuron ones which are unable to realize the former and have worse partition complexity for the latter. Our findings establish a foundation for multi-neuron relaxations and point to new directions for certified robustness, including training methods tailored to multi-neuron relaxations and verification methods with multi-neuron relaxations as the main subroutine.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>神经网络认证中多神经元凸松弛的表达能力</div>
<div class="mono" style="margin-top:8px">神经网络认证方法在很大程度上依赖于凸松弛来提供鲁棒性保证。然而，这些松弛往往不够精确：即使是最准确的单神经元松弛对于一般的ReLU网络也是不完整的，这一限制被称为*单神经元凸障碍*。虽然多神经元松弛已被启发式地应用于解决此问题，但出现了两个核心问题：（i）它们是否克服了凸障碍，如果没有，（ii）它们是否提供了超越单神经元松弛的理论能力。在这项工作中，我们首次对多神经元松弛的表达能力进行了严格分析。令人惊讶的是，我们表明它们本质上是不完整的，即使在分配足够资源以最佳捕捉有限数量的神经元和层时也是如此。这个结果将单神经元障碍扩展为神经网络认证的*普遍凸障碍*。积极的一面是，我们表明可以通过（i）用多项式数量的精心设计的ReLU神经元增强网络，或（ii）将输入域划分为凸子多面体来实现完整性，从而将多神经元松弛与无法实现前者且对后者具有更差划分复杂度的单神经元松弛区分开来。我们的发现为多神经元松弛奠定了基础，并指向了认证鲁棒性的新方向，包括针对多神经元松弛的训练方法和以多神经元松弛为主要子例程的验证方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitations of neural network certification methods that rely on convex relaxations, particularly the incomplete nature of single-neuron relaxations for general ReLU networks, known as the single-neuron convex barrier. The authors conduct a rigorous analysis of multi-neuron relaxations to determine whether they can overcome this barrier and if they provide theoretical advantages over single-neuron relaxations. The findings reveal that multi-neuron relaxations are also inherently incomplete, leading to a universal convex barrier for neural network certification, but completeness can be achieved through augmenting the network with additional ReLU neurons or by partitioning the input domain into convex sub-polytopes, thus highlighting the distinct advantages of multi-neuron relaxations in certified robustness efforts.</div>
<div class="mono" style="margin-top:8px">本研究解决了依赖于凸松弛的神经网络认证方法的局限性，特别是被称为单神经元凸障碍的单神经元松弛的不充分性。作者对多神经元松弛进行了严格分析，以确定它们是否能够克服这一障碍或提供额外的理论能力。研究结果表明，多神经元松弛同样固有不完整，确立了神经网络认证的普遍凸障碍。然而，研究还表明，通过增加额外的ReLU神经元或将输入域划分为凸子多面体，可以实现完整性，突显了多神经元松弛在划分复杂性和认证鲁棒性潜力方面相较于单神经元松弛的明显优势。</div>
</details>
</div>
<div class="card">
<div class="title">SpecTUS: Spectral Translator for Unknown Structures annotation from EI-MS spectra</div>
<div class="meta-line">Authors: Adam Hájek, Michal Starý, Elliott Price, Filip Jozefov, Helge Hecht, Aleš Křenek</div>
<div class="meta-line">First: 2025-02-07T17:36:13+00:00 · Latest: 2026-02-20T18:18:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.05114v2">Abs</a> · <a href="https://arxiv.org/pdf/2502.05114v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Compound identification and structure annotation from mass spectra is a well-established task widely applied in drug detection, criminal forensics, small molecule biomarker discovery and chemical engineering.
  We propose SpecTUS: Spectral Translator for Unknown Structures, a deep neural model that addresses the task of structural annotation of small molecules from low-resolution gas chromatography electron ionization mass spectra (GC-EI-MS). Our model analyzes the spectra in \textit{de novo} manner -- a direct translation from the spectra into 2D-structural representation. Our approach is particularly useful for analyzing compounds unavailable in spectral libraries.
  In a rigorous evaluation of our model on the novel structure annotation task across different libraries, we outperformed standard database search techniques by a wide margin. On a held-out testing set, including \numprint{28267} spectra from the NIST database, we show that our model&#x27;s single suggestion perfectly reconstructs 43\% of the subset&#x27;s compounds. This single suggestion is strictly better than the candidate of the database hybrid search (common method among practitioners)
  in 76\% of cases. In a~still affordable scenario of~10 suggestions, perfect reconstruction is achieved in 65\%, and 84\% are better than the hybrid search.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SpecTUS：用于未知结构注释的光谱翻译器，基于EI-MS光谱</div>
<div class="mono" style="margin-top:8px">从质谱中进行化合物鉴定和结构注释是一项成熟的任务，广泛应用于药物检测、刑事法医学、小分子生物标志物发现和化学工程。我们提出了SpecTUS：用于未知结构的光谱翻译器，这是一种深度神经模型，旨在解决从低分辨率气相色谱电子电离质谱（GC-EI-MS）中进行小分子结构注释的任务。我们的模型以\textit{de novo}方式分析光谱——直接将光谱翻译为二维结构表示。我们的方法特别适用于分析在光谱库中不可用的化合物。在对我们模型在不同库中的新结构注释任务进行严格评估时，我们的表现远超标准数据库搜索技术。在一个保留的测试集中，包括来自NIST数据库的\numprint{28267}个光谱，我们展示了模型的单一建议完美重构了43\%的子集化合物。这个单一建议在76\%的情况下严格优于数据库混合搜索的候选（在从业者中常见的方法）。在仍然可接受的10个建议的情况下，完美重构达到了65\%，并且84\%优于混合搜索。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve the identification and structural annotation of small molecules from mass spectra, which is crucial in various fields such as drug detection and forensics. The authors propose a deep neural model called SpecTUS, which translates low-resolution gas chromatography electron ionization mass spectra into 2D structural representations in a de novo manner, allowing for the analysis of compounds not found in existing spectral libraries. Experimental results demonstrate that SpecTUS significantly outperforms traditional database search techniques, achieving perfect reconstruction of 43% of compounds in a testing set of 28,267 spectra, with 76% of its single suggestions being superior to those from hybrid searches, and achieving 65% perfect reconstruction with 10 suggestions.</div>
<div class="mono" style="margin-top:8px">本研究的动机是改善小分子从质谱中识别和结构注释的能力，这在药物检测和法医学等多个领域至关重要。作者提出了SpecTUS，这是一种深度神经模型，能够以自下而上的方式对低分辨率气相色谱电子电离质谱中的化合物进行结构注释，将光谱直接转换为二维结构表示。实验结果表明，SpecTUS显著优于标准数据库搜索技术，在28,267个光谱的测试集中实现了43%的化合物完美重构，其单一建议在76%的情况下优于混合搜索的结果，并且在10个建议的情况下实现了65%的完美重构，84%的结果优于混合搜索。</div>
</details>
</div>
<div class="card">
<div class="title">Unifying approach to uniform expressivity of graph neural networks</div>
<div class="meta-line">Authors: Huan Luo, Jonni Virtema</div>
<div class="meta-line">First: 2026-02-20T18:18:48+00:00 · Latest: 2026-02-20T18:18:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18409v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18409v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>统一图神经网络的均匀表达能力的方法</div>
<div class="mono" style="margin-top:8px">图神经网络（GNN）的表达能力通常通过与Weisfeiler-Leman（WL）算法和一阶逻辑片段的对应关系进行分析。标准GNN的限制在于只能对直接邻域或全局读出进行聚合。为了提高其表达能力，最近的尝试已将子结构信息（例如，循环计数和子图属性）纳入考虑。本文通过引入模板GNN（T-GNN）来形式化这一架构趋势，T-GNN是一个广义框架，其中节点特征通过聚合来自指定图模板集的有效模板嵌入进行更新。我们提出了相应的逻辑，分级模板模态逻辑（GML(T)），以及基于模板的双模拟和WL算法的广义概念。我们建立了T-GNN的表达能力与GML(T)之间的等价关系，并提供了一种统一的方法来分析GNN的表达能力：我们展示了标准AC-GNN及其最近变体如何被解释为T-GNN的实例。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the expressive power of Graph Neural Networks (GNNs), which are typically constrained to aggregating information from immediate neighborhoods or global read-outs. The authors introduce Template GNNs (T-GNNs), a generalized framework that updates node features by aggregating valid template embeddings from a specified set of graph templates. The key findings demonstrate an equivalence between the expressive power of T-GNNs and the proposed Graded template modal logic (GML(T)), providing a unified approach to analyze GNN expressivity and showing that standard AC-GNNs and their variants can be viewed as specific instances of T-GNNs.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于增强图神经网络（GNN）的表达能力，而GNN通常仅限于从直接邻域或全局读出中聚合信息。作者提出了模板GNN（T-GNN），这是一个通过从指定的图模板集合中聚合有效模板嵌入来更新节点特征的广义框架。他们建立了T-GNN的表达能力与一种新逻辑——分级模板模态逻辑（GML(T)）之间的等价关系，表明标准的AC-GNN及其最近变体可以被视为T-GNN的特定实例，从而提供了一种统一的GNN表达性分析方法。</div>
</details>
</div>
<div class="card">
<div class="title">Investigating Writing Professionals&#x27; Relationships with Generative AI: How Combined Perceptions of Rivalry and Collaboration Shape Work Practices and Outcomes</div>
<div class="meta-line">Authors: Rama Adithya Varanasi, Oded Nov, Batia Mishan Wiesenfeld</div>
<div class="meta-line">First: 2026-02-09T03:01:21+00:00 · Latest: 2026-02-20T18:18:05+00:00</div>
<div class="meta-line">Comments: CHI&#x27;2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.08227v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.08227v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This study investigates how professional writers&#x27; complex relationship with GenAI shapes their work practices and outcomes. Through a cross-sectional survey with writing professionals (n=403) in diverse roles, we show that collaboration and rivalry orientation are associated with differences in work practices and outcomes. Rivalry is primarily associated with relational crafting and skill maintenance. Collaboration is primarily associated with task crafting, productivity, and satisfaction, at the cost of long-term skill deterioration. Combination of the orientations (high rivalry and high collaboration) reconciles these differences, while boosting the association with the outcomes. Our findings argue for a balanced approach where high levels of rivalry and collaboration are essential to shape work practices and generate outcomes aimed at the long-term success of the job. We present key design implications on how to increase friction (rivalry) and reduce over-reliance (collaboration) to achieve a more balanced relationship with GenAI.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>调查写作专业人士与生成性人工智能的关系：竞争与合作的综合认知如何塑造工作实践和结果</div>
<div class="mono" style="margin-top:8px">本研究探讨了专业作家与生成性人工智能的复杂关系如何影响他们的工作实践和结果。通过对403名不同角色的写作专业人士进行横断面调查，我们发现合作和竞争取向与工作实践和结果的差异相关。竞争主要与关系构建和技能维护相关。合作主要与任务构建、生产力和满意度相关，但会导致长期技能退化。两种取向的结合（高竞争和高合作）调和了这些差异，同时增强了与结果的关联。我们的研究主张采取平衡的方法，高水平的竞争和合作对于塑造工作实践和产生旨在长期成功的结果至关重要。我们提出了关键设计启示，如何增加摩擦（竞争）和减少过度依赖（合作），以实现与生成性人工智能的更平衡关系。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study explores the intricate relationship between professional writers and generative AI, aiming to understand how perceptions of rivalry and collaboration influence their work practices and outcomes. Utilizing a cross-sectional survey of 403 writing professionals, the research identifies that rivalry is linked to relational crafting and skill maintenance, while collaboration correlates with task crafting, productivity, and satisfaction, albeit at the risk of long-term skill decline. The combination of high rivalry and high collaboration is found to reconcile these differences and enhance outcomes, suggesting that a balanced approach is crucial for long-term job success and offering design implications for optimizing the interaction with generative AI.</div>
<div class="mono" style="margin-top:8px">本研究探讨了专业作家与生成性人工智能之间复杂的关系，重点关注竞争和合作的认知如何影响他们的工作实践和成果。通过对403名不同角色的写作专业人士进行横断面调查，研究发现竞争主要与关系塑造和技能维护相关，而合作则与任务塑造、生产力和满意度相关，但可能导致长期技能下降。高竞争和高合作的结合被发现能够调和这些差异并增强积极成果，表明在与生成性人工智能的互动中，平衡的方法对写作专业人士的长期成功至关重要。</div>
</details>
</div>
<div class="card">
<div class="title">Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges</div>
<div class="meta-line">Authors: Minh Dinh, Stéphane Deny</div>
<div class="meta-line">First: 2026-02-20T18:14:05+00:00 · Latest: 2026-02-20T18:14:05+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18406v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18406v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>鲁棒对象识别的潜在等变算子：前景与挑战</div>
<div class="mono" style="margin-top:8px">尽管深度学习在计算机视觉中取得了成功，但在识别经历过训练中很少见的群体对称变换的对象时仍然存在困难，例如以不寻常的姿势、尺度、位置或其组合出现的对象。等变神经网络是解决跨对称变换泛化问题的方案，但需要事先了解变换。另一类架构提议从对称变换的示例中在潜在空间中学习等变算子。在这里，我们使用简单的旋转和平移的噪声MNIST数据集，展示了如何成功利用这些架构进行分布外分类，从而克服传统网络和等变网络的局限性。尽管在概念上引人入胜，但我们讨论了在将这些架构扩展到更复杂数据集时面临的挑战。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of recognizing objects that have undergone group-symmetric transformations, which are often not represented in training data. The authors propose a method using latent equivariant operators that learn from examples of symmetric transformations, rather than requiring prior knowledge of these transformations. Experimental results demonstrate that this approach effectively enables out-of-distribution classification on simple datasets like rotated and translated noisy MNIST, although the authors also highlight significant challenges in scaling these architectures to more complex datasets.</div>
<div class="mono" style="margin-top:8px">本研究解决了在现实场景中常见但在训练数据中缺乏的群对称变换下识别物体的挑战。作者提出了一种新方法，使用潜在等变算子从对称变换的示例中学习，而不是依赖于对这些变换的先验知识。实验结果表明，该方法在简单数据集（如旋转和平移的噪声MNIST）上有效改善了分布外分类，尽管作者也强调了将这些架构扩展到更复杂数据集时面临的重大挑战。</div>
</details>
</div>
<div class="card">
<div class="title">Wink: Recovering from Misbehaviors in Coding Agents</div>
<div class="meta-line">Authors: Rahul Nanda, Chandra Maddila, Smriti Jha, Euna Mehnaz Khan, Matteo Paltenghi, Satish Chandra</div>
<div class="meta-line">First: 2026-02-19T03:15:00+00:00 · Latest: 2026-02-20T18:13:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17037v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.17037v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user&#x27;s instructions, getting stuck in repetitive loops, or failing to use tools correctly. These failures disrupt the development workflow and often require resource-intensive manual intervention. In this paper, we present a system for automatically recovering from agentic misbehaviors at scale. We first introduce a taxonomy of misbehaviors grounded in an analysis of production traffic, identifying three primary categories: Specification Drift, Reasoning Problems, and Tool Call Failures, which we find occur in about 30% of all agent trajectories.
  To address these issues, we developed a lightweight, asynchronous self-intervention system named Wink. Wink observes agent trajectories and provides targeted course-correction guidance to nudge the agent back to a productive path. We evaluated our system on over 10,000 real world agent trajectories and found that it successfully resolves 90% of the misbehaviors that require a single intervention. Furthermore, a live A/B test in our production environment demonstrated that our system leads to a statistically significant reduction in Tool Call Failures, Tokens per Session and Engineer Interventions per Session. We present our experience designing and deploying this system, offering insights into the challenges of building resilient agentic systems at scale.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Wink：从编码代理的失误中恢复</div>
<div class="mono" style="margin-top:8px">自主编码代理，依靠大型语言模型（LLMs），在软件行业中越来越多地被采用以自动化复杂的工程任务。然而，这些代理容易出现各种失误，例如偏离用户指令、陷入重复循环或未能正确使用工具。这些失败会干扰开发工作流程，通常需要资源密集型的人工干预。在本文中，我们提出了一种系统，用于在大规模上自动恢复代理失误。我们首先介绍了一种基于生产流量分析的失误分类法，识别出三种主要类别：规范漂移、推理问题和工具调用失败，我们发现这些问题出现在约30%的代理轨迹中。为了解决这些问题，我们开发了一种轻量级的异步自我干预系统，名为Wink。Wink观察代理轨迹，并提供有针对性的纠正指导，以将代理引导回生产路径。我们在超过10,000个真实代理轨迹上评估了我们的系统，发现它成功解决了90%需要单次干预的失误。此外，在我们的生产环境中进行的实时A/B测试表明，我们的系统在工具调用失败、每次会话的令牌数和每次会话的工程师干预方面显著减少。我们分享了设计和部署该系统的经验，提供了构建大规模弹性代理系统的挑战的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the frequent misbehaviors of autonomous coding agents powered by large language models, which can disrupt software development workflows. The authors developed a lightweight, asynchronous self-intervention system called Wink, which categorizes misbehaviors into Specification Drift, Reasoning Problems, and Tool Call Failures, occurring in about 30% of agent trajectories. Evaluation of Wink on over 10,000 real-world agent trajectories showed that it successfully resolves 90% of misbehaviors requiring a single intervention and significantly reduces Tool Call Failures and engineer interventions in a live A/B test.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决由大型语言模型驱动的自主编码代理的误行为，这些误行为可能会干扰软件开发工作流程。作者开发了一个名为Wink的系统，该系统将误行为分为规范漂移、推理问题和工具调用失败，这些问题发生在大约30%的代理轨迹中。通过对超过10,000个真实世界代理轨迹的评估，Wink成功解决了90%需要单次干预的误行为，并在实时A/B测试中显示出工具调用失败和工程师干预的显著减少。</div>
</details>
</div>
<div class="card">
<div class="title">xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity</div>
<div class="meta-line">Authors: Maximilian Beck, Kajetan Schweighofer, Sebastian Böck, Sebastian Lehner, Sepp Hochreiter</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2025-10-02T17:14:34+00:00 · Latest: 2026-02-20T18:12:16+00:00</div>
<div class="meta-line">Comments: Accepted at ICLR 2026. Code and data available at https://github.com/NX-AI/xlstm_scaling_laws</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.02228v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.02228v2">PDF</a> · <a href="https://github.com/NX-AI/xlstm_scaling_laws">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Scaling laws play a central role in the success of Large Language Models (LLMs), enabling the prediction of model performance relative to compute budgets prior to training. While Transformers have been the dominant architecture, recent alternatives such as xLSTM offer linear complexity with respect to context length while remaining competitive in the billion-parameter regime. We conduct a comparative investigation on the scaling behavior of Transformers and xLSTM along the following lines, providing insights to guide future model design and deployment. First, we study the scaling behavior for xLSTM in compute-optimal and over-training regimes using both IsoFLOP and parametric fit approaches on a wide range of model sizes (80M-7B) and number of training tokens (2B-2T). Second, we examine the dependence of optimal model sizes on context length, a pivotal aspect that was largely ignored in previous work. Finally, we analyze inference-time scaling characteristics. Our findings reveal that in typical LLM training and inference scenarios, xLSTM scales favorably compared to Transformers. Notably, xLSTM models consistently Pareto-dominate Transformer models, delivering lower cross-entropy loss for the same compute budget.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>xLSTM缩放法则：线性时间复杂度下的竞争性能</div>
<div class="mono" style="margin-top:8px">缩放法则在大型语言模型（LLMs）的成功中发挥着核心作用，使得在训练之前能够预测模型性能与计算预算的关系。尽管变换器（Transformers）一直是主导架构，但最近的替代方案如xLSTM在上下文长度方面提供了线性复杂度，同时在十亿参数范围内保持竞争力。我们对变换器和xLSTM的缩放行为进行了比较研究，提供了指导未来模型设计和部署的见解。首先，我们使用IsoFLOP和参数拟合方法研究了xLSTM在计算最优和过度训练状态下的缩放行为，涵盖了广泛的模型规模（80M-7B）和训练标记数量（2B-2T）。其次，我们考察了最优模型规模对上下文长度的依赖，这是之前工作中被忽视的关键方面。最后，我们分析了推理时间的缩放特性。我们的发现表明，在典型的LLM训练和推理场景中，xLSTM的缩放表现优于变换器。值得注意的是，xLSTM模型在相同计算预算下始终优于变换器模型，提供了更低的交叉熵损失。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to explore the scaling laws of Large Language Models (LLMs) and to evaluate the performance of xLSTM as a competitive alternative to the dominant Transformer architecture, particularly in terms of linear time complexity. The authors conducted a comparative analysis of the scaling behavior of xLSTM and Transformers by examining various model sizes and training token counts, utilizing both IsoFLOP and parametric fit approaches. The key findings indicate that xLSTM models outperform Transformers in typical training and inference scenarios, consistently achieving lower cross-entropy loss for the same compute budget, thereby suggesting a favorable scaling behavior for xLSTM compared to Transformers.</div>
<div class="mono" style="margin-top:8px">本研究探讨了大型语言模型（LLMs）的扩展规律，以增强模型性能相对于计算预算的预测。该研究采用比较分析方法，研究了变压器和xLSTM之间的扩展行为，重点关注不同模型规模和训练令牌下的计算最优和过度训练状态。结果表明，在典型的训练和推理场景中，xLSTM始终优于变压器，在相同的计算预算下实现了更低的交叉熵损失，从而暗示其在未来模型设计和部署中的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">Scientific Knowledge-Guided Machine Learning for Vessel Power Prediction: A Comparative Study</div>
<div class="meta-line">Authors: Orfeas Bourchas, George Papalambrou</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2026-02-20T18:12:14+00:00 · Latest: 2026-02-20T18:12:14+00:00</div>
<div class="meta-line">Comments: Accepted to the KGML Bridge at AAAI 2026 (non-archival)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18403v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18403v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate prediction of main engine power is essential for vessel performance optimization, fuel efficiency, and compliance with emission regulations. Conventional machine learning approaches, such as Support Vector Machines, variants of Artificial Neural Networks (ANNs), and tree-based methods like Random Forests, Extra Tree Regressors, and XGBoost, can capture nonlinearities but often struggle to respect the fundamental propeller law relationship between power and speed, resulting in poor extrapolation outside the training envelope. This study introduces a hybrid modeling framework that integrates physics-based knowledge from sea trials with data-driven residual learning. The baseline component, derived from calm-water power curves of the form $P = cV^n$, captures the dominant power-speed dependence, while another, nonlinear, regressor is then trained to predict the residual power, representing deviations caused by environmental and operational conditions. By constraining the machine learning task to residual corrections, the hybrid model simplifies learning, improves generalization, and ensures consistency with the underlying physics. In this study, an XGBoost, a simple Neural Network, and a Physics-Informed Neural Network (PINN) coupled with the baseline component were compared to identical models without the baseline component. Validation on in-service data demonstrates that the hybrid model consistently outperformed a pure data-driven baseline in sparse data regions while maintaining similar performance in populated ones. The proposed framework provides a practical and computationally efficient tool for vessel performance monitoring, with applications in weather routing, trim optimization, and energy efficiency planning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于科学知识的机器学习在船舶动力预测中的应用：比较研究</div>
<div class="mono" style="margin-top:8px">准确预测主机功率对船舶性能优化、燃油效率和遵守排放法规至关重要。传统的机器学习方法，如支持向量机、人工神经网络（ANN）的变体以及基于树的方法（如随机森林、额外树回归器和XGBoost），能够捕捉非线性关系，但往往难以遵循功率与速度之间的基本螺旋桨定律关系，导致在训练范围外的外推效果不佳。本研究提出了一种混合建模框架，将来自海试的基于物理的知识与数据驱动的残差学习相结合。基线组件源自形式为$P = cV^n$的平静水域功率曲线，捕捉了主导的功率-速度依赖关系，而另一个非线性回归器则被训练以预测残余功率，代表由环境和操作条件引起的偏差。通过将机器学习任务限制为残差修正，混合模型简化了学习，提高了泛化能力，并确保与基础物理的一致性。在本研究中，比较了XGBoost、简单神经网络和与基线组件耦合的物理信息神经网络（PINN）与没有基线组件的相同模型。在在役数据上的验证表明，混合模型在稀疏数据区域始终优于纯数据驱动的基线，同时在数据密集区域保持相似的性能。所提出的框架为船舶性能监测提供了一种实用且计算高效的工具，适用于天气路线规划、吃水优化和能效规划。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the accuracy of main engine power predictions for vessels, which is crucial for optimizing performance, fuel efficiency, and meeting emission regulations. The study employs a hybrid modeling framework that combines physics-based knowledge from sea trials with data-driven residual learning, where a baseline model captures the primary power-speed relationship and a nonlinear regressor predicts residual power deviations. Experimental results indicate that this hybrid model outperforms traditional data-driven approaches, particularly in sparse data regions, while maintaining comparable performance in more populated areas, thus offering a practical tool for vessel performance monitoring and optimization.</div>
<div class="mono" style="margin-top:8px">本研究的动机是提高船舶主机功率预测的准确性，这对优化性能、提高燃油效率和遵守排放法规至关重要。该研究采用了一种混合建模框架，将来自海试的基于物理的知识与数据驱动的残差学习相结合，使用从平静水域功率曲线得出的基线组件来捕捉功率与速度之间的关系，同时使用非线性回归器预测残差功率偏差。实验结果表明，该混合模型在稀疏数据区域的表现始终优于传统的数据驱动方法，而在数据较为密集的区域则保持了相似的性能，从而为船舶性能监测和优化提供了一种实用工具。</div>
</details>
</div>
<div class="card">
<div class="title">Leakage and Second-Order Dynamics Improve Hippocampal RNN Replay</div>
<div class="meta-line">Authors: Josue Casco-Rodriguez, Nanda H. Krishna, Richard G. Baraniuk</div>
<div class="meta-line">First: 2026-02-20T18:07:09+00:00 · Latest: 2026-02-20T18:07:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18401v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18401v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Biological neural networks (like the hippocampus) can internally generate &quot;replay&quot; resembling stimulus-driven activity. Recent computational models of replay use noisy recurrent neural networks (RNNs) trained to path-integrate. Replay in these networks has been described as Langevin sampling, but new modifiers of noisy RNN replay have surpassed this description. We re-examine noisy RNN replay as sampling to understand or improve it in three ways: (1) Under simple assumptions, we prove that the gradients replay activity should follow are time-varying and difficult to estimate, but readily motivate the use of hidden state leakage in RNNs for replay. (2) We confirm that hidden state adaptation (negative feedback) encourages exploration in replay, but show that it incurs non-Markov sampling that also slows replay. (3) We propose the first model of temporally compressed replay in noisy path-integrating RNNs through hidden state momentum, connect it to underdamped Langevin sampling, and show that, together with adaptation, it counters slowness while maintaining exploration. We verify our findings via path-integration of 2D triangular and T-maze paths and of high-dimensional paths of synthetic rat place cell activity.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>泄漏和二阶动态改善海马体RNN重放</div>
<div class="mono" style="margin-top:8px">生物神经网络（如海马体）可以内部生成类似于刺激驱动活动的“重放”。最近的重放计算模型使用了经过训练的噪声递归神经网络（RNN）进行路径积分。这些网络中的重放被描述为朗之万采样，但新的噪声RNN重放修饰符已超越了这一描述。我们重新审视噪声RNN重放作为采样，以三种方式理解或改善它：（1）在简单假设下，我们证明重放活动应遵循的梯度是时间变化的且难以估计，但很容易激励在RNN中使用隐藏状态泄漏进行重放。（2）我们确认隐藏状态适应（负反馈）鼓励重放中的探索，但显示它会导致非马尔可夫采样，从而减慢重放速度。（3）我们提出了第一个在噪声路径积分RNN中通过隐藏状态动量实现的时间压缩重放模型，将其与欠阻尼朗之万采样联系起来，并显示它与适应结合可以抵消减慢，同时保持探索。我们通过对2D三角形和T迷宫路径以及合成大鼠位置细胞活动的高维路径进行路径积分验证了我们的发现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the mechanisms behind replay activity in biological neural networks, specifically focusing on the hippocampus and its resemblance to stimulus-driven activity. The authors employ noisy recurrent neural networks (RNNs) to analyze replay dynamics, introducing concepts such as hidden state leakage and adaptation to enhance exploration during replay. Key findings reveal that while hidden state adaptation promotes exploration, it also leads to non-Markov sampling that slows down replay; however, the introduction of hidden state momentum in their model allows for temporally compressed replay, effectively balancing exploration and speed, as validated through path-integration experiments involving various maze configurations and synthetic neural activity data.</div>
<div class="mono" style="margin-top:8px">本研究探讨了生物神经网络（特别是海马体）中的重放机制，旨在增强对用于路径积分的噪声递归神经网络（RNNs）性能的理解。作者采用理论方法分析重放的动态，证明重放活动的梯度是时间变化的，并倡导在RNN中引入隐藏状态泄漏。主要发现表明，尽管隐藏状态适应促进了重放过程中的探索，但也引入了非马尔可夫采样，导致重放速度减慢；然而，结合适应引入隐藏状态动量可以实现时间压缩的重放，提高效率而不牺牲探索性，这一结果通过多种路径积分实验得到了验证。</div>
</details>
</div>
<div class="card">
<div class="title">PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing</div>
<div class="meta-line">Authors: Ehsan Lari, Reza Arablouei, Stefan Werner</div>
<div class="meta-line">First: 2026-02-20T18:01:59+00:00 · Latest: 2026-02-20T18:01:59+00:00</div>
<div class="meta-line">Comments: 13 pages, 5 figures, 2 tables, Submitted to IEEE Transactions on Signal Processing (TSP)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18396v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18396v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose PRISM-FCP (Partial shaRing and robust calIbration with Statistical Margins for Federated Conformal Prediction), a Byzantine-resilient federated conformal prediction framework that utilizes partial model sharing to improve robustness against Byzantine attacks during both model training and conformal calibration. Existing approaches address adversarial behavior only in the calibration stage, leaving the learned model susceptible to poisoned updates. In contrast, PRISM-FCP mitigates attacks end-to-end. During training, clients partially share updates by transmitting only $M$ of $D$ parameters per round. This attenuates the expected energy of an adversary&#x27;s perturbation in the aggregated update by a factor of $M/D$, yielding lower mean-square error (MSE) and tighter prediction intervals. During calibration, clients convert nonconformity scores into characterization vectors, compute distance-based maliciousness scores, and downweight or filter suspected Byzantine contributions before estimating the conformal quantile. Extensive experiments on both synthetic data and the UCI Superconductivity dataset demonstrate that PRISM-FCP maintains nominal coverage guarantees under Byzantine attacks while avoiding the interval inflation observed in standard FCP with reduced communication, providing a robust and communication-efficient approach to federated uncertainty quantification.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PRISM-FCP：通过部分共享实现拜占庭弹性的联邦符合预测</div>
<div class="mono" style="margin-top:8px">我们提出了PRISM-FCP（部分共享和具有统计边际的稳健校准的联邦符合预测），这是一个拜占庭弹性的联邦符合预测框架，利用部分模型共享来提高对拜占庭攻击的稳健性，适用于模型训练和符合校准阶段。现有方法仅在校准阶段解决对抗行为，使得学习到的模型易受污染更新的影响。相比之下，PRISM-FCP在端到端上减轻攻击。在训练过程中，客户端通过每轮仅传输$M$个参数中的$D$个部分共享更新。这通过$M/D$的因子减弱了对手在聚合更新中的扰动的预期能量，从而降低均方误差（MSE）并收紧预测区间。在校准过程中，客户端将非符合性分数转换为特征向量，计算基于距离的恶意分数，并在估计符合分位数之前降低或过滤可疑的拜占庭贡献。在合成数据和UCI超导数据集上的大量实验表明，PRISM-FCP在拜占庭攻击下保持名义覆盖保证，同时避免了标准FCP中观察到的区间膨胀，并减少了通信，提供了一种稳健且通信高效的联邦不确定性量化方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the robustness of federated conformal prediction frameworks against Byzantine attacks, which can compromise model integrity during training and calibration. The proposed method, PRISM-FCP, employs partial model sharing where clients transmit only a fraction of model parameters per round, thereby reducing the impact of adversarial perturbations. Experimental results on synthetic data and the UCI Superconductivity dataset show that PRISM-FCP achieves lower mean-square error and tighter prediction intervals while maintaining nominal coverage guarantees under Byzantine attacks, all with reduced communication overhead compared to standard approaches.</div>
<div class="mono" style="margin-top:8px">本研究的动机是增强联邦符合预测框架对拜占庭攻击的鲁棒性，这种攻击可能在训练和校准过程中损害模型的完整性。提出的方法PRISM-FCP采用部分模型共享，客户端仅传输一部分模型参数，从而减少对抗性扰动的影响。实验结果表明，PRISM-FCP在拜占庭攻击下仍能保持名义覆盖保证，同时实现更低的均方误差和更紧的预测区间，证明其在联邦不确定性量化中提供了一种鲁棒且高效的通信解决方案。</div>
</details>
</div>
<div class="card">
<div class="title">Self-Aware Object Detection via Degradation Manifolds</div>
<div class="meta-line">Authors: Stefan Becker, Simon Weiss, Wolfgang Hübner, Michael Arens</div>
<div class="meta-line">First: 2026-02-20T17:58:46+00:00 · Latest: 2026-02-20T17:58:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18394v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18394v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector&#x27;s nominal operating regime. We refer to this capability as self-aware object detection.
  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector&#x27;s feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.
  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.
  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过降级流形实现自我意识物体检测</div>
<div class="mono" style="margin-top:8px">物体检测器在正常成像条件下表现强劲，但在模糊、噪声、压缩、不利天气或分辨率变化时可能会无声失败。因此，在安全关键的环境中，仅仅生成预测而不评估输入是否仍在检测器的正常操作范围内是不够的。我们将这种能力称为自我意识物体检测。
我们引入了一种基于降级流形的降级感知自我意识框架，该框架根据图像降级而非语义内容明确构建检测器的特征空间。我们的方法通过多层对比学习增强了标准检测骨干，使用轻量级嵌入头进行训练。共享相同降级组成的图像被拉近，而不同降级配置的图像被推远，从而产生几何组织的表示，捕捉降级类型和严重性，而无需降级标签或显式密度建模。
为了锚定学习到的几何形状，我们从干净的训练嵌入中估计出一个原始原型，定义表示空间中的正常操作点。自我意识表现为与该参考的几何偏差，提供了一种内在的、图像级的降级引起的偏移信号，与检测置信度无关。
在合成损坏基准、跨数据集零样本迁移和自然天气引起的分布变化上的广泛实验表明，干净与降级之间的可分离性强，多个检测器架构下行为一致，并且在语义变化下具有强大的泛化能力。这些结果表明，降级感知表示几何为实际和检测器无关的基础提供了支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance object detection systems&#x27; reliability in safety-critical environments by enabling them to assess input conditions and detect when they fall outside nominal operating regimes due to various degradations. The authors propose a degradation-aware self-awareness framework that organizes a detector&#x27;s feature space based on image degradation using a lightweight embedding head trained through multi-layer contrastive learning. Experimental results show strong separation between pristine and degraded images across synthetic corruption benchmarks and real-world conditions, demonstrating consistent performance across different detector architectures and robust generalization despite semantic shifts.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高物体检测系统在各种不利条件下的可靠性，因为传统检测器在面对图像退化时常常会无声失败。作者提出了一种基于退化流形的自我意识框架，该框架通过多层对比学习训练的轻量级嵌入头，根据图像退化组织检测器的特征空间。实验结果表明，该方法在原始图像和退化图像之间实现了强分离，在不同检测器架构中表现一致，并在语义变化下展现出强大的泛化能力，表明所提出的表示几何有效且适用于各种检测系统。</div>
</details>
</div>
<div class="card">
<div class="title">ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees</div>
<div class="meta-line">Authors: David Smith Sundarsingh, Jun Wang, Jyotirmoy V. Deshmukh, Yiannis Kantaros</div>
<div class="meta-line">First: 2025-04-22T20:32:34+00:00 · Latest: 2026-02-20T17:50:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.21022v2">Abs</a> · <a href="https://arxiv.org/pdf/2504.21022v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Linear Temporal Logic (LTL) is a widely used task specification language for autonomous systems. To mitigate the significant manual effort and expertise required to define LTL-encoded tasks, several methods have been proposed for translating Natural Language (NL) instructions into LTL formulas, which, however, lack correctness guarantees. To address this, we propose a new NL-to-LTL translation method, called ConformalNL2LTL that achieves user-defined translation success rates on unseen NL commands. Our method constructs LTL formulas iteratively by solving a sequence of open-vocabulary question-answering (QA) problems using large language models (LLMs). These QA tasks are handled collaboratively by a primary and an auxiliary model. The primary model answers each QA instance while quantifying uncertainty via conformal prediction; when it is insufficiently certain according to user-defined confidence thresholds, it requests assistance from the auxiliary model and, if necessary, from the user. We demonstrate theoretically and empirically that ConformalNL2LTL achieves the desired translation accuracy while minimizing user intervention.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ConformalNL2LTL：将自然语言指令翻译为具有保形正确性保证的时序逻辑公式</div>
<div class="mono" style="margin-top:8px">线性时序逻辑（LTL）是自主系统中广泛使用的任务规范语言。为了减少定义LTL编码任务所需的显著手动工作和专业知识，提出了几种将自然语言（NL）指令翻译为LTL公式的方法，但这些方法缺乏正确性保证。为了解决这个问题，我们提出了一种新的NL到LTL翻译方法，称为ConformalNL2LTL，它在未见的NL命令上实现用户定义的翻译成功率。我们的方法通过使用大型语言模型（LLMs）迭代地构建LTL公式，解决一系列开放词汇的问题回答（QA）问题。这些QA任务由主模型和辅助模型协作处理。主模型回答每个QA实例，同时通过保形预测量化不确定性；当根据用户定义的置信阈值不够确定时，它请求辅助模型的帮助，并在必要时请求用户的协助。我们理论和实证地证明，ConformalNL2LTL在最小化用户干预的同时实现了所需的翻译准确性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to reduce the manual effort and expertise needed to define Linear Temporal Logic (LTL) tasks for autonomous systems by improving the translation of Natural Language (NL) instructions into LTL formulas with correctness guarantees. The authors propose a novel method called ConformalNL2LTL, which constructs LTL formulas iteratively through a series of open-vocabulary question-answering tasks using large language models, with a primary model assessing uncertainty and an auxiliary model providing support when needed. Experimental results show that ConformalNL2LTL achieves user-defined translation success rates on unseen NL commands while ensuring high translation accuracy and minimizing user intervention.</div>
<div class="mono" style="margin-top:8px">本研究的动机是减少将自然语言（NL）指令翻译为线性时序逻辑（LTL）公式所需的人工努力和专业知识，因为现有方法缺乏正确性保证。作者提出了一种新方法，称为ConformalNL2LTL，该方法通过使用大型语言模型解决开放词汇问答问题，迭代构建LTL公式，主要模型评估不确定性，并在必要时寻求辅助模型或用户的帮助。实验结果表明，ConformalNL2LTL在未见的NL指令上实现了用户定义的翻译成功率，同时确保高翻译准确性，且用户干预最小。</div>
</details>
</div>
<div class="card">
<div class="title">Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO</div>
<div class="meta-line">Authors: Mohamed Elgouhary, Amr S. El-Wakeel</div>
<div class="meta-line">First: 2026-02-20T17:48:21+00:00 · Latest: 2026-02-20T17:48:21+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18386v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18386v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在自主赛车中学习调整纯追踪：使用PPO的联合前视和转向增益控制</div>
<div class="mono" style="margin-top:8px">纯追踪（PP）因其高效性和几何清晰性在自主赛车中广泛用于实时路径跟踪，但性能对关键参数（前视距离和转向增益）的选择非常敏感。标准的基于速度的调度仅大致调整这些参数，且常常无法在不同赛道和速度特征间转移。我们提出了一种强化学习（RL）方法，使用近端策略优化（PPO）在线联合选择前视距离Ld和转向增益g。该策略在每个控制步骤观察紧凑的状态特征（速度和曲率）并输出（Ld，g）。在F1TENTH Gym中训练并部署在ROS 2堆栈中，该策略直接驱动PP（轻微平滑），无需每个地图重新调整。在仿真和真实汽车测试中，所提出的RL-PP控制器联合选择（Ld，g）始终优于固定前视PP、基于速度调度的自适应PP和仅前视的RL变体，并且在我们评估的设置中在圈速、路径跟踪精度和转向平滑度方面超过了运动学MPC赛道跟踪器，证明了策略引导的参数调整可以可靠地改善基于经典几何的控制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the performance of Pure Pursuit (PP) in autonomous racing, which is sensitive to the selection of key parameters like lookahead distance and steering gain. The authors propose a reinforcement learning approach using Proximal Policy Optimization (PPO) to jointly optimize these parameters in real-time based on state features such as speed and curvature. Experimental results show that the RL-PP controller significantly outperforms traditional fixed-lookahead PP and other adaptive methods in terms of lap time, path-tracking accuracy, and steering smoothness, indicating that policy-guided tuning can effectively enhance classical control methods.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高自主赛车中纯追踪（PP）的性能，该性能对关键参数如前瞻距离和转向增益的选择非常敏感。作者提出了一种使用近端策略优化（PPO）的强化学习方法，实时联合优化这些参数，基于速度和曲率等紧凑状态特征。实验结果表明，RL-PP控制器在圈速、路径跟踪精度和转向平滑性方面显著优于传统的固定前瞻PP、基于速度调度的自适应PP和仅考虑前瞻的RL变体，表明基于策略的调优可以有效增强经典控制方法。</div>
</details>
</div>
<div class="card">
<div class="title">FedZMG: Efficient Client-Side Optimization in Federated Learning</div>
<div class="meta-line">Authors: Fotios Zantalis, Evangelos Zervas, Grigorios Koulouras</div>
<div class="meta-line">First: 2026-02-20T17:45:28+00:00 · Latest: 2026-02-20T17:45:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18384v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18384v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the &quot;intensity&quot; or &quot;bias&quot; shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FedZMG：联邦学习中的高效客户端优化</div>
<div class="mono" style="margin-top:8px">联邦学习（FL）使得在边缘设备上进行分布式模型训练，同时保护数据隐私。然而，客户端往往具有非独立同分布（non-IID）数据，这通常导致客户端漂移，从而降低收敛速度和模型性能。虽然提出了自适应优化器来缓解这些影响，但它们通常引入了不适合资源受限的物联网环境的计算复杂性或通信开销。本文介绍了联邦零均值梯度（FedZMG），一种新颖的无参数客户端优化算法，旨在通过结构性正则化优化空间来应对客户端漂移。FedZMG推进了梯度中心化的理念，将局部梯度投影到零均值超平面，有效中和了异构数据分布中固有的“强度”或“偏差”变化，而无需额外的通信或超参数调整。提供了理论分析，证明FedZMG降低了有效梯度方差，并保证了比标准FedAvg更紧的收敛界限。在EMNIST、CIFAR100和莎士比亚数据集上的广泛实证评估表明，FedZMG在高度非独立同分布的环境中实现了比基线FedAvg和自适应优化器FedAdam更好的收敛速度和最终验证准确率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges posed by non-IID data in Federated Learning, which can lead to client-drift and negatively impact model performance. The authors propose a novel client-side optimization algorithm called Federated Zero Mean Gradients (FedZMG), which regularizes the optimization space by projecting local gradients onto a zero-mean hyperplane, thus mitigating the effects of data heterogeneity without incurring additional communication costs or hyperparameter tuning. Experimental results on EMNIST, CIFAR100, and Shakespeare datasets show that FedZMG significantly improves convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, especially in scenarios with highly non-IID data distributions.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决联邦学习中非独立同分布（non-IID）数据带来的挑战，这可能导致客户端漂移并阻碍模型性能。作者提出了一种名为联邦零均值梯度（FedZMG）的新型客户端优化算法，通过将局部梯度投影到零均值超平面上来规范优化空间，从而避免了额外通信或超参数调整的需求。对EMNIST、CIFAR100和莎士比亚数据集的实验结果表明，FedZMG在高度非IID数据分布的情况下，显著提高了收敛速度和最终验证准确性，相较于基线FedAvg和自适应优化器FedAdam表现更佳。</div>
</details>
</div>
<div class="card">
<div class="title">Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in Reinforcement Learning</div>
<div class="meta-line">Authors: Tiberiu-Andrei Georgescu, Alexander W. Goodall, Dalal Alrajeh, Francesco Belardinelli, Sebastian Uchitel</div>
<div class="meta-line">First: 2025-11-04T14:27:28+00:00 · Latest: 2026-02-20T17:44:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.02605v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.02605v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Shielding is widely used to enforce safety in reinforcement learning (RL), ensuring that an agent&#x27;s actions remain compliant with formal specifications. Classical shielding approaches, however, are often static, in the sense that they assume fixed logical specifications and hand-crafted abstractions. While these static shields provide safety under nominal assumptions, they fail to adapt when environment assumptions are violated. In this paper, we develop an adaptive shielding framework based on based on Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and expressive fragment of Linear Temporal Logic (LTL) that captures both safety and liveness properties. Our method detects environment assumption violations at runtime and employs Inductive Logic Programming (ILP) to automatically repair GR(1) specifications online, in a systematic and interpretable way. This ensures that the shield evolves gracefully, ensuring liveness is achievable and minimally weakening goals only when necessary. We consider two case studies: Minepump and Atari Seaquest; showing that (i) static symbolic controllers are often severely suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped with our adaptive shield maintain near-optimal reward and perfect logical compliance compared with static shields.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于强化学习中保持活性保护的自适应 GR(1) 规范修复</div>
<div class="mono" style="margin-top:8px">保护在强化学习 (RL) 中被广泛使用，以确保代理的行为符合正式规范。然而，经典的保护方法通常是静态的，因为它们假设固定的逻辑规范和手工制作的抽象。虽然这些静态保护在名义假设下提供安全性，但在环境假设被违反时，它们无法适应。本文提出了一种基于 GR(1) 规范的自适应保护框架，GR(1) 是线性时序逻辑 (LTL) 的一个可处理且表达丰富的片段，能够捕捉安全性和活性属性。我们的方法在运行时检测环境假设的违反，并采用归纳逻辑编程 (ILP) 在线自动修复 GR(1) 规范，以系统和可解释的方式进行。这确保了保护能够优雅地演变，确保活性可实现，并在必要时仅最小化目标的削弱。我们考虑了两个案例研究：Minepump 和 Atari Seaquest；显示 (i) 静态符号控制器在优化辅助奖励时往往严重次优，以及 (ii) 配备我们自适应保护的 RL 代理与静态保护相比，保持近乎最优的奖励和完美的逻辑合规性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance safety in reinforcement learning (RL) through adaptive shielding that can respond to violations of environment assumptions, as traditional static shielding methods are insufficient in dynamic contexts. The authors propose an adaptive shielding framework utilizing Generalized Reactivity of rank 1 (GR(1)) specifications, which allows for real-time detection of assumption violations and employs Inductive Logic Programming (ILP) to repair specifications systematically. Experimental results from case studies on Minepump and Atari Seaquest demonstrate that static symbolic controllers are often suboptimal for optimizing auxiliary rewards, while RL agents using the adaptive shield achieve near-optimal rewards and maintain perfect logical compliance, outperforming static shields.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于通过开发一种能够适应环境假设违反的屏蔽框架来增强强化学习（RL）的安全性，因为传统的静态屏蔽方法在动态环境中不足以应对。作者提出了一种基于广义反应性等级1（GR(1)）规范的自适应屏蔽方法，该方法利用归纳逻辑编程（ILP）实时修复规范。对Minepump和Atari Seaquest的案例研究表明，静态符号控制器在优化辅助奖励时往往表现不佳，而使用自适应屏蔽的RL代理则实现了接近最优的奖励，并与静态屏蔽相比，保持了完美的逻辑合规性。</div>
</details>
</div>
<div class="card">
<div class="title">Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach</div>
<div class="meta-line">Authors: Markus Gross, Hans-Martin Rieser</div>
<div class="meta-line">First: 2026-02-20T17:33:27+00:00 · Latest: 2026-02-20T17:33:27+00:00</div>
<div class="meta-line">Comments: 34 pages, 12 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18377v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18377v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>量子极限学习机的理论与可解释性：一种保利传输矩阵方法</div>
<div class="mono" style="margin-top:8px">量子水库计算机（QRCs）作为量子机器学习的一种有前景的方法，利用量子系统的自然动态进行数据处理，并且训练简单。本文考虑具有连续时间水库动态的n量子比特量子极限学习机（QELMs）。QELMs是无记忆的QRCs，能够执行各种机器学习任务，包括图像分类和时间序列预测。我们应用保利传输矩阵（PTM）形式主义来理论分析编码、水库动态和测量操作（包括时间复用）对QELM性能的影响。该形式主义明确表明，编码决定了QELM可用的完整（非线性）特征集，而量子通道在线性变换这些特征后，由所选择的测量算子进行探测。因此，优化QELM可以被视为一个解码问题，其中塑造通道引起的变换，使得与任务相关的特征可用于回归器。PTM形式主义使人能够识别QELM的经典表示，从而指导其设计以实现特定的训练目标。作为具体应用，我们专注于学习非线性动态系统，并展示了在此类轨迹上训练的QELM学习到对基础流映射的替代近似。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the potential of quantum extreme learning machines (QELMs) as a novel approach to quantum machine learning, motivated by their ability to leverage quantum dynamics for efficient data processing. The study employs the Pauli transfer matrix (PTM) formalism to analyze how encoding, reservoir dynamics, and measurement operations affect QELM performance. Key findings reveal that the encoding dictates the available nonlinear features for the QELM, and optimizing the QELM can be framed as a decoding problem, ultimately demonstrating that a QELM can effectively learn surrogate approximations of nonlinear dynamical systems from training trajectories.</div>
<div class="mono" style="margin-top:8px">本研究探讨了量子极限学习机（QELM）作为有效的量子储备计算机在机器学习任务中的潜力，动机在于其利用量子动态进行数据处理的能力。作者采用保利转移矩阵（PTM）形式主义分析编码、储备动态和测量操作对QELM性能的影响。主要发现表明，编码定义了QELM可访问的非线性特征集，优化QELM可以被视为解码问题，从而增强模型从非线性动态系统中学习的能力，近似底层流映射。</div>
</details>
</div>
<div class="card">
<div class="title">Zero-shot Interactive Perception</div>
<div class="meta-line">Authors: Venkatesh Sripada, Frank Guerin, Amir Ghalamzan</div>
<div class="meta-line">First: 2026-02-20T17:30:25+00:00 · Latest: 2026-02-20T17:30:25+00:00</div>
<div class="meta-line">Comments: Original manuscript submitted on April 24, 2025. Timestamped and publicly available on OpenReview: https://openreview.net/forum?id=7MhpFcr5Nx</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18374v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18374v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM&#x27;s visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>零-shot互动感知</div>
<div class="mono" style="margin-top:8px">互动感知（IP）使机器人能够提取工作空间中的隐藏信息，并通过与物体的物理交互和改变环境状态来执行操作计划——这对于解决复杂、部分可观察场景中的遮挡和模糊至关重要。我们提出了零-shot IP（ZS-IP），这是一个新颖的框架，将多策略操作（推和抓）与基于记忆的视觉语言模型（VLM）结合起来，以指导机器人交互并解决语义查询。ZS-IP集成了三个关键组件：（1）增强观察（EO）模块，通过常规关键点和我们提出的推线增强VLM的视觉感知——一种针对推动作的新型2D视觉增强，（2）基于记忆的动作模块，通过上下文查找增强语义推理，以及（3）一个机器人控制器，根据VLM输出执行推、拉或抓取。与针对拾取和放置优化的基于网格的增强不同，推线捕捉了接触丰富动作的可用性，显著提高了推的性能。我们在具有不同遮挡和任务复杂性的多样场景中，对7自由度的Franka Panda臂进行了ZS-IP的评估。我们的实验表明，ZS-IP在推任务中优于被动和基于视角的感知技术，如基于标记的视觉提示（MOKA），同时保持非目标元素的完整性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance interactive perception in robotics, allowing robots to better extract hidden information and execute manipulation tasks in complex environments. The authors introduce Zero-Shot Interactive Perception (ZS-IP), a framework that combines multi-strategy manipulation techniques with a memory-driven Vision Language Model to facilitate robotic interactions and resolve semantic queries. Experimental results show that ZS-IP significantly outperforms existing methods, particularly in pushing tasks, by effectively utilizing pushlines for contact-rich actions, thus improving performance in scenarios with varying occlusions and task complexities.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于增强机器人与环境互动的能力，并通过交互感知（IP）解决复杂场景中的模糊性。作者提出了一种名为零-shot IP（ZS-IP）的新框架，该框架结合了多策略操作技术和基于记忆的视觉语言模型（VLM），以促进机器人互动和语义推理。实验结果表明，ZS-IP在推送任务中显著优于传统的被动和基于视角的感知方法，同时有效保持了在不同遮挡和复杂场景中非目标元素的完整性。</div>
</details>
</div>
<div class="card">
<div class="title">&quot;How Do I ...?&quot;: Procedural Questions Predominate Student-LLM Chatbot Conversations</div>
<div class="meta-line">Authors: Alexandra Neagu, Marcus Messer, Peter Johnson, Rhodri Nelson</div>
<div class="meta-line">First: 2026-02-20T17:27:41+00:00 · Latest: 2026-02-20T17:27:41+00:00</div>
<div class="meta-line">Comments: 14 pages, 2 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18372v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18372v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Providing scaffolding through educational chatbots built on Large Language Models (LLM) has potential risks and benefits that remain an open area of research. When students navigate impasses, they ask for help by formulating impasse-driven questions. Within interactions with LLM chatbots, such questions shape the user prompts and drive the pedagogical effectiveness of the chatbot&#x27;s response. This paper focuses on such student questions from two datasets of distinct learning contexts: formative self-study, and summative assessed coursework. We analysed 6,113 messages from both learning contexts, using 11 different LLMs and three human raters to classify student questions using four existing schemas. On the feasibility of using LLMs as raters, results showed moderate-to-good inter-rater reliability, with higher consistency than human raters. The data showed that &#x27;procedural&#x27; questions predominated in both learning contexts, but more so when students prepare for summative assessment. These results provide a basis on which to use LLMs for classification of student questions. However, we identify clear limitations in both the ability to classify with schemas and the value of doing so: schemas are limited and thus struggle to accommodate the semantic richness of composite prompts, offering only partial understanding the wider risks and benefits of chatbot integration. In the future, we recommend an analysis approach that captures the nuanced, multi-turn nature of conversation, for example, by applying methods from conversation analysis in discursive psychology.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>&quot;我该如何...?&quot;: 程序性问题主导学生与LLM聊天机器人的对话</div>
<div class="mono" style="margin-top:8px">通过基于大型语言模型（LLM）构建的教育聊天机器人提供支架，存在潜在的风险和收益，这仍然是一个开放的研究领域。当学生遇到障碍时，他们通过提出以障碍为驱动的问题来寻求帮助。在与LLM聊天机器人的互动中，这类问题塑造了用户提示，并推动了聊天机器人响应的教学有效性。本文关注来自两个不同学习背景的数据集中的学生问题：形成性自学和总结性评估课程。我们分析了来自这两种学习背景的6,113条消息，使用11种不同的LLM和三位人工评分者，利用四种现有的分类框架对学生问题进行分类。在使用LLM作为评分者的可行性方面，结果显示中等到良好的评分者间可靠性，且一致性高于人工评分者。数据表明，在这两种学习背景中，“程序性”问题占主导地位，但在学生为总结性评估做准备时更为明显。这些结果为使用LLM对学生问题进行分类提供了基础。然而，我们识别出在使用分类框架进行分类的能力和这样做的价值方面的明显局限性：分类框架有限，因此难以适应复合提示的语义丰富性，仅提供对聊天机器人整合的更广泛风险和收益的部分理解。未来，我们建议采用一种分析方法，捕捉对话的细微、多轮特性，例如，通过在话语心理学中应用对话分析的方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates the role of procedural questions in student interactions with educational chatbots powered by Large Language Models (LLMs), motivated by the need to understand how these questions influence chatbot effectiveness. The study analyzed 6,113 messages from two distinct learning contexts—formative self-study and summative assessed coursework—using 11 different LLMs and three human raters to classify the questions based on four existing schemas. The findings revealed that procedural questions were predominant in both contexts, particularly during summative assessments, and demonstrated moderate-to-good inter-rater reliability for LLMs compared to human raters, although the study also highlighted limitations in the classification schemas used and suggested future research should focus on capturing the complexity of conversational interactions.</div>
<div class="mono" style="margin-top:8px">本研究探讨了程序性问题在学生与大型语言模型（LLM）驱动的教育聊天机器人互动中的作用，旨在理解这些问题如何影响聊天机器人的有效性。研究分析了来自两种不同学习背景的6113条消息——形成性自学和总结性评估课程，使用11种不同的LLM和三位人工评审者根据四种现有框架对问题进行分类。结果显示，在这两种背景下，程序性问题占主导地位，尤其是在总结性评估期间，并且LLM与人工评审者相比表现出中等到良好的评审一致性，突显了LLM在分类学生询问中的潜力，同时也指出了现有分类框架的局限性。</div>
</details>
</div>
<div class="card">
<div class="title">Quantum Maximum Likelihood Prediction via Hilbert Space Embeddings</div>
<div class="meta-line">Authors: Sreejith Sreekumar, Nir Weinberger</div>
<div class="meta-line">First: 2026-02-20T17:16:38+00:00 · Latest: 2026-02-20T17:16:38+00:00</div>
<div class="meta-line">Comments: 32+4 pages, 1 figure</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18364v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18364v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent works have proposed various explanations for the ability of modern large language models (LLMs) to perform in-context prediction. We propose an alternative conceptual viewpoint from an information-geometric and statistical perspective. Motivated by Bach[2023], we model training as learning an embedding of probability distributions into the space of quantum density operators, and in-context learning as maximum-likelihood prediction over a specified class of quantum models. We provide an interpretation of this predictor in terms of quantum reverse information projection and quantum Pythagorean theorem when the class of quantum models is sufficiently expressive. We further derive non-asymptotic performance guarantees in terms of convergence rates and concentration inequalities, both in trace norm and quantum relative entropy. Our approach provides a unified framework to handle both classical and quantum LLMs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过希尔伯特空间嵌入的量子最大似然预测</div>
<div class="mono" style="margin-top:8px">最近的研究提出了多种解释，说明现代大型语言模型（LLMs）在上下文预测中的能力。我们从信息几何和统计的角度提出了一种替代的概念视角。受Bach[2023]的启发，我们将训练建模为将概率分布嵌入量子密度算子的空间，并将上下文学习建模为在特定量子模型类上的最大似然预测。当量子模型类足够表达时，我们提供了该预测器在量子逆信息投影和量子毕达哥拉斯定理方面的解释。我们进一步推导了关于收敛速率和集中不等式的非渐近性能保证，包括迹范数和量子相对熵。我们的方法提供了一个统一的框架来处理经典和量子LLMs。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to understand the in-context prediction capabilities of large language models (LLMs) from an information-geometric and statistical perspective. The authors propose a method that models training as embedding probability distributions into quantum density operators and frames in-context learning as maximum-likelihood prediction within a class of quantum models. Key experimental findings include the interpretation of the predictor through quantum reverse information projection and the quantum Pythagorean theorem, along with the derivation of non-asymptotic performance guarantees regarding convergence rates and concentration inequalities in both trace norm and quantum relative entropy.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于理解大型语言模型在上下文预测能力背后的机制，采用信息几何和统计学的视角。作者提出了一种方法，将训练建模为将概率分布嵌入量子密度算子的过程，并将上下文学习框定为在一类量子模型中进行最大似然预测。主要实验结果包括推导出与收敛速率和集中不等式相关的非渐近性能保证，展示了适用于经典和量子大型语言模型的统一框架。</div>
</details>
</div>
<div class="card">
<div class="title">Visual Planning: Let&#x27;s Think Only with Images</div>
<div class="meta-line">Authors: Yi Xu, Chengzu Li, Han Zhou, Xingchen Wan, Caiqi Zhang, Anna Korhonen, Ivan Vulić</div>
<div class="meta-line">Venue: ICLR 2026 Oral</div>
<div class="meta-line">First: 2025-05-16T16:17:22+00:00 · Latest: 2026-02-20T17:09:35+00:00</div>
<div class="meta-line">Comments: ICLR 2026 (Oral)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.11409v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.11409v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have substantially enhanced machine reasoning across diverse tasks. However, these models predominantly rely on pure text as the medium for both expressing and structuring reasoning, even when visual information is present. In this work, we argue that language may not always be the most natural or effective modality for reasoning, particularly in tasks involving spatial and geometrical information. Motivated by this, we propose a new paradigm, Visual Planning, which enables planning through purely visual representations for these &quot;vision-first&quot; tasks, as a supplementary channel to language-based reasoning. In this paradigm, planning is executed via sequences of images that encode step-by-step inference in the visual domain, akin to how humans sketch or visualize future actions. We introduce a novel reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), empowered by GRPO for post-training large vision models, leading to substantial improvements in planning in a selection of representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our visual planning paradigm outperforms all other planning variants that conduct reasoning in the text-only space. Our results establish Visual Planning as a viable and promising supplement to language-based reasoning, opening new avenues for tasks that benefit from intuitive, image-based inference.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>视觉规划：让我们只用图像思考</div>
<div class="mono" style="margin-top:8px">最近，大型语言模型（LLMs）及其多模态扩展（MLLMs）的进展显著增强了机器在各种任务中的推理能力。然而，这些模型主要依赖纯文本作为表达和构建推理的媒介，即使在存在视觉信息的情况下。在本研究中，我们认为语言并不总是推理的最自然或有效的方式，特别是在涉及空间和几何信息的任务中。基于此，我们提出了一种新的范式——视觉规划，允许通过纯视觉表示进行规划，作为语言推理的补充渠道。在这一范式中，规划通过编码逐步推理的图像序列执行，类似于人类草图或可视化未来行动。我们引入了一种新颖的强化学习框架，基于强化学习的视觉规划（VPRL），通过GRPO增强后训练的大型视觉模型，在一系列代表性的视觉导航任务（如FrozenLake、Maze和MiniBehavior）中显著改善了规划效果。我们的视觉规划范式优于所有在仅文本空间中进行推理的其他规划变体。我们的结果确立了视觉规划作为语言推理的可行且有前景的补充，为受益于直观图像推理的任务开辟了新的途径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitations of Large Language Models (LLMs) and their multimodal extensions (MLLMs) in reasoning tasks that involve visual information, as they primarily rely on text. To address this, the authors propose a new paradigm called Visual Planning, which utilizes purely visual representations for planning in spatial and geometrical tasks. They introduce a reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), which shows significant improvements in planning performance on visual navigation tasks such as FrozenLake, Maze, and MiniBehavior, outperforming traditional text-based reasoning methods and demonstrating the effectiveness of image-based inference.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于大型语言模型（LLMs）及其多模态扩展在有效利用视觉信息进行推理任务方面的局限性。为了解决这个问题，作者提出了一种新的范式，称为视觉规划，专注于通过视觉表示而非文本进行规划。他们引入了一种强化学习框架，视觉规划通过强化学习（VPRL），在视觉导航任务（如FrozenLake、Maze和MiniBehavior）中表现出显著的规划性能提升，超越了传统的基于文本的推理方法。这项工作突显了基于视觉的推理作为语言方法的补充方法的潜力。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260223_0335.html">20260223_0335</a>
<a href="archive/20260222_0334.html">20260222_0334</a>
<a href="archive/20260221_0345.html">20260221_0345</a>
<a href="archive/20260220_0348.html">20260220_0348</a>
<a href="archive/20260219_0357.html">20260219_0357</a>
<a href="archive/20260218_0356.html">20260218_0356</a>
<a href="archive/20260217_0341.html">20260217_0341</a>
<a href="archive/20260216_0336.html">20260216_0336</a>
<a href="archive/20260215_0334.html">20260215_0334</a>
<a href="archive/20260213_0357.html">20260213_0357</a>
<a href="archive/20260212_0403.html">20260212_0403</a>
<a href="archive/20260210_0412.html">20260210_0412</a>
<a href="archive/20260208_0334.html">20260208_0334</a>
<a href="archive/20260207_0346.html">20260207_0346</a>
<a href="archive/20260206_0346.html">20260206_0346</a>
<a href="archive/20260205_0348.html">20260205_0348</a>
<a href="archive/20260204_0354.html">20260204_0354</a>
<a href="archive/20260203_1224.html">20260203_1224</a>
<a href="archive/20260202_0334.html">20260202_0334</a>
<a href="archive/20260201_0330.html">20260201_0330</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0342.html">20260130_0342</a>
<a href="archive/20260129_0342.html">20260129_0342</a>
<a href="archive/20260128_0340.html">20260128_0340</a>
<a href="archive/20260127_0335.html">20260127_0335</a>
<a href="archive/20260126_0328.html">20260126_0328</a>
<a href="archive/20260125_0326.html">20260125_0326</a>
<a href="archive/20260124_0335.html">20260124_0335</a>
<a href="archive/20260123_0336.html">20260123_0336</a>
<a href="archive/20260122_0339.html">20260122_0339</a>
<a href="archive/20260121_0422.html">20260121_0422</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_0325.html">20260118_0325</a>
<a href="archive/20260117_0329.html">20260117_0329</a>
<a href="archive/20260116_0336.html">20260116_0336</a>
<a href="archive/20260115_0332.html">20260115_0332</a>
<a href="archive/20260114_0332.html">20260114_0332</a>
<a href="archive/20260113_0331.html">20260113_0331</a>
<a href="archive/20260112_0325.html">20260112_0325</a>
<a href="archive/20260111_0325.html">20260111_0325</a>
<a href="archive/20260110_0330.html">20260110_0330</a>
<a href="archive/20260109_0330.html">20260109_0330</a>
<a href="archive/20260108_0332.html">20260108_0332</a>
<a href="archive/20260107_0328.html">20260107_0328</a>
<a href="archive/20260106_1857.html">20260106_1857</a>
<a href="archive/20260106_1846.html">20260106_1846</a>
<a href="archive/20260106_0330.html">20260106_0330</a>
<a href="archive/20260105_0325.html">20260105_0325</a>
<a href="archive/20260104_2229.html">20260104_2229</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
