<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-30 03:42</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260130_0342</div>
    <div class="row"><div class="card">
<div class="title">Recursive Language Models</div>
<div class="meta-line">Authors: Alex L. Zhang, Tim Kraska, Omar Khattab</div>
<div class="meta-line">First: 2025-12-31T03:43:41+00:00 · Latest: 2026-01-28T18:59:39+00:00</div>
<div class="meta-line">Comments: 9 pages, 33 with Appendix</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.24601v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.24601v2">PDF</a> · <a href="https://github.com/alexzhang13/rlm">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference paradigm that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs can successfully process inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of vanilla frontier LLMs and common long-context scaffolds across four diverse long-context tasks while having comparable cost. At a small scale, we post-train the first natively recursive language model. Our model, RLM-Qwen3-8B, outperforms the underlying Qwen3-8B model by $28.3\%$ on average and even approaches the quality of vanilla GPT-5 on three long-context tasks. Code is available at https://github.com/alexzhang13/rlm.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>递归语言模型</div>
<div class="mono" style="margin-top:8px">我们研究允许大型语言模型（LLMs）通过推理时间扩展处理任意长提示。我们提出了递归语言模型（RLMs），这是一种将长提示视为外部环境一部分的通用推理范式，允许LLM以编程方式检查、分解并递归调用自身处理提示片段。我们发现RLMs能够成功处理输入，超出模型上下文窗口两个数量级，甚至对于较短的提示，在四个不同的长上下文任务中，RLMs的质量显著优于普通前沿LLMs和常见的长上下文支架，同时成本相当。在小规模下，我们后训练了第一个原生递归语言模型。我们的模型RLM-Qwen3-8B在平均上比基础的Qwen3-8B模型提高了$28.3\%$，并且在三个长上下文任务中接近普通GPT-5的质量。代码可在https://github.com/alexzhang13/rlm获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the capability of large language models (LLMs) to handle long prompts effectively. The authors introduce Recursive Language Models (RLMs), a novel inference paradigm that allows LLMs to treat long prompts as part of an external environment, enabling them to decompose and recursively process segments of the input. Experimental results demonstrate that RLMs can manage inputs significantly larger than typical model context windows, outperforming standard LLMs and existing long-context solutions across four diverse tasks, while maintaining similar computational costs. The RLM-Qwen3-8B model shows an average improvement of 28.3% over the base Qwen3-8B model and approaches the performance of GPT-5 on three long-context tasks.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于增强大型语言模型（LLMs）有效处理长提示的能力。作者提出了递归语言模型（RLMs），这是一种新颖的推理范式，允许LLMs将长提示视为外部环境的一部分，从而能够分解并递归处理输入的片段。实验结果表明，RLMs能够处理远超典型模型上下文窗口的输入，在四个不同的任务中表现优于标准LLMs和现有的长上下文解决方案，同时保持相似的计算成本。RLM-Qwen3-8B模型在基准Qwen3-8B模型上平均提高了28.3%，并在三个长上下文任务中接近GPT-5的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Evolutionary Strategies lead to Catastrophic Forgetting in LLMs</div>
<div class="meta-line">Authors: Immanuel Abdi, Akshat Gupta, Micah Mok, Alexander Lu, Nicholas Lee, Gopala Anumanchipalli</div>
<div class="meta-line">First: 2026-01-28T18:59:34+00:00 · Latest: 2026-01-28T18:59:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20861v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20861v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>进化策略导致大型语言模型中的灾难性遗忘</div>
<div class="mono" style="margin-top:8px">当前人工智能系统中最大的缺失能力之一是部署后持续学习的能力。实现这种持续学习系统面临多个挑战，其中之一是用于训练最先进大型语言模型的基于梯度的算法所需的大量内存。进化策略（ES）最近重新成为传统学习算法的无梯度替代方案，并在大型语言模型的特定任务上显示出令人鼓舞的表现。本文对进化策略进行了全面分析，并特别评估其在训练越来越多的更新步骤时的遗忘曲线。我们首先发现，进化策略能够在相似的计算预算下，达到接近GRPO在数学和推理任务上的性能。然而，最重要的是，对于持续学习而言，进化策略的性能提升伴随着对先前能力的显著遗忘，限制了其在线训练模型的适用性。我们还探讨了这种行为背后的原因，并显示出与相应的GRPO更新相比，使用进化策略进行的更新稀疏性大大降低，$\ell_2$范数大几个数量级，从而解释了两种算法之间的对比遗忘曲线。通过这项研究，我们旨在突出无梯度算法如进化策略中的遗忘问题，并希望激励未来的工作来减轻这些问题。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenge of continuous learning in AI systems, particularly the limitations of gradient-based algorithms in large language models (LLMs) due to their high memory requirements. The authors conduct a comprehensive analysis of Evolutionary Strategies (ES) as a gradient-free alternative, evaluating its forgetting curves while training with an increasing number of update steps. The findings reveal that while ES achieves performance levels comparable to gradient-based methods for math and reasoning tasks, it also leads to significant forgetting of previously acquired skills, which restricts its effectiveness for online training. The study further investigates the reasons for this behavior, noting that ES updates are less sparse and have much larger $\ell_2$ norms than those from gradient-based methods, contributing to the observed forgetting patterns.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决人工智能系统中持续学习的挑战，特别是大型语言模型（LLMs）中梯度基算法的内存需求。作者研究了进化策略（ES）作为一种无梯度替代方案的性能，分析了其在增加更新步骤时的遗忘曲线。研究结果表明，尽管ES在数学和推理任务上达到了与基于梯度的方法相当的性能水平，但它也导致了对先前学习能力的显著遗忘，这限制了其在线训练的有效性。研究进一步解释了ES的更新比基于梯度的方法更不稀疏且$\ell_2$范数大得多，从而导致了观察到的遗忘行为。</div>
</details>
</div>
<div class="card">
<div class="title">LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs</div>
<div class="meta-line">Authors: Piyush Jha, Arnav Arora, Vijay Ganesh</div>
<div class="meta-line">Venue: AAAI 2025</div>
<div class="meta-line">First: 2024-11-13T18:44:30+00:00 · Latest: 2026-01-28T18:58:57+00:00</div>
<div class="meta-line">Comments: Accepted at AAAI 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2411.08862v2">Abs</a> · <a href="https://arxiv.org/pdf/2411.08862v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce LLMStinger, a novel approach that leverages Large Language Models (LLMs) to automatically generate adversarial suffixes for jailbreak attacks. Unlike traditional methods, which require complex prompt engineering or white-box access, LLMStinger uses a reinforcement learning (RL) loop to fine-tune an attacker LLM, generating new suffixes based on existing attacks for harmful questions from the HarmBench benchmark. Our method significantly outperforms existing red-teaming approaches (we compared against 15 of the latest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on LLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for their extensive safety measures. Additionally, we achieved a 94.97% ASR on GPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability of LLMStinger across open and closed-source models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LLMStinger：使用强化学习微调的LLM进行LLM越狱</div>
<div class="mono" style="margin-top:8px">我们介绍了LLMStinger，这是一种新颖的方法，利用大型语言模型（LLM）自动生成用于越狱攻击的对抗后缀。与传统方法不同，传统方法需要复杂的提示工程或白盒访问，LLMStinger使用强化学习（RL）循环微调攻击者LLM，根据HarmBench基准中有害问题的现有攻击生成新的后缀。我们的方法显著优于现有的红队方法（我们与15种最新方法进行了比较），在LLaMA2-7B-chat上实现了+57.2%的攻击成功率（ASR）提升，在Claude 2上实现了+50.3%的ASR提升，这两种模型以其广泛的安全措施而闻名。此外，我们在GPT-3.5上达到了94.97%的ASR，在Gemma-2B-it上达到了99.4%的ASR，展示了LLMStinger在开源和闭源模型中的鲁棒性和适应性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research motivation behind LLMStinger is to enhance the effectiveness of jailbreak attacks on Large Language Models (LLMs) by automating the generation of adversarial suffixes. The main method involves a reinforcement learning (RL) loop that fine-tunes an attacker LLM to create new suffixes based on existing attacks, specifically targeting harmful questions from the HarmBench benchmark. The key experimental findings indicate that LLMStinger significantly outperforms traditional red-teaming methods, achieving a +57.2% improvement in Attack Success Rate (ASR) on LLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, with exceptional ASR rates of 94.97% on GPT-3.5 and 99.4% on Gemma-2B-it, showcasing its robustness across various models.</div>
<div class="mono" style="margin-top:8px">本研究的动机是通过自动生成对抗后缀来增强对大型语言模型（LLMs）进行越狱攻击的有效性。作者提出了LLMStinger，利用强化学习（RL）循环对攻击者LLM进行微调，使其能够基于HarmBench基准中的现有攻击生成新的后缀，而无需复杂的提示工程。实验结果表明，LLMStinger显著优于15种现有的红队方法，在LLaMA2-7B-chat上实现了57.2%的攻击成功率（ASR）提升，在Claude 2上提高了50.3%，并在GPT-3.5和Gemma-2B-it上分别达到了94.97%和99.4%的ASR，显示出其在各种模型中的鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">ArchesClimate: Probabilistic Decadal Ensemble Generation With Flow Matching</div>
<div class="meta-line">Authors: Graham Clyne, Guillaume Couairon, Guillaume Gastineau, Claire Monteleoni, Anastase Charantonis</div>
<div class="meta-line">First: 2025-09-19T12:53:24+00:00 · Latest: 2026-01-28T18:58:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.15942v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.15942v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Climate projections have uncertainties related to components of the climate system and their interactions. A typical approach to quantifying these uncertainties is to use climate models to create ensembles of repeated simulations under different initial conditions. Due to the complexity of these simulations, generating such ensembles of projections is computationally expensive. In this work, we present ArchesClimate, a deep learning-based climate model emulator that aims to reduce this cost. ArchesClimate is trained on decadal hindcasts of the IPSL-CM6A-LR climate model at a spatial resolution of approximately 2.5x1.25 degrees. We train a flow matching model following ArchesWeatherGen, which we adapt to predict near-term climate. Once trained, the model generates states at a one-month lead time and can be used to auto-regressively emulate climate model simulations of any length. We show that for up to 10 years, these generations are stable and physically consistent. We also show that for several important climate variables, ArchesClimate generates simulations that are interchangeable with the IPSL model. This work suggests that climate model emulators could significantly reduce the cost of climate model simulations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ArchesClimate：基于流匹配的概率十年集合生成</div>
<div class="mono" style="margin-top:8px">气候预测存在与气候系统组件及其相互作用相关的不确定性。量化这些不确定性的典型方法是使用气候模型在不同初始条件下创建重复模拟的集合。由于这些模拟的复杂性，生成这样的预测集合在计算上是昂贵的。在本研究中，我们提出了ArchesClimate，这是一种基于深度学习的气候模型仿真器，旨在降低这一成本。ArchesClimate在IPSL-CM6A-LR气候模型的十年回溯数据上进行训练，空间分辨率约为2.5x1.25度。我们训练了一个流匹配模型，基于ArchesWeatherGen进行调整，以预测近期气候。训练完成后，该模型在一个月的提前期生成状态，并可用于自回归地模拟任意长度的气候模型模拟。我们展示了在长达10年的时间内，这些生成结果是稳定且物理一致的。我们还展示了对于几个重要的气候变量，ArchesClimate生成的模拟与IPSL模型是可互换的。这项工作表明，气候模型仿真器可以显著降低气候模型模拟的成本。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the computational expense associated with generating ensembles of climate projections, which are essential for quantifying uncertainties in climate models. The authors developed ArchesClimate, a deep learning-based climate model emulator trained on decadal hindcasts from the IPSL-CM6A-LR climate model, utilizing a flow matching approach to predict near-term climate. The key findings indicate that ArchesClimate can generate stable and physically consistent climate states for up to 10 years, and its simulations for several critical climate variables are comparable to those produced by the IPSL model, suggesting a potential reduction in the costs of climate model simulations.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决生成气候预测集合所需的计算成本，这对于量化气候模型的不确定性至关重要。作者开发了ArchesClimate，这是一种基于深度学习的气候模型仿真器，训练于来自IPSL-CM6A-LR气候模型的十年回溯数据，采用了从ArchesWeatherGen适应而来的流匹配方法来预测近期气候。主要发现表明，ArchesClimate能够生成稳定且物理一致的气候状态，预测时间可达10年，其在多个关键气候变量上的模拟结果与IPSL模型相当，表明气候建模的仿真成本可能会显著降低。</div>
</details>
</div>
<div class="card">
<div class="title">DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems</div>
<div class="meta-line">Authors: Kostis Michailidis, Dimos Tsouros, Tias Guns</div>
<div class="meta-line">First: 2025-06-06T12:56:02+00:00 · Latest: 2026-01-28T18:58:23+00:00</div>
<div class="meta-line">Comments: This version is currently submitted and it is under review. For CP-Bench (the paper accepted at ECAI25), please refer to the previous version of this entry (v2)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.06052v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.06052v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Discrete Combinatorial Problems (DCPs) are prevalent in industrial decision-making and optimisation. However, while constraint solving technologies for DCPs have advanced significantly, the core process of formalising them, namely constraint modelling, requires significant expertise and remains a bottleneck for wider adoption. Aiming to alleviate this bottleneck, recent studies have explored using Large Language Models (LLMs) to transform combinatorial problem descriptions into executable constraint models. However, the existing evaluation datasets for discrete constraint modelling are often limited to small, homogeneous, or domain-specific problems, which do not capture the diversity of real-world scenarios. This work addresses this gap by introducing DCP-Bench-Open, a novel benchmark that includes a diverse set of well-known discrete combinatorial problems sourced from the Constraint Programming (CP) and Operations Research (OR) communities, structured explicitly for evaluating LLM-driven constraint modelling. With this dataset, and given the variety of modelling frameworks, we compare and evaluate the modelling capabilities of LLMs for three distinct constraint modelling systems, which vary in abstraction level and underlying syntax. Notably, the results show higher performance when modelling with a high-level Python-based framework. Additionally, we systematically evaluate the use of prompt-based and inference-time compute methods across different LLMs, which further increase accuracy, reaching up to 91% on this highly challenging benchmark. DCP-Bench-Open is publicly available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DCP-Bench-Open：评估大语言模型在离散组合问题约束建模中的应用</div>
<div class="mono" style="margin-top:8px">离散组合问题（DCPs）在工业决策和优化中普遍存在。然而，尽管DCP的约束求解技术已显著进步，但其核心过程——约束建模，仍需大量专业知识，成为更广泛应用的瓶颈。为缓解这一瓶颈，近期研究探索了使用大语言模型（LLMs）将组合问题描述转化为可执行的约束模型。然而，现有的离散约束建模评估数据集通常局限于小型、同质或特定领域的问题，无法捕捉现实场景的多样性。本研究通过引入DCP-Bench-Open，填补了这一空白，该基准包含了一组多样化的知名离散组合问题，来源于约束编程（CP）和运筹学（OR）社区，专门用于评估基于LLM的约束建模。利用该数据集，并考虑到多种建模框架，我们比较和评估了LLMs在三种不同约束建模系统中的建模能力，这些系统在抽象级别和底层语法上各不相同。值得注意的是，结果显示在使用基于Python的高级框架进行建模时性能更高。此外，我们系统地评估了在不同LLMs中使用基于提示和推理时计算方法的效果，进一步提高了准确性，在这一高度挑战的基准上达到了91%。DCP-Bench-Open已公开发布。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the bottleneck in constraint modelling for Discrete Combinatorial Problems (DCPs), which is crucial for industrial decision-making and optimization but requires significant expertise. The authors introduce DCP-Bench-Open, a benchmark designed to evaluate the capabilities of Large Language Models (LLMs) in transforming combinatorial problem descriptions into executable constraint models, using a diverse set of well-known DCPs from the Constraint Programming and Operations Research communities. The experimental results indicate that LLMs perform better when using a high-level Python-based modelling framework, achieving accuracy rates of up to 91% with the application of prompt-based and inference-time compute methods across different LLMs.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决离散组合问题（DCPs）中的约束建模瓶颈，该过程对于工业决策和优化至关重要，但需要显著的专业知识。作者提出了DCP-Bench-Open，这是一个旨在评估大型语言模型（LLMs）将问题描述转化为可执行约束模型能力的基准，使用来自约束编程和运筹学社区的一系列多样化的知名DCPs。主要发现表明，LLMs在使用基于高级Python的框架进行建模时表现更佳，并且对不同LLMs的提示基础和推理时间计算方法的系统评估在这一具有挑战性的基准上达到了高达91%的准确率。</div>
</details>
</div>
<div class="card">
<div class="title">SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models</div>
<div class="meta-line">Authors: Sebastiano Monti, Carlo Nicolini, Gianni Pellegrini, Jacopo Staiano, Bruno Lepri</div>
<div class="meta-line">First: 2026-01-28T18:56:00+00:00 · Latest: 2026-01-28T18:56:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20856v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20856v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SokoBench：评估大型语言模型的长远规划和推理能力</div>
<div class="mono" style="margin-top:8px">尽管大型语言模型的能力在复杂推理任务上得到了越来越多的测试，但它们的长远规划能力尚未得到广泛研究。在这项工作中，我们对最先进的大型推理模型（LRMs）的规划和长远推理能力进行了系统评估。我们提出了一种基于推箱子难题的新基准，故意简化以将长远规划与状态持久性隔离。我们的发现揭示了当解决方案需要超过25步时，规划性能的一致下降，表明前向规划能力的基本限制。我们展示了为LRMs配备规划领域定义语言（PDDL）解析、验证和求解工具可以带来适度的改进，表明固有的架构限制可能无法仅通过测试时的扩展方法克服。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to evaluate the long-horizon planning capabilities of large language models, which have not been thoroughly explored despite their performance on complex reasoning tasks. The authors developed a benchmark using simplified Sokoban puzzles to specifically assess long-horizon planning while minimizing the influence of state persistence. The key findings indicate that planning performance significantly declines when the number of required moves exceeds 25, highlighting a fundamental limitation in the models&#x27; forward planning abilities, although incorporating Planning Domain Definition Language (PDDL) tools yields some improvements.</div>
<div class="mono" style="margin-top:8px">本研究的动机是评估大型语言模型的长远规划能力，尽管它们在复杂推理任务中的表现已得到验证，但这一能力尚未得到充分探讨。作者开发了一个基于推箱子游戏的基准，系统地评估了最先进的大型推理模型（LRMs）的规划和推理能力，旨在将长远规划与状态持久性隔离开来。结果表明，当所需移动次数超过25次时，规划性能显著下降，突显了前向规划能力的基本限制，尽管集成规划领域定义语言（PDDL）工具显示出一定的改善，表明仅靠扩展测试时间可能无法克服的架构限制。</div>
</details>
</div>
<div class="card">
<div class="title">From Specialist to Generalist: Unlocking SAM&#x27;s Learning Potential on Unlabeled Medical Images</div>
<div class="meta-line">Authors: Vi Vu, Thanh-Huy Nguyen, Tien-Thinh Nguyen, Ba-Thinh Lam, Hoang-Thien Nguyen, Tianyang Wang, Xingjian Li, Min Xu</div>
<div class="meta-line">Venue: ISBI 2026</div>
<div class="meta-line">First: 2026-01-25T18:13:48+00:00 · Latest: 2026-01-28T18:55:46+00:00</div>
<div class="meta-line">Comments: Accepted to ISBI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17934v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.17934v2">PDF</a> · <a href="https://github.com/vnlvi2k3/SC-SAM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM&#x27;s adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从专家到通才：释放SAM在无标签医学图像上的学习潜力</div>
<div class="mono" style="margin-top:8px">基础模型如Segment Anything Model (SAM)展现出强大的泛化能力，但由于领域转移、标签稀缺以及参数高效微调（PEFT）无法利用无标签数据，适应医学图像仍然困难。虽然传统模型如U-Net在半监督医学学习中表现出色，但它们对PEFT SAM的辅助潜力在很大程度上被忽视。我们提出了SC-SAM，一个专家-通才框架，其中U-Net提供基于点的提示和伪标签来指导SAM的适应，而SAM则作为强大的通才监督者来规范U-Net。这种相互指导形成了一个双向共同训练循环，使两个模型能够有效利用无标签数据。在前列腺MRI和息肉分割基准测试中，我们的方法取得了最先进的结果，超越了其他现有的半监督SAM变体，甚至医学基础模型如MedSAM，突显了专家-通才合作在标签高效医学图像分割中的价值。我们的代码可在https://github.com/vnlvi2k3/SC-SAM获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of adapting foundation models like the Segment Anything Model (SAM) to medical images, which is hindered by domain shifts and a lack of labeled data. The authors propose a specialist-generalist framework called SC-SAM, where a U-Net model provides point-based prompts and pseudo-labels to assist SAM&#x27;s adaptation, while SAM acts as a generalist supervisor to regularize U-Net. Experimental results demonstrate that SC-SAM achieves state-of-the-art performance on prostate MRI and polyp segmentation tasks, surpassing existing semi-supervised SAM variants and medical foundation models, thereby emphasizing the effectiveness of specialist-generalist collaboration in medical image segmentation.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高基础模型如Segment Anything Model (SAM) 在医学图像上的适应能力，这一过程因领域转移和标注数据稀缺而面临挑战。作者提出了一种名为SC-SAM的专家-通用框架，其中U-Net模型提供基于点的提示和伪标签来辅助SAM，而SAM则作为监督者来规范U-Net，形成一个双向共训练循环，以利用未标记数据。实验结果表明，SC-SAM在前列腺MRI和息肉分割基准测试中实现了最先进的性能，超越了现有的半监督SAM变体和其他医学基础模型，从而强调了专家-通用合作在医学图像分割中的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Exploring Transformer Placement in Variational Autoencoders for Tabular Data Generation</div>
<div class="meta-line">Authors: Aníbal Silva, Moisés Santos, André Restivo, Carlos Soares</div>
<div class="meta-line">First: 2026-01-28T18:54:27+00:00 · Latest: 2026-01-28T18:54:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20854v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20854v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tabular data remains a challenging domain for generative models. In particular, the standard Variational Autoencoder (VAE) architecture, typically composed of multilayer perceptrons, struggles to model relationships between features, especially when handling mixed data types. In contrast, Transformers, through their attention mechanism, are better suited for capturing complex feature interactions. In this paper, we empirically investigate the impact of integrating Transformers into different components of a VAE. We conduct experiments on 57 datasets from the OpenML CC18 suite and draw two main conclusions. First, results indicate that positioning Transformers to leverage latent and decoder representations leads to a trade-off between fidelity and diversity. Second, we observe a high similarity between consecutive blocks of a Transformer in all components. In particular, in the decoder, the relationship between the input and output of a Transformer is approximately linear.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在变分自编码器中探索变压器的放置以生成表格数据</div>
<div class="mono" style="margin-top:8px">表格数据仍然是生成模型的一个挑战领域。特别是，标准的变分自编码器（VAE）架构通常由多层感知器组成，难以建模特征之间的关系，尤其是在处理混合数据类型时。相比之下，变压器通过其注意力机制更适合捕捉复杂的特征交互。本文通过实证研究探讨将变压器集成到VAE不同组件中的影响。我们在OpenML CC18套件的57个数据集上进行实验，并得出两个主要结论。首先，结果表明，将变压器放置在潜在和解码器表示中会导致保真度和多样性之间的权衡。其次，我们观察到在所有组件中，变压器的连续块之间具有高度相似性。特别是在解码器中，变压器的输入和输出之间的关系大致是线性的。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to improve the performance of Variational Autoencoders (VAEs) in generating tabular data, as traditional VAE architectures struggle with feature relationships, particularly with mixed data types. The authors empirically explore the integration of Transformers into various components of a VAE, conducting experiments on 57 datasets from the OpenML CC18 suite. The key findings reveal that placing Transformers to utilize latent and decoder representations results in a trade-off between fidelity and diversity, and that there is a notable linear relationship between the input and output of Transformers in the decoder, with high similarity observed between consecutive Transformer blocks across all components.</div>
<div class="mono" style="margin-top:8px">本研究解决了标准变分自编码器（VAE）在生成表格数据时的局限性，特别是在建模复杂特征交互方面的困难。作者研究了将变换器集成到VAE的不同组件中的影响，利用57个来自OpenML CC18套件的数据集进行实验。研究结果表明，将变换器放置在潜在表示和解码器表示中会导致保真度和多样性之间的权衡，并且在解码器中，变换器的输入和输出之间存在显著的线性关系，所有组件中连续变换器块之间的相似性也很高。</div>
</details>
</div>
<div class="card">
<div class="title">HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization</div>
<div class="meta-line">Authors: Hongzheng Chen, Yingheng Wang, Yaohui Cai, Hins Hu, Jiajie Li, Shirley Huang, Chenhui Deng, Rongjian Liang, Shufeng Kong, Haoxing Ren, Samitha Samaranayake, Carla P. Gomes, Zhiru Zhang</div>
<div class="meta-line">Venue: ICLR</div>
<div class="meta-line">First: 2025-06-09T17:46:47+00:00 · Latest: 2026-01-28T18:52:54+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR&#x27;26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.07972v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.07972v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HeuriGym：用于组合优化中LLM生成启发式算法的代理基准</div>
<div class="mono" style="margin-top:8px">尽管大型语言模型（LLMs）在推理和基于代理的问题解决方面取得了显著进展，但当前的评估方法未能充分评估其能力：现有基准要么依赖于容易饱和和记忆的封闭式问题，要么是缺乏一致性和严谨性的主观比较。在本研究中，我们介绍了HeuriGym，这是一个旨在评估LLM生成的组合优化问题的启发式算法的代理框架，具有明确的目标和广泛的解决方案空间。HeuriGym使LLM能够提出启发式算法，通过代码执行接收评估反馈，并迭代改进其解决方案。我们在计算机系统、物流和生物学等领域的九个问题上评估了九个最先进的模型，揭示了工具使用、规划和自适应推理方面的持续局限性。为了量化性能，我们提出了质量-产出指数（QYI），该指标同时捕捉解决方案通过率和质量。即使是像GPT-o4-mini-high和Gemini-2.5-Pro这样的顶级模型，其QYI得分也仅为0.6，远低于专家基准1。我们的开源基准旨在引导LLM的发展，以实现更有效和现实的科学和工程领域问题解决。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the inadequacies of current evaluation methodologies for Large Language Models (LLMs) in assessing their reasoning and problem-solving capabilities in combinatorial optimization. The authors introduce HeuriGym, an agentic framework that allows LLMs to generate heuristics, receive feedback through code execution, and iteratively improve their solutions across various domains. The evaluation of nine state-of-the-art models on nine different problems reveals significant limitations in their tool use, planning, and adaptive reasoning, with the proposed Quality-Yield Index (QYI) indicating that even the best models achieve scores of only 0.6, which is substantially lower than the expert baseline of 1.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决当前评估大语言模型（LLMs）在组合优化问题上解决能力的评估方法不足。作者提出了HeuriGym，这是一个代理框架，允许LLMs生成启发式算法，通过代码执行获得反馈，并迭代改进其解决方案。对九种最先进模型在多个领域的评估显示，它们在工具使用、规划和自适应推理方面存在显著限制，所提出的质量收益指数（QYI）表明，即使是最佳模型的得分也仅为0.6，远低于专家基准的1。</div>
</details>
</div>
<div class="card">
<div class="title">C3Box: A CLIP-based Class-Incremental Learning Toolbox</div>
<div class="meta-line">Authors: Hao Sun, Da-Wei Zhou</div>
<div class="meta-line">First: 2026-01-28T18:52:36+00:00 · Latest: 2026-01-28T18:52:36+00:00</div>
<div class="meta-line">Comments: The code is available at https://github.com/LAMDA-CL/C3Box</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20852v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20852v1">PDF</a> · <a href="https://github.com/LAMDA-CL/C3Box">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box a reliable benchmark platform for continual learning research. Designed to be user-friendly, C3Box relies only on widely used open-source libraries and supports major operating systems. The code is available at https://github.com/LAMDA-CL/C3Box.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>C3Box：基于CLIP的增量学习工具箱</div>
<div class="mono" style="margin-top:8px">传统机器学习系统通常设计用于静态数据分布，在从不断变化的数据流中学习时容易遭遇灾难性遗忘。增量学习（CIL）通过使学习系统能够持续学习新类别而保留先前知识来应对这一挑战。随着CLIP等预训练模型（PTMs）的兴起，利用其强大的泛化和语义对齐能力已成为CIL中的一个有前景的方向。然而，现有的基于CLIP的CIL方法往往分散在不同的代码库中，依赖于不一致的配置，阻碍了公平比较、可重复性和实际应用。因此，我们提出了C3Box（基于CLIP的增量学习工具箱），这是一个模块化和全面的Python工具箱。C3Box将代表性的传统CIL方法、基于ViT的CIL方法和最先进的基于CLIP的CIL方法整合到一个统一的基于CLIP的框架中。通过继承PyCIL的简化设计，C3Box提供了基于JSON的配置和标准化执行管道。该设计使得可重复实验的工程开销低，并使C3Box成为持续学习研究的可靠基准平台。C3Box旨在用户友好，仅依赖于广泛使用的开源库，并支持主要操作系统。代码可在https://github.com/LAMDA-CL/C3Box获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the issue of catastrophic forgetting in traditional machine learning systems when learning from evolving data streams, particularly in the context of Class-Incremental Learning (CIL). The authors developed C3Box, a modular Python toolbox that integrates various CIL methods, including traditional, ViT-based, and state-of-the-art CLIP-based approaches, into a unified framework. The key findings indicate that C3Box facilitates reproducible experimentation with minimal engineering effort, providing a reliable benchmark platform for continual learning research while ensuring user-friendliness and compatibility with widely used open-source libraries.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决传统机器学习系统在从不断变化的数据流中学习时遭遇的灾难性遗忘问题，特别是通过类增量学习（CIL）。作者开发了C3Box，一个模块化的Python工具箱，将多种CIL方法，包括传统方法、基于ViT的方法和最先进的基于CLIP的方法，整合到一个统一的框架中。主要发现表明，C3Box以最小的工程努力促进可重复实验，作为持续学习研究的可靠基准平台，提供标准化的执行流程和基于JSON的配置。</div>
</details>
</div>
<div class="card">
<div class="title">Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation</div>
<div class="meta-line">Authors: Weixin Chen, Li Chen, Yuhan Zhao</div>
<div class="meta-line">Venue: WWW 2026 Oral Presentation</div>
<div class="meta-line">First: 2026-01-28T18:48:43+00:00 · Latest: 2026-01-28T18:48:43+00:00</div>
<div class="meta-line">Comments: Accepted to WWW 2026 Workshop on HCRS (Oral Presentation)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20848v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20848v1">PDF</a> · <a href="https://github.com/weixinchen98/Cofair">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite growing efforts to mitigate unfairness in recommender systems, existing fairness-aware methods typically fix the fairness requirement at training time and provide limited post-training flexibility. However, in real-world scenarios, diverse stakeholders may demand differing fairness requirements over time, so retraining for different fairness requirements becomes prohibitive. To address this limitation, we propose Cofair, a single-train framework that enables post-training fairness control in recommendation. Specifically, Cofair introduces a shared representation layer with fairness-conditioned adapter modules to produce user embeddings specialized for varied fairness levels, along with a user-level regularization term that guarantees user-wise monotonic fairness improvements across these levels. We theoretically establish that the adversarial objective of Cofair upper bounds demographic parity and the regularization term enforces progressive fairness at user level. Comprehensive experiments on multiple datasets and backbone models demonstrate that our framework provides dynamic fairness at different levels, delivering comparable or better fairness-accuracy curves than state-of-the-art baselines, without the need to retrain for each new fairness requirement. Our code is publicly available at https://github.com/weixinchen98/Cofair.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>后训练公平性控制：动态推荐中的单次训练框架</div>
<div class="mono" style="margin-top:8px">尽管在减轻推荐系统中的不公平性方面的努力不断增加，现有的公平性感知方法通常在训练时固定公平性要求，并提供有限的后训练灵活性。然而，在现实场景中，不同的利益相关者可能会随着时间的推移要求不同的公平性标准，因此针对不同的公平性要求进行重新训练变得不可行。为了解决这一限制，我们提出了Cofair，一个单次训练框架，能够在推荐中实现后训练公平性控制。具体而言，Cofair引入了一个共享表示层和公平性条件适配模块，以生成针对不同公平性水平的用户嵌入，并结合一个用户级正则化项，确保在这些水平上用户的单调公平性改进。我们理论上证明了Cofair的对抗目标上界了人口平等，而正则化项在用户级别上强制实施渐进公平性。在多个数据集和基础模型上的全面实验表明，我们的框架在不同水平上提供动态公平性，提供与最先进基线相当或更好的公平性-准确性曲线，而无需针对每个新的公平性要求进行重新训练。我们的代码可在https://github.com/weixinchen98/Cofair公开获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the limitations of existing fairness-aware methods in recommender systems, which typically fix fairness requirements at training time and lack post-training flexibility. The authors propose a framework called Cofair, which utilizes a shared representation layer with fairness-conditioned adapter modules to create user embeddings tailored for varying fairness levels, along with a user-level regularization term to ensure monotonic fairness improvements. Experimental results on multiple datasets show that Cofair achieves dynamic fairness across different levels, providing comparable or superior fairness-accuracy trade-offs compared to state-of-the-art methods without the need for retraining for each new fairness requirement.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决现有推荐系统中公平性方法的局限性，这些方法通常在训练期间固定公平性要求，缺乏对不同利益相关者需求的灵活性。作者提出了一种名为Cofair的框架，允许在训练后进行公平性控制，通过引入共享表示层和公平性条件适配模块，以及用户级正则化项，确保用户级单调公平性改进。对多个数据集的实验结果表明，Cofair在不同水平上实现了动态公平性，提供了与最先进方法相比可比或更好的公平性-准确性权衡，而无需针对每个新公平性要求进行重新训练。</div>
</details>
</div>
<div class="card">
<div class="title">Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</div>
<div class="meta-line">Authors: Rui Pan, Zhuofu Chen, Hongyi Liu, Arvind Krishnamurthy, Ravi Netravali</div>
<div class="meta-line">First: 2025-12-23T18:16:58+00:00 · Latest: 2026-01-28T18:48:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20573v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.20573v3">PDF</a> · <a href="https://github.com/ruipeterpan/failfast">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM&#x27;s speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It &quot;fails fast&quot; by spending minimal compute in hard-to-speculate regions to shrink speculation latency and &quot;wins big&quot; by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\times$ speedup over vanilla decoding, 1.7$\times$ over the best naive dLLM drafter, and 1.7$\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>快速失败，赢得胜利：通过扩散大语言模型重新思考投标策略</div>
<div class="mono" style="margin-top:8px">扩散大语言模型（dLLMs）提供快速、并行的标记生成，但其独立使用受到固有效率与质量的权衡影响。我们展示了如果谨慎应用，dLLMs的特性实际上可以成为投标人在自回归（AR）验证中的优势。我们的核心见解是，dLLM的并行解码速度大幅降低了昂贵拒绝的风险，为有效实现导致大幅加速的（难以捉摸的）长草稿提供了实用机制。我们提出了FailFast，一个基于dLLM的投机解码框架，通过动态调整其投机长度来实现这一方法。它通过在难以投机的区域花费最小计算来缩短投机延迟，从而“快速失败”，并通过在较容易的区域积极延长草稿长度来减少验证延迟，从而“赢得胜利”（在许多情况下，一次投机并接受70个标记！）。在没有任何微调的情况下，FailFast实现了AR LLM的无损加速，并在各种模型和工作负载中实现了比普通解码快4.9$\times$，比最佳简单dLLM投标者快1.7$\times$，比EAGLE-3快1.7$\times$。我们在https://github.com/ruipeterpan/failfast上开源了FailFast。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the efficiency-quality tradeoff inherent in the standalone use of Diffusion Large Language Models (dLLMs) for token generation. The authors propose a novel framework called FailFast, which leverages the speed of dLLMs in speculative decoding with autoregressive verifiers by dynamically adapting speculation lengths. Experimental results demonstrate that FailFast achieves lossless acceleration of autoregressive LLMs, providing up to 4.9 times speedup over traditional decoding methods and 1.7 times over the best naive dLLM drafter, effectively enhancing performance across various models and workloads.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于扩散大型语言模型（dLLMs）在独立使用时存在的效率与质量之间的权衡。作者提出了一种名为FailFast的推测解码框架，利用dLLMs的速度，通过根据解码区域的难度动态调整推测长度，来最小化昂贵的拒绝。实验结果表明，FailFast实现了对自回归LLMs的无损加速，在各种模型和工作负载中，提供了比传统解码方法快4.9倍、比最佳的朴素dLLM草拟器快1.7倍的加速效果。</div>
</details>
</div>
<div class="card">
<div class="title">A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion</div>
<div class="meta-line">Authors: Willams de Lima Costa, Thifany Ketuli Silva de Souza, Jonas Ferreira Silva, Carlos Gabriel Bezerra Pereira, Bruno Reis Vila Nova, Leonardo Silvino Brito, Rafael Raider Leoni, Juliano Silva, Valter Ferreira, Sibele Miguel Soares Neto, Samantha Uehara, Daniel Giacomo, João Marcelo Teixeira, Veronica Teichrieb, Cristiano Coelho de Araújo</div>
<div class="meta-line">First: 2026-01-28T18:46:29+00:00 · Latest: 2026-01-28T18:46:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20847v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20847v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过相机-IMU融合实现稳健路面分类的新数据集和框架</div>
<div class="mono" style="margin-top:8px">路面分类（RSC）是环境感知预测维护系统的关键推动力。然而，现有的RSC技术由于感知模态和缺乏环境多样性的数据集的限制，往往无法在狭窄的操作条件之外进行推广。本研究通过引入一个多模态框架，融合图像和惯性测量，使用轻量级双向交叉注意力模块，随后是一个自适应门控层，在领域转移下调整模态贡献，从而解决这些限制。鉴于当前基准的局限性，特别是缺乏变异性，我们引入了ROAD，一个由三个互补子集组成的新数据集：（i）使用行业标准数据记录仪同步的RGB-IMU流的真实世界多模态录音，捕获于多种光照、天气和表面条件下；（ii）一个大型仅视觉子集，旨在评估在不利光照和异构捕获设置下的稳健性；（iii）一个合成子集，旨在研究在实践中难以获得的场景中的分布外泛化。实验表明，我们的方法在PVS基准上比之前的最先进技术提高了1.4个百分点，在我们的多模态ROAD子集上提高了11.6个百分点，并且在少数类上始终具有更高的F1分数。该框架在夜间、暴雨和混合表面过渡等具有挑战性的视觉条件下也表现出稳定的性能。这些发现表明，将经济实惠的相机和IMU传感器与多模态注意力机制相结合，为路面理解提供了可扩展、稳健的基础，特别适用于环境变异性和成本限制限制高端传感器套件采用的地区。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance road surface classification (RSC) for predictive maintenance systems, addressing the limitations of existing techniques that struggle with generalization due to narrow operational conditions and insufficiently diverse datasets. The authors propose a multimodal framework that integrates images and inertial measurements through a lightweight bidirectional cross-attention module and an adaptive gating layer to adjust modality contributions during domain shifts. Experimental results indicate that this method achieves a 1.4 percentage point improvement over the previous state-of-the-art on the PVS benchmark and an 11.6 percentage point improvement on the new ROAD dataset, demonstrating stable performance across various challenging conditions such as nighttime and heavy rain, thus providing a robust solution for road surface understanding.</div>
<div class="mono" style="margin-top:8px">本研究的动机是增强道路表面分类（RSC）以支持预测性维护系统，解决现有技术在环境变化下的局限性。作者提出了一种多模态框架，通过双向交叉注意模块和自适应门控层整合图像和惯性测量，以优化模态贡献。实验结果表明，该方法在PVS基准上比之前的最先进技术提高了1.4个百分点，在新的ROAD数据集上提高了11.6个百分点，并且在少数类的F1分数上有所改善，同时在夜间和大雨等挑战性条件下表现稳定。</div>
</details>
</div>
<div class="card">
<div class="title">PatchFormer: A Patch-Based Time Series Foundation Model with Hierarchical Masked Reconstruction and Cross-Domain Transfer Learning for Zero-Shot Multi-Horizon Forecasting</div>
<div class="meta-line">Authors: Olaf Yunus Laitinen Imanov, Derya Umut Kulali, Taner Yilmaz</div>
<div class="meta-line">First: 2026-01-28T18:45:45+00:00 · Latest: 2026-01-28T18:45:45+00:00</div>
<div class="meta-line">Comments: 5 pages; 2 figures; 7 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20845v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20845v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time series forecasting is a fundamental problem with applications in climate, energy, healthcare, and finance. Many existing approaches require domain-specific feature engineering and substantial labeled data for each task. We introduce PatchFormer, a patch-based time series foundation model that uses hierarchical masked reconstruction for self-supervised pretraining and lightweight adapters for efficient transfer. PatchFormer segments time series into patches and learns multiscale temporal representations with learnable aggregation across temporal scales. Pretraining uses masked patch reconstruction with dynamic masking and objectives that encourage both local accuracy and global consistency, followed by cross-domain knowledge distillation. Experiments on 24 benchmark datasets spanning weather, energy, traffic, finance, and healthcare demonstrate state-of-the-art zero-shot multi-horizon forecasting, reducing mean squared error by 27.3 percent relative to strong baselines while requiring 94 percent less task-specific training data. The model exhibits near log-linear scaling with more pretraining data up to 100 billion points and processes length-512 sequences 3.8x faster than full-sequence transformers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PatchFormer：一种基于补丁的时间序列基础模型，具有分层掩码重建和跨域迁移学习，用于零-shot多时间段预测</div>
<div class="mono" style="margin-top:8px">时间序列预测是一个基本问题，应用于气候、能源、医疗和金融等领域。许多现有方法需要特定领域的特征工程和大量标记数据。我们介绍了PatchFormer，这是一种基于补丁的时间序列基础模型，使用分层掩码重建进行自监督预训练，并通过轻量级适配器实现高效迁移。PatchFormer将时间序列分割为补丁，并通过可学习的聚合学习多尺度时间表示。预训练使用动态掩码的掩码补丁重建和鼓励局部准确性与全局一致性的目标，随后进行跨域知识蒸馏。在涵盖天气、能源、交通、金融和医疗的24个基准数据集上的实验表明，该模型在零-shot多时间段预测中达到最先进水平，相较于强基线减少了27.3%的均方误差，同时需要94%的任务特定训练数据更少。该模型在预训练数据达到1000亿点时表现出接近对数线性扩展，并且处理长度为512的序列速度比全序列变换器快3.8倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges of time series forecasting, which often requires extensive domain-specific feature engineering and labeled data. The authors propose PatchFormer, a patch-based foundation model that employs hierarchical masked reconstruction for self-supervised pretraining and utilizes lightweight adapters for efficient transfer learning. Experimental results on 24 benchmark datasets indicate that PatchFormer achieves state-of-the-art performance in zero-shot multi-horizon forecasting, reducing mean squared error by 27.3% compared to strong baselines while requiring 94% less task-specific training data, and demonstrates significant efficiency improvements in processing time and scalability with increased pretraining data.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决时间序列预测中的挑战，这通常需要大量特定领域的特征工程和标记数据。作者提出了PatchFormer，这是一种基于补丁的基础模型，采用分层掩蔽重建进行自监督预训练，并使用轻量级适配器实现高效的迁移学习。在24个基准数据集上的实验结果表明，PatchFormer在零-shot多时间段预测中实现了最先进的性能，相较于强基线减少了27.3%的均方误差，同时使用了94%更少的任务特定训练数据，并且处理长度为512的序列速度比传统的全序列变换器快3.8倍。</div>
</details>
</div>
<div class="card">
<div class="title">$\mathbb{R}^{2k}$ is Theoretically Large Enough for Embedding-based Top-$k$ Retrieval</div>
<div class="meta-line">Authors: Zihao Wang, Hang Yin, Lihui Liu, Hanghang Tong, Yangqiu Song, Ginny Wong, Simon See</div>
<div class="meta-line">First: 2026-01-28T18:45:43+00:00 · Latest: 2026-01-28T18:45:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20844v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20844v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper studies the minimal dimension required to embed subset memberships ($m$ elements and ${m\choose k}$ subsets of at most $k$ elements) into vector spaces, denoted as Minimal Embeddable Dimension (MED). The tight bounds of MED are derived theoretically and supported empirically for various notions of &quot;distances&quot; or &quot;similarities,&quot; including the $\ell_2$ metric, inner product, and cosine similarity. In addition, we conduct numerical simulation in a more achievable setting, where the ${m\choose k}$ subset embeddings are chosen as the centroid of the embeddings of the contained elements. Our simulation easily realizes a logarithmic dependency between the MED and the number of elements to embed. These findings imply that embedding-based retrieval limitations stem primarily from learnability challenges, not geometric constraints, guiding future algorithm design.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>$\mathbb{R}^{2k}$ 理论上足够大以支持基于嵌入的 Top-$k$ 检索</div>
<div class="mono" style="margin-top:8px">本文研究了将子集成员关系（$m$ 个元素和至多 $k$ 个元素的 ${m\choose k}$ 子集）嵌入向量空间所需的最小维度，称为最小可嵌入维度（MED）。理论上推导出 MED 的紧界限，并通过各种“距离”或“相似性”的概念进行实证支持，包括 $\ell_2$ 度量、内积和余弦相似性。此外，我们在一个更可实现的环境中进行数值模拟，其中 ${m\choose k}$ 子集嵌入被选为包含元素的嵌入的质心。我们的模拟轻松实现了 MED 与要嵌入的元素数量之间的对数依赖关系。这些发现表明，基于嵌入的检索限制主要源于可学习性挑战，而非几何约束，从而指导未来的算法设计。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)</div>
<div class="meta-line">Authors: Saurav Prateek</div>
<div class="meta-line">First: 2026-01-28T18:45:39+00:00 · Latest: 2026-01-28T18:45:39+00:00</div>
<div class="meta-line">Comments: 11 pages, 6 figures, 2 tables, source code: https://github.com/SauravP97/deep-researcher-reflect-evolve/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20843v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20843v1">PDF</a> · <a href="https://github.com/SauravP97/deep-researcher-reflect-evolve/">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>具有顺序计划反思和候选人交叉的深度研究者（深度研究者反思进化）</div>
<div class="mono" style="margin-top:8px">本文介绍了一种新颖的深度研究者架构，旨在通过解决并行扩展范式的固有局限性，生成关于复杂博士级主题的详细研究报告。我们的系统利用了两个关键创新：通过反思进行的顺序研究计划优化和候选人交叉算法。顺序优化过程被证明是一种有效的方法，使代理能够维持集中式的全球研究上下文，从而回顾当前进展，推理研究计划，并在运行时智能地进行更改。这种动态适应与并行方法形成对比，后者往往面临知识孤岛问题。候选人交叉算法通过部署多个具有不同参数的LLM候选人来进一步提高搜索效率，以探索更大的搜索空间，并将其发现综合以策划全面的最终研究响应。该过程以一次性报告生成结束，确保最终文档由统一叙述和高事实密度所支持。我们的深度研究者由Gemini 2.5 Pro模型驱动，在全球公认的100个博士级研究任务基准DeepResearch Bench上进行了评估。我们的架构获得了46.21的总体得分，表现优于领先的深度研究代理，如Claude Researcher、Nvidia AIQ Research Assistant、Perplexity Research、Kimi Researcher和Grok Deeper Search，这些代理在DeepResearch Bench的活跃排行榜上运行。该表现略微超过了我们之前的工作Static DRA，并强化了顺序扩展始终优于并行自一致性范式的发现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the limitations of the Parallel Scaling paradigm in generating detailed research reports on complex PhD topics by introducing a novel Deep Researcher architecture. The method employs Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm, allowing the system to maintain a centralized Global Research Context and adapt its research plan dynamically. Experimental results on the DeepResearch Bench, which includes 100 doctoral level research tasks, show that the architecture achieved a score of 46.21, outperforming leading deep research agents and confirming that sequential scaling is more effective than parallel approaches.</div>
<div class="mono" style="margin-top:8px">本文通过引入一种新颖的深度研究者架构，解决了并行扩展范式在生成复杂博士主题详细研究报告方面的局限性。该方法采用了通过反思的顺序研究计划优化和候选人交叉算法，允许动态适应和高效探索更大的搜索空间。在DeepResearch Bench上的实验结果显示，该架构的总体得分为46.21，超越了领先的深度研究代理，证实了顺序扩展比并行方法更有效。</div>
</details>
</div>
<div class="card">
<div class="title">BlindSight: Harnessing Sparsity for Efficient Vision-Language Models</div>
<div class="meta-line">Authors: Tharun Adithya Srikrishnan, Deval Shah, Timothy Hein, Ahmed Hasssan, Stephen Youn, Steven K. Reinhardt</div>
<div class="meta-line">First: 2025-07-11T23:15:30+00:00 · Latest: 2026-01-28T18:45:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.09071v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.09071v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large vision-language models (VLMs) enable joint processing of text and images. However, incorporating vision data significantly increases the prompt length, resulting in a longer time to first token (TTFT). This bottleneck can be alleviated by leveraging the inherent sparsity in the attention computation. Analyzing these attention patterns in VLMs when processing a series of images, we observe the absence of inter-image attention in a substantial portion of layers. Based on this, we propose BlindSight: an approach to optimize multi-image VLM inference using an input-template-aware attention sparsity mask with no runtime overhead. We utilize a dataset to derive a prompt-agnostic categorization for attention heads: Dense, Sink, Intra-Image, and Intra-Image+Sink. We develop a Triton-based GPU kernel to leverage this sparsity. BlindSight achieves a 1.8-3.2x speedup in the attention computation (prompt length 36K-300K). BlindSight generalizes across VLMs (Qwen2-VL, Qwen2.5-VL, Gemma 3), with only a 0.78% absolute accuracy degradation on average on multi-image comprehension benchmarks. Finally, we advocate for the design of efficient VLMs that combine BlindSight-inspired sparse and dense layers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BlindSight：利用稀疏性提高视觉-语言模型的效率</div>
<div class="mono" style="margin-top:8px">大型视觉-语言模型（VLMs）能够实现文本和图像的联合处理。然而，纳入视觉数据显著增加了提示长度，导致首次令牌时间（TTFT）延长。通过利用注意力计算中的固有稀疏性，可以缓解这一瓶颈。在处理一系列图像时，我们分析了VLM中的注意力模式，观察到在相当一部分层中缺乏图像间的注意力。基于此，我们提出了BlindSight：一种优化多图像VLM推理的方法，使用输入模板感知的注意力稀疏掩码且没有运行时开销。我们利用一个数据集推导出对注意力头的提示无关分类：稠密、汇聚、图像内和图像内+汇聚。我们开发了一个基于Triton的GPU内核来利用这种稀疏性。BlindSight在注意力计算中实现了1.8-3.2倍的加速（提示长度36K-300K）。BlindSight在VLMs（Qwen2-VL、Qwen2.5-VL、Gemma 3）中具有广泛的适用性，在多图像理解基准上平均仅有0.78%的绝对准确度下降。最后，我们倡导设计结合BlindSight启发的稀疏和稠密层的高效VLMs。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to improve the efficiency of large vision-language models (VLMs), which face increased prompt lengths due to the incorporation of vision data, leading to longer time to first token (TTFT). The authors propose a method called BlindSight, which optimizes multi-image VLM inference by utilizing an input-template-aware attention sparsity mask without adding runtime overhead. Experimental results demonstrate that BlindSight achieves a speedup of 1.8-3.2 times in attention computation across various VLMs, with only a minimal average accuracy degradation of 0.78% on multi-image comprehension benchmarks, suggesting its effectiveness in enhancing VLM performance while maintaining accuracy.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决大型视觉语言模型（VLMs）在结合视觉数据时，由于提示长度增加而导致的效率低下问题，这会导致首次令牌的时间延长（TTFT）。作者提出了BlindSight，一种通过利用输入模板感知的注意稀疏掩码来优化多图像VLM推理的方法，且不增加运行时开销。实验结果表明，BlindSight在各种VLM中实现了1.8-3.2倍的注意计算加速，同时在多图像理解基准测试中平均仅有0.78%的准确率下降。</div>
</details>
</div>
<div class="card">
<div class="title">Reward Models Inherit Value Biases from Pretraining</div>
<div class="meta-line">Authors: Brian Christian, Jessica A. F. Thompson, Elle Michelle Yang, Vincent Adam, Hannah Rose Kirk, Christopher Summerfield, Tsvetomira Dumbalska</div>
<div class="meta-line">First: 2026-01-28T18:40:29+00:00 · Latest: 2026-01-28T18:40:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20838v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20838v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reward models (RMs) are central to aligning large language models (LLMs) with human values but have received less attention than pre-trained and post-trained LLMs themselves. Because RMs are initialized from LLMs, they inherit representations that shape their behavior, but the nature and extent of this influence remain understudied. In a comprehensive study of 10 leading open-weight RMs using validated psycholinguistic corpora, we show that RMs exhibit significant differences along multiple dimensions of human value as a function of their base model. Using the &quot;Big Two&quot; psychological axes, we show a robust preference of Llama RMs for &quot;agency&quot; and a corresponding robust preference of Gemma RMs for &quot;communion.&quot; This phenomenon holds even when the preference data and finetuning process are identical, and we trace it back to the logits of the respective instruction-tuned and pre-trained models. These log-probability differences themselves can be formulated as an implicit RM; we derive usable implicit reward scores and show that they exhibit the very same agency/communion difference. We run experiments training RMs with ablations for preference data source and quantity, which demonstrate that this effect is not only repeatable but surprisingly durable. Despite RMs being designed to represent human preferences, our evidence shows that their outputs are influenced by the pretrained LLMs on which they are based. This work underscores the importance of safety and alignment efforts at the pretraining stage, and makes clear that open-source developers&#x27; choice of base model is as much a consideration of values as of performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>奖励模型继承预训练的价值偏见</div>
<div class="mono" style="margin-top:8px">奖励模型（RMs）在将大型语言模型（LLMs）与人类价值观对齐中至关重要，但相比于预训练和后训练的LLMs，它们受到的关注较少。由于RMs是从LLMs初始化的，它们继承了塑造其行为的表征，但这种影响的性质和程度仍然未被充分研究。在对10个领先的开放权重RMs进行的全面研究中，我们使用经过验证的心理语言学语料库，显示RMs在多个维度的人类价值观上表现出显著差异，这取决于其基础模型。使用“二大心理轴”，我们展示了Llama RMs对“能动性”的强烈偏好，以及Gemma RMs对“交往”的相应强烈偏好。即使在偏好数据和微调过程相同的情况下，这一现象依然存在，我们追溯到各自的指令调优和预训练模型的logits。这些log-概率差异本身可以被表述为一个隐式RM；我们推导出可用的隐式奖励分数，并显示它们表现出相同的能动性/交往差异。我们进行了实验，训练RMs并对偏好数据源和数量进行消融，结果表明这一效应不仅可重复，而且出乎意料地持久。尽管RMs旨在代表人类偏好，但我们的证据表明，它们的输出受到所基于的预训练LLMs的影响。这项工作强调了在预训练阶段进行安全和对齐工作的必要性，并明确指出开源开发者对基础模型的选择既是价值观的考虑，也是性能的考量。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study investigates how reward models (RMs), which are crucial for aligning large language models (LLMs) with human values, inherit biases from their pre-trained counterparts. By analyzing 10 leading open-weight RMs using validated psycholinguistic corpora, the researchers found significant differences in human value representation based on the base model, specifically noting that Llama RMs favored &#x27;agency&#x27; while Gemma RMs preferred &#x27;communion.&#x27; This preference persisted even with identical preference data and finetuning processes, indicating that the logits from the instruction-tuned and pre-trained models influence RM behavior. The experiments also demonstrated that the observed agency/communion differences are durable and repeatable, highlighting the need for careful consideration of values during the pretraining of RMs.</div>
<div class="mono" style="margin-top:8px">本研究探讨了奖励模型（RMs）如何从其预训练的同类中继承偏见，这些模型对将大型语言模型（LLMs）与人类价值观对齐至关重要。研究采用对10个领先的开放权重RMs进行全面分析，使用经过验证的心理语言学语料库评估它们在各种人类价值维度上的行为。研究结果显示，价值偏好存在显著差异，Llama RMs偏向于“能动性”，而Gemma RMs偏向于“交往”，这一模式即使在相同的偏好数据和微调过程中也依然存在，表明预训练模型的底层logits影响了这些结果。此外，实验表明这一效应是可重复且持久的，强调了在预训练阶段进行安全性和对齐工作时对基础模型的仔细考虑的必要性。</div>
</details>
</div>
<div class="card">
<div class="title">Discrete Variational Autoencoding via Policy Search</div>
<div class="meta-line">Authors: Michael Drolet, Firas Al-Hafez, Aditya Bhatt, Jan Peters, Oleg Arenz</div>
<div class="meta-line">First: 2025-09-29T12:44:05+00:00 · Latest: 2026-01-28T18:33:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.24716v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.24716v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit efficiency and can be modeled with autoregressive discrete distributions, enabling parameter-efficient multimodal search with transformers. However, discrete random variables do not allow for exact differentiable parameterization; therefore, discrete VAEs typically rely on approximations, such as Gumbel-Softmax reparameterization or straight-through gradient estimates, or employ high-variance gradient-free methods such as REINFORCE that have had limited success on high-dimensional tasks such as image reconstruction. Inspired by popular techniques in policy search, we propose a training framework for discrete VAEs that leverages the natural gradient of a non-parametric encoder to update the parametric encoder without requiring reparameterization. Our method, combined with automatic step size adaptation and a transformer-based encoder, scales to challenging datasets such as ImageNet and outperforms both approximate reparameterization methods and quantization-based discrete autoencoders in reconstructing high-dimensional data from compact latent spaces.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过策略搜索的离散变分自编码</div>
<div class="mono" style="margin-top:8px">变分自编码器（VAE）中的离散潜在瓶颈提供了高比特效率，可以用自回归离散分布建模，从而实现基于变换器的参数高效多模态搜索。然而，离散随机变量不允许精确的可微参数化；因此，离散VAE通常依赖于近似方法，如Gumbel-Softmax重参数化或直通梯度估计，或采用高方差的无梯度方法，如REINFORCE，这在图像重建等高维任务中成功有限。受策略搜索中流行技术的启发，我们提出了一种离散VAE的训练框架，利用非参数编码器的自然梯度来更新参数编码器，而无需重参数化。我们的方法结合自动步长调整和基于变换器的编码器，能够扩展到挑战性数据集，如ImageNet，并在从紧凑潜在空间重建高维数据方面超越了近似重参数化方法和基于量化的离散自编码器。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of discrete variational autoencoders (VAEs) in high-dimensional tasks, particularly their reliance on approximations for parameterization. The authors propose a novel training framework that utilizes the natural gradient of a non-parametric encoder to update a parametric encoder, avoiding the need for reparameterization. Experimental results demonstrate that this method, when combined with automatic step size adaptation and a transformer-based encoder, successfully scales to complex datasets like ImageNet and surpasses existing methods in reconstructing high-dimensional data from compact latent spaces.</div>
<div class="mono" style="margin-top:8px">该研究解决了离散变分自编码器（VAE）在高维任务中由于不可微分参数化而面临的局限性。作者提出了一种新的训练框架，灵感来自策略搜索技术，利用非参数编码器的自然梯度来更新参数编码器，而无需重参数化。实验结果表明，该方法结合自动步长适应和基于变压器的编码器，在从紧凑的潜在空间重建高维数据方面，显著优于传统的近似方法和基于量化的离散自编码器，尤其是在像ImageNet这样的挑战性数据集上。</div>
</details>
</div>
<div class="card">
<div class="title">Linear representations in language models can change dramatically over a conversation</div>
<div class="meta-line">Authors: Andrew Kyle Lampinen, Yuxuan Li, Eghbal Hosseini, Sangnie Bhardwaj, Murray Shanahan</div>
<div class="meta-line">First: 2026-01-28T18:33:17+00:00 · Latest: 2026-01-28T18:33:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20834v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20834v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Language model representations often contain linear directions that correspond to high-level concepts. Here, we study the dynamics of these representations: how representations evolve along these dimensions within the context of (simulated) conversations. We find that linear representations can change dramatically over a conversation; for example, information that is represented as factual at the beginning of a conversation can be represented as non-factual at the end and vice versa. These changes are content-dependent; while representations of conversation-relevant information may change, generic information is generally preserved. These changes are robust even for dimensions that disentangle factuality from more superficial response patterns, and occur across different model families and layers of the model. These representation changes do not require on-policy conversations; even replaying a conversation script written by an entirely different model can produce similar changes. However, adaptation is much weaker from simply having a sci-fi story in context that is framed more explicitly as such. We also show that steering along a representational direction can have dramatically different effects at different points in a conversation. These results are consistent with the idea that representations may evolve in response to the model playing a particular role that is cued by a conversation. Our findings may pose challenges for interpretability and steering -- in particular, they imply that it may be misleading to use static interpretations of features or directions, or probes that assume a particular range of features consistently corresponds to a particular ground-truth value. However, these types of representational dynamics also point to exciting new research directions for understanding how models adapt to context.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语言模型中的线性表示在对话中可能发生剧烈变化</div>
<div class="mono" style="margin-top:8px">语言模型的表示通常包含与高级概念对应的线性方向。本文研究了这些表示的动态：在（模拟）对话的背景下，这些表示如何沿着这些维度演变。我们发现，线性表示在对话中可能发生剧烈变化；例如，在对话开始时被表示为事实的信息，在对话结束时可能被表示为非事实，反之亦然。这些变化依赖于内容；虽然与对话相关的信息的表示可能会变化，但一般信息通常会被保留。这些变化在将事实性与更表面的响应模式区分开的维度上也很稳健，并且发生在不同的模型家族和模型层中。这些表示变化不需要在政策对话中进行；即使重播由完全不同模型编写的对话脚本，也能产生类似的变化。然而，仅仅在上下文中有一个更明确框定的科幻故事，适应性要弱得多。我们还表明，在对话的不同点沿着表示方向引导可能会产生截然不同的效果。这些结果与表示可能会响应模型在对话中扮演特定角色的想法一致。我们的发现可能对可解释性和引导性提出挑战——特别是，它们暗示使用静态特征或方向的解释，或假设特定特征范围始终对应于特定真实值的探针，可能会产生误导。然而，这些类型的表示动态也指向了理解模型如何适应上下文的新研究方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation of this research is to understand how linear representations in language models evolve during conversations, particularly in relation to high-level concepts. The authors employed a method of simulating conversations to observe changes in these representations, finding that the representation of information can shift dramatically from factual to non-factual and vice versa throughout a conversation. Key experimental results indicate that while conversation-relevant information is subject to change, generic information remains stable, and these dynamics occur across various model families and layers, suggesting that representations adapt to the conversational context, which raises challenges for interpretability and the use of static feature interpretations in language models.</div>
<div class="mono" style="margin-top:8px">本研究的动机是理解语言模型中的线性表示在对话过程中如何演变，特别是这些表示如何与高级概念相关。作者采用模拟对话的方法分析不同模型家族和层次中的这些表示的动态特征。主要发现表明，线性表示在对话过程中可能发生显著变化，信息可以在对话中从事实转变为非事实，反之亦然，这取决于讨论的内容，而通用信息则保持稳定。这些变化即使在重播来自不同模型的对话脚本时也会发生，表明模型在对话中的角色影响表示动态，这对可解释性和静态特征解释的使用提出了挑战。</div>
</details>
</div>
<div class="card">
<div class="title">FLOL: Fast Baselines for Real-World Low-Light Enhancement</div>
<div class="meta-line">Authors: Juan C. Benito, Daniel Feijoo, Alvaro Garcia, Marcos V. Conde</div>
<div class="meta-line">First: 2025-01-16T18:06:09+00:00 · Latest: 2026-01-28T18:31:35+00:00</div>
<div class="meta-line">Comments: Journal Preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.09718v2">Abs</a> · <a href="https://arxiv.org/pdf/2501.09718v2">PDF</a> · <a href="https://github.com/cidautai/FLOL">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Low-Light Image Enhancement (LLIE) is a key task in computational photography and imaging. The problem of enhancing images captured during night or in dark environments has been well-studied in the computer vision literature. However, current deep learning-based solutions struggle with efficiency and robustness for real-world scenarios (e.g., scenes with noise, saturated pixels). We propose a lightweight neural network that combines image processing in the frequency and spatial domains. Our baseline method, FLOL, is one of the fastest models for this task, achieving results comparable to the state-of-the-art on popular real-world benchmarks such as LOLv2, LSRW, MIT-5K and UHD-LL. Moreover, we are able to process 1080p images in real-time under 12ms. Code and models at https://github.com/cidautai/FLOL</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FLOL：真实世界低光增强的快速基线</div>
<div class="mono" style="margin-top:8px">低光图像增强（LLIE）是计算摄影和成像中的关键任务。夜间或黑暗环境中捕获的图像增强问题在计算机视觉文献中得到了充分研究。然而，当前基于深度学习的解决方案在真实场景（例如，噪声、饱和像素的场景）中效率和鲁棒性方面存在困难。我们提出了一种轻量级神经网络，结合了频域和空间域的图像处理。我们的基线方法FLOL是该任务中最快的模型之一，在流行的真实世界基准（如LOLv2、LSRW、MIT-5K和UHD-LL）上取得了与最先进技术相当的结果。此外，我们能够在12毫秒内实时处理1080p图像。代码和模型可在https://github.com/cidautai/FLOL获取。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges of low-light image enhancement (LLIE) in real-world scenarios, where existing deep learning methods often lack efficiency and robustness. The authors propose a lightweight neural network called FLOL, which integrates image processing techniques in both frequency and spatial domains. Experimental results demonstrate that FLOL is one of the fastest models for LLIE, achieving performance comparable to state-of-the-art methods on various benchmarks while processing 1080p images in real-time under 12 milliseconds.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决在现实场景中低光图像增强（LLIE）面临的挑战，现有的深度学习方法往往缺乏效率和鲁棒性。作者提出了一种名为FLOL的轻量级神经网络，结合了频域和空间域的图像处理技术。实验结果表明，FLOL是LLIE任务中最快的模型之一，在多个基准测试中表现与最先进的方法相当，同时能够在12毫秒内实时处理1080p图像。</div>
</details>
</div>
<div class="card">
<div class="title">MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents</div>
<div class="meta-line">Authors: Vishnu Sashank Dorbala, Dinesh Manocha</div>
<div class="meta-line">First: 2026-01-28T18:31:17+00:00 · Latest: 2026-01-28T18:31:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20831v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20831v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MemCtrl：将多模态大语言模型作为具身智能体的主动记忆控制器</div>
<div class="mono" style="margin-top:8px">基础模型依赖上下文学习进行个性化决策。上下文窗口的有限大小需要像RAG这样的记忆压缩和检索系统。然而，这些系统通常将记忆视为大型离线存储空间，这对期望在严格的记忆和计算约束下在线操作的具身智能体不利。在本研究中，我们提出了MemCtrl，一个新颖的框架，利用多模态大语言模型（MLLMs）在线修剪记忆。MemCtrl通过一个可训练的记忆头μ增强MLLMs，该记忆头作为门控，决定在探索过程中保留、更新或丢弃哪些观察或反思。我们通过训练两种类型的μ进行评估，1）通过离线专家，2）通过在线强化学习，观察到μ增强的MLLMs在整体具身任务完成能力上有显著提升。特别是在对多个EmbodiedBench基准子集的两个表现较差的MLLMs进行MemCtrl增强时，我们观察到μ增强的MLLMs平均提高约16%，在特定指令子集上超过20%。最后，我们对μ收集的记忆片段进行了定性分析，指出μ增强的MLLMs在长且复杂的指令类型上的优越表现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for personalized decision-making in embodied agents, which face constraints in memory and computation. The authors propose MemCtrl, a framework that utilizes Multimodal Large Language Models (MLLMs) to manage memory online by incorporating a trainable memory head that selectively retains, updates, or discards observations during exploration. Experimental results demonstrate that MLLM models augmented with MemCtrl significantly improve task completion ability, achieving an average enhancement of approximately 16% on the EmbodiedBench benchmark, with specific instruction subsets showing improvements exceeding 20%.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于现有记忆系统在具身智能体中的局限性，这些系统在在线操作时面临记忆和计算约束。作者提出了MemCtrl，一个利用多模态大语言模型（MLLMs）动态修剪记忆的框架，通过引入一个可训练的记忆头来选择性地保留、更新或丢弃观察。实验结果表明，增强了MemCtrl的MLLM模型显著提高了任务完成能力，在EmbodiedBench基准测试中平均提升约16%，特定指令子集的提升超过20%，同时提供了关于记忆管理方法有效性的定性见解。</div>
</details>
</div>
<div class="card">
<div class="title">VSCOUT: A Hybrid Variational Autoencoder Approach to Outlier Detection in High-Dimensional Retrospective Monitoring</div>
<div class="meta-line">Authors: Waldyn G. Martinez</div>
<div class="meta-line">First: 2026-01-28T18:30:48+00:00 · Latest: 2026-01-28T18:30:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20830v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20830v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern industrial and service processes generate high-dimensional, non-Gaussian, and contamination-prone data that challenge the foundational assumptions of classical Statistical Process Control (SPC). Heavy tails, multimodality, nonlinear dependencies, and sparse special-cause observations can distort baseline estimation, mask true anomalies, and prevent reliable identification of an in-control (IC) reference set. To address these challenges, we introduce VSCOUT, a distribution-free framework designed specifically for retrospective (Phase I) monitoring in high-dimensional settings. VSCOUT combines an Automatic Relevance Determination Variational Autoencoder (ARD-VAE) architecture with ensemble-based latent outlier filtering and changepoint detection. The ARD prior isolates the most informative latent dimensions, while the ensemble and changepoint filters identify pointwise and structural contamination within the determined latent space. A second-stage retraining step removes flagged observations and re-estimates the latent structure using only the retained inliers, mitigating masking and stabilizing the IC latent manifold. This two-stage refinement produces a clean and reliable IC baseline suitable for subsequent Phase II deployment. Extensive experiments across benchmark datasets demonstrate that VSCOUT achieves superior sensitivity to special-cause structure while maintaining controlled false alarms, outperforming classical SPC procedures, robust estimators, and modern machine-learning baselines. Its scalability, distributional flexibility, and resilience to complex contamination patterns position VSCOUT as a practical and effective method for retrospective modeling and anomaly detection in AI-enabled environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>VSCOUT：一种混合变分自编码器方法用于高维回顾监测中的异常检测</div>
<div class="mono" style="margin-top:8px">现代工业和服务过程生成高维、非高斯且易受污染的数据，这挑战了经典统计过程控制（SPC）的基础假设。重尾、多模态、非线性依赖和稀疏特殊原因观察可能扭曲基线估计，掩盖真实异常，并阻碍可靠识别控制状态（IC）参考集。为应对这些挑战，我们引入了VSCOUT，这是一种专为高维环境中的回顾（第一阶段）监测设计的无分布框架。VSCOUT结合了自动相关性确定变分自编码器（ARD-VAE）架构与基于集成的潜在异常过滤和变点检测。ARD先验隔离出最具信息量的潜在维度，而集成和变点过滤器则识别确定的潜在空间中的逐点和结构性污染。第二阶段的再训练步骤移除标记的观察，并仅使用保留的内点重新估计潜在结构，从而减轻掩蔽并稳定IC潜在流形。这一两阶段的精炼产生了一个干净且可靠的IC基线，适合后续的第二阶段部署。在基准数据集上的广泛实验表明，VSCOUT在保持控制的虚假警报的同时，对特殊原因结构具有更高的敏感性，优于经典SPC程序、稳健估计器和现代机器学习基线。其可扩展性、分布灵活性和对复杂污染模式的韧性使VSCOUT成为在AI驱动环境中进行回顾建模和异常检测的实用有效方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges posed by high-dimensional, non-Gaussian data in industrial processes that complicate traditional Statistical Process Control (SPC) methods. The authors propose VSCOUT, a hybrid framework that integrates an Automatic Relevance Determination Variational Autoencoder (ARD-VAE) with ensemble-based outlier filtering and changepoint detection for effective retrospective monitoring. Experimental results indicate that VSCOUT significantly enhances sensitivity to special-cause anomalies while controlling false alarms, outperforming classical SPC methods and modern machine-learning approaches across various benchmark datasets.</div>
<div class="mono" style="margin-top:8px">本研究解决了工业过程中高维非高斯数据带来的挑战，这使得传统统计过程控制方法变得复杂。作者提出了VSCOUT，这是一种混合框架，结合了自动相关性确定变分自编码器与基于集成的异常值过滤和变更点检测，以有效进行回顾性监控。实验结果表明，VSCOUT显著提高了对异常的敏感性，同时控制了假警报，在多个基准数据集上优于传统的统计过程控制方法和现代机器学习方法。</div>
</details>
</div>
<div class="card">
<div class="title">Online Conformal Model Selection for Nonstationary Time Series</div>
<div class="meta-line">Authors: Shibo Li, Yao Zheng</div>
<div class="meta-line">First: 2025-06-05T19:45:52+00:00 · Latest: 2026-01-28T18:29:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.05544v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.05544v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces the MPS (Model Prediction Set), a novel framework for online model selection for nonstationary time series. Classical model selection methods, such as information criteria and cross-validation, rely heavily on the stationarity assumption and often fail in dynamic environments which undergo gradual or abrupt changes over time. Yet real-world data are rarely stationary, and model selection under nonstationarity remains a largely open problem. To tackle this challenge, we combine conformal inference with model confidence sets to develop a procedure that adaptively selects models best suited to the evolving dynamics at any given time. Concretely, the MPS updates in real time a confidence set of candidate models that covers the best model for the next time period with a specified long-run probability, while adapting to nonstationarity of unknown forms. Through simulations and real-world data analysis, we demonstrate that MPS reliably and efficiently identifies optimal models under nonstationarity, an essential capability lacking in offline methods. Moreover, MPS frequently produces high-quality sets with small cardinality, whose evolution offers deeper insights into changing dynamics. As a generic framework, MPS accommodates any data-generating process, data structure, model class, training method, and evaluation metric, making it broadly applicable across diverse problem settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>非平稳时间序列的在线保形模型选择</div>
<div class="mono" style="margin-top:8px">本文介绍了MPS（模型预测集），这是一个用于非平稳时间序列的在线模型选择的新框架。经典的模型选择方法，如信息准则和交叉验证，严重依赖于平稳性假设，并且在经历逐渐或突然变化的动态环境中往往失败。然而，现实世界的数据很少是平稳的，非平稳下的模型选择仍然是一个基本未解的问题。为了解决这一挑战，我们将保形推断与模型置信集结合，开发了一种程序，能够自适应地选择最适合于任何给定时刻演变动态的模型。具体而言，MPS实时更新候选模型的置信集，以指定的长期概率覆盖下一个时间段的最佳模型，同时适应未知形式的非平稳性。通过模拟和真实数据分析，我们证明MPS能够可靠且高效地识别非平稳下的最佳模型，这是离线方法所缺乏的基本能力。此外，MPS经常生成小基数的高质量集合，其演变提供了对变化动态的更深入见解。作为一个通用框架，MPS适用于任何数据生成过程、数据结构、模型类别、训练方法和评估指标，使其在多种问题设置中广泛适用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the limitations of traditional model selection methods, which often fail in nonstationary environments where real-world data frequently exhibit dynamic changes. The authors propose the Model Prediction Set (MPS), a novel framework that integrates conformal inference with model confidence sets to enable adaptive model selection for nonstationary time series. Experimental results from simulations and real-world data analysis show that MPS effectively identifies optimal models in nonstationary contexts, producing high-quality model sets with small cardinality and providing insights into evolving dynamics, thus overcoming the shortcomings of offline methods.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决经典模型选择方法在非平稳环境中的局限性，因为真实世界的数据经常随时间变化而变化。作者提出了模型预测集（MPS），这是一种新颖的框架，结合了保形推断和模型置信集，以实现非平稳时间序列的在线模型选择。来自模拟和真实数据分析的实验结果表明，MPS能够有效识别动态环境中的最佳模型，提供高质量的小规模模型集，并深入洞察数据动态的演变，这是传统离线方法所缺乏的能力。</div>
</details>
</div>
<div class="card">
<div class="title">Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning</div>
<div class="meta-line">Authors: Minwu Kim, Safal Shrestha, Keith Ross</div>
<div class="meta-line">First: 2026-01-28T18:29:21+00:00 · Latest: 2026-01-28T18:29:21+00:00</div>
<div class="meta-line">Comments: 16 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20829v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20829v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model&#x27;s robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过失败前缀条件化在饱和问题上训练推理模型</div>
<div class="mono" style="margin-top:8px">可验证奖励的强化学习（RLVR）显著提高了大型语言模型（LLMs）的推理能力，但随着问题的饱和，训练往往停滞。我们将核心挑战确定为信息性失败的可获取性差：学习信号存在但在标准回放中很少遇到。为了解决这个问题，我们提出了失败前缀条件化，这是一种简单有效的从饱和问题中学习的方法。我们的方法不是从原始问题开始，而是通过对来自稀有错误推理轨迹的前缀进行条件化训练，重新分配探索，从而使模型接触到易失败的状态。我们观察到，失败前缀条件化的性能提升与在中等难度问题上训练的效果相当，同时保持了令牌效率。此外，我们分析了模型的鲁棒性，发现我们的方法在误导性失败前缀下减少了性能下降，尽管在遵循正确早期推理方面有轻微的权衡。最后，我们证明了一种迭代方法，在训练过程中刷新失败前缀，可以在性能达到平台期后解锁额外的收益。总体而言，我们的结果表明，失败前缀条件化为扩展RLVR在饱和问题上的训练提供了一条有效途径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to enhance the reasoning capabilities of large language models (LLMs) in reinforcement learning settings, particularly when training stalls on saturated problems due to the infrequent occurrence of informative failures. The authors propose a method called failure-prefix conditioning, which involves conditioning training on prefixes from rare incorrect reasoning trajectories to improve model exposure to failure-prone states. Experimental results indicate that this approach leads to performance improvements comparable to training on medium-difficulty problems while maintaining token efficiency, and it also enhances robustness against misleading failure prefixes, although with a slight trade-off in early reasoning accuracy. Additionally, an iterative training approach that refreshes failure prefixes further boosts performance after initial gains plateau.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于提高大型语言模型（LLMs）在强化学习环境中的推理能力，特别是在训练因饱和问题而停滞时，因信息性失败的发生频率较低。作者提出了一种称为失败前缀条件化的方法，该方法通过对稀有错误推理轨迹的前缀进行条件化训练，从而改善模型对易失败状态的暴露。实验结果表明，该方法在性能提升方面与中等难度问题的训练相当，同时保持了令牌效率。此外，该方法增强了模型对误导性失败前缀的鲁棒性，尽管在早期推理准确性上略有妥协。此外，迭代更新训练中的失败前缀的方法在性能初步提升后也带来了进一步的性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">In-Context Bias Propagation in LLM-Based Tabular Data Generation</div>
<div class="meta-line">Authors: Pol G. Recasens, Alberto Gutierrez, Jordi Torres, Josep. Ll Berral, Javier Carnerero-Cano, Anisa Halimi, Kieran Fraser</div>
<div class="meta-line">First: 2025-06-11T11:39:29+00:00 · Latest: 2026-01-28T18:25:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.09630v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.09630v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) are increasingly used for synthetic tabular data generation through in-context learning (ICL), offering a practical solution for data augmentation in data scarce scenarios. While prior work has shown the potential of LLMs to improve downstream task performance through augmenting underrepresented groups, these benefits often assume access to a subset of unbiased in-context examples, representative of the real dataset. In real-world settings, however, data is frequently noisy and demographically skewed. In this paper, we systematically study how statistical biases within in-context examples propagate to the distribution of synthetic tabular data, showing that even mild in-context biases lead to global statistical distortions. We further introduce an adversarial scenario where a malicious contributor can inject bias into the synthetic dataset via a subset of in-context examples, ultimately compromising the fairness of downstream classifiers for a targeted and protected subgroup. Finally, we evaluate mitigation strategies based on preprocessing in-context examples, demonstrating that while such interventions can attenuate disparity, the inherent sensitivity of LLMs to adversarial prompts remains a persistent challenge. Our findings highlight a critical new vulnerability in LLM-based data generation pipelines within sensitive domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于大语言模型的表格数据生成中的上下文偏见传播</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）越来越多地用于通过上下文学习（ICL）生成合成表格数据，为数据稀缺场景中的数据增强提供了实用解决方案。虽然先前的研究表明，LLMs可以通过增强代表性不足的群体来提高下游任务的性能，但这些好处通常假设可以访问一组无偏见的上下文示例，这些示例代表了真实数据集。然而，在现实世界中，数据往往是嘈杂的且在人口统计上存在偏差。本文系统研究了上下文示例中的统计偏见如何传播到合成表格数据的分布，表明即使是轻微的上下文偏见也会导致全球统计扭曲。我们进一步引入了一种对抗场景，其中恶意贡献者可以通过一组上下文示例向合成数据集中注入偏见，最终损害针对特定受保护子群体的下游分类器的公平性。最后，我们评估了基于预处理上下文示例的缓解策略，表明尽管这些干预措施可以减轻差异，但LLMs对对抗性提示的固有敏感性仍然是一个持续的挑战。我们的研究结果突显了LLM基础数据生成管道在敏感领域中的一个关键新漏洞。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges posed by biases in synthetic tabular data generation using Large Language Models (LLMs), particularly in data-scarce scenarios. The authors systematically investigate how biases in in-context examples can propagate and distort the distribution of generated data, revealing that even minor biases can lead to significant global statistical distortions. They also present an adversarial scenario where biased in-context examples can be used to compromise the fairness of downstream classifiers, and evaluate mitigation strategies that, while somewhat effective, highlight the ongoing vulnerability of LLMs to adversarial prompts in sensitive applications.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决使用大型语言模型（LLMs）生成合成表格数据时的偏见问题，特别是在数据稀缺且常常失衡的情况下。作者系统地研究了上下文示例中的偏见如何传播并扭曲生成数据的分布，发现即使是轻微的偏见也会导致显著的统计扭曲。他们还探讨了一种对抗场景，其中可以故意引入偏见，从而损害特定子群体的下游分类器的公平性。研究评估了通过预处理上下文示例的缓解策略，发现尽管这些策略可以减少差异，但LLMs对对抗性提示的敏感性仍然是一个重大问题。</div>
</details>
</div>
<div class="card">
<div class="title">Neural Theorem Proving for Verification Conditions: A Real-World Benchmark</div>
<div class="meta-line">Authors: Qiyuan Xu, Xiaokun Luan, Renxi Wang, Joshua Ong Jun Leang, Peixin Wang, Haonan Li, Wenda Li, Conrad Watt</div>
<div class="meta-line">Venue: ICLR</div>
<div class="meta-line">First: 2026-01-26T20:37:11+00:00 · Latest: 2026-01-28T18:25:21+00:00</div>
<div class="meta-line">Comments: Accepted in ICLR&#x27;26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18944v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18944v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于验证条件的神经定理证明：一个现实世界基准</div>
<div class="mono" style="margin-top:8px">定理证明是程序验证的基础，其中验证条件（VCs）的自动证明仍然是主要瓶颈。现实世界的程序验证经常遇到现有自动定理证明器（ATPs）无法证明的困难VC，导致对大量手动证明的迫切需求，这给实际应用带来了负担。尽管神经定理证明（NTP）在数学竞赛中取得了显著成功，展示了机器学习方法在形式推理中的潜力，但其在程序验证，特别是VC证明中的应用仍然基本未被探索。尽管已有关于注释合成和验证相关定理证明的工作，但没有基准专门针对这一基本瓶颈：自动VC证明。本研究介绍了用于验证条件的神经定理证明（NTP4VC），提出了该任务的第一个现实世界多语言基准。我们的基准利用来自Linux和Contiki-OS内核等现实项目的工业管道（Why3和Frama-C）生成在Isabelle、Lean和Rocq等形式语言中语义等价的测试用例。我们评估了大型语言模型（LLMs），包括通用模型和针对定理证明进行微调的模型在NTP4VC上的表现。结果表明，尽管LLMs在VC证明中显示出潜力，但程序验证仍面临重大挑战，突显了未来研究的巨大差距和机会。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the bottleneck in automated proof of Verification Conditions (VCs) in program verification, which often requires extensive manual proofs due to the limitations of existing Automated Theorem Provers (ATPs). The authors introduce Neural Theorem Proving for Verification Conditions (NTP4VC), a novel benchmark that utilizes real-world projects and industrial pipelines to generate semantically equivalent test cases across various formal languages. The evaluation of large language models (LLMs) on this benchmark reveals that while they show potential in VC proving, significant challenges persist, indicating a substantial gap and opportunity for further research in program verification.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决程序验证中自动证明验证条件（VC）的挑战，由于现有的自动定理证明器（ATP）的局限性，通常需要大量的手动证明。作者提出了验证条件的神经定理证明（NTP4VC），这是一个基准，利用真实世界项目和工业管道生成跨各种形式语言的语义等价测试用例。对大型语言模型（LLM）在该基准上的评估表明，尽管它们在VC证明中显示出潜力，但仍然存在显著的挑战需要解决，这表明程序验证领域存在巨大的差距和进一步研究的机会。</div>
</details>
</div>
<div class="card">
<div class="title">Demystifying Prediction Powered Inference</div>
<div class="meta-line">Authors: Yilin Song, Dan M. Kluger, Harsh Parikh, Tian Gu</div>
<div class="meta-line">First: 2026-01-28T18:16:02+00:00 · Latest: 2026-01-28T18:16:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20819v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20819v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Machine learning predictions are increasingly used to supplement incomplete or costly-to-measure outcomes in fields such as biomedical research, environmental science, and social science. However, treating predictions as ground truth introduces bias while ignoring them wastes valuable information. Prediction-Powered Inference (PPI) offers a principled framework that leverages predictions from large unlabeled datasets to improve statistical efficiency while maintaining valid inference through explicit bias correction using a smaller labeled subset. Despite its potential, the growing PPI variants and the subtle distinctions between them have made it challenging for practitioners to determine when and how to apply these methods responsibly. This paper demystifies PPI by synthesizing its theoretical foundations, methodological extensions, connections to existing statistics literature, and diagnostic tools into a unified practical workflow. Using the Mosaiks housing price data, we show that PPI variants produce tighter confidence intervals than complete-case analysis, but that double-dipping, i.e. reusing training data for inference, leads to anti-conservative confidence intervals and coverages. Under missing-not-at-random mechanisms, all methods, including classical inference using only labeled data, yield biased estimates. We provide a decision flowchart linking assumption violations to appropriate PPI variants, a summary table of selective methods, and practical diagnostic strategies for evaluating core assumptions. By framing PPI as a general recipe rather than a single estimator, this work bridges methodological innovation and applied practice, helping researchers responsibly integrate predictions into valid inference.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>揭开预测驱动推断的神秘面纱</div>
<div class="mono" style="margin-top:8px">机器学习预测越来越多地用于补充生物医学研究、环境科学和社会科学等领域中不完整或难以测量的结果。然而，将预测视为真实值会引入偏差，而忽视它们则浪费了宝贵的信息。预测驱动推断（PPI）提供了一个原则性框架，利用来自大型未标记数据集的预测来提高统计效率，同时通过使用较小的标记子集进行明确的偏差修正来保持有效推断。尽管其潜力巨大，但不断增长的PPI变体及其微妙的区别使得从业者在何时以及如何负责任地应用这些方法时面临挑战。本文通过将PPI的理论基础、方法扩展、与现有统计文献的联系以及诊断工具综合成一个统一的实用工作流程，揭开了PPI的神秘面纱。使用Mosaiks房价数据，我们展示了PPI变体产生的置信区间比完全案例分析更紧凑，但双重使用，即将训练数据用于推断，会导致反保守的置信区间和覆盖率。在缺失非随机机制下，包括仅使用标记数据的经典推断在内的所有方法都会产生偏倚估计。我们提供了一个决策流程图，将假设违反与适当的PPI变体联系起来，以及一个选择性方法的总结表和评估核心假设的实用诊断策略。通过将PPI框架视为一种通用配方而非单一估计量，这项工作架起了方法创新与应用实践之间的桥梁，帮助研究人员负责任地将预测整合到有效推断中。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation behind this research is to address the challenges posed by using machine learning predictions in fields like biomedical research and social science, where incomplete data can lead to biased outcomes. The authors propose Prediction-Powered Inference (PPI) as a framework that utilizes predictions from large unlabeled datasets to enhance statistical efficiency while correcting for bias using a smaller labeled dataset. Experimental results using Mosaiks housing price data demonstrate that PPI variants yield tighter confidence intervals compared to complete-case analysis, although issues such as double-dipping can result in anti-conservative confidence intervals. The paper also provides practical tools, including a decision flowchart and diagnostic strategies, to help researchers apply PPI methods responsibly.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决在生物医学研究和社会科学等领域中使用机器学习预测所面临的挑战，这些领域中的不完整数据如果被视为真实情况会引入偏差。作者提出了预测驱动推断（PPI）作为一种框架，利用来自大型未标记数据集的预测来提高统计效率，同时通过较小的标记子集进行偏差校正。主要发现表明，PPI变体相比于完整案例分析产生更紧凑的置信区间，但警告双重使用训练数据可能导致反保守的置信区间。该论文还为研究人员提供了实用工具，以便负责任地应用PPI方法。</div>
</details>
</div>
<div class="card">
<div class="title">Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)</div>
<div class="meta-line">Authors: Ghazaleh Serati, Samuel Foucher, Jerome Theau</div>
<div class="meta-line">First: 2026-01-26T19:02:18+00:00 · Latest: 2026-01-28T18:12:45+00:00</div>
<div class="meta-line">Comments: 30 pages, 8 figures, submitted to Frontiers in Ecology and Evolution</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18891v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18891v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network&#x27;s architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year&#x27;s (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在挑战性北极环境中进行野生动物检测和计数的弱监督框架：以驯鹿（Rangifer tarandus）为例</div>
<div class="mono" style="margin-top:8px">近年来，北极地区的驯鹿数量下降，促使开发可扩展且准确的监测方法，以指导基于证据的保护行动和政策决策。手动解读这些图像劳动强度大且容易出错，突显了在不同场景中进行自动可靠检测的必要性。然而，由于背景异质性严重、空旷地形占主导（类别不平衡）、目标小或被遮挡以及密度和规模变化大，自动检测面临挑战。为使检测模型（HerdNet）更能应对这些挑战，提出了一种基于检测网络架构的弱监督块级预训练。检测数据集包括分布在阿拉斯加的五个驯鹿群。通过学习该数据集中空与非空标签，该方法产生了早期的弱监督知识，以增强检测，相较于从通用权重初始化的HerdNet。相应地，基于块的预训练网络在多群图像（2017年）和独立年份（2019年）的测试集上达到了高准确率（F1：93.7%/92.6%），使得能够可靠地绘制包含动物的区域，以便在大型航空图像上进行手动计数。转移到检测时，从弱监督预训练初始化在正块上相较于ImageNet权重获得了一致的提升（F1：92.6%/93.5%对比89.3%/88.6%），以及全图计数（F1：95.5%/93.3%对比91.5%/90.4%）。剩余的局限性是来自动物类背景杂乱的假阳性和与低动物密度遮挡相关的假阴性。总体而言，在检测之前对粗略标签进行预训练，使得即使在标记数据有限的情况下也能依赖于弱监督预训练权重，取得与通用权重初始化相当的结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The decline of caribou populations in the Arctic has highlighted the need for scalable and accurate monitoring methods to support conservation efforts. This study introduces a weakly supervised framework called HerdNet, which utilizes patch-level pretraining based on a detection network&#x27;s architecture to improve detection accuracy in challenging environments characterized by background heterogeneity and class imbalance. The results demonstrate that this approach achieves high F1 scores of 93.7% and 92.6% on multi-herd imagery and independent test sets, respectively, and shows consistent improvements over traditional initialization methods, although challenges remain with false positives and negatives due to background clutter and low animal density.</div>
<div class="mono" style="margin-top:8px">北极驯鹿种群的下降促使需要有效的监测方法来支持保护工作。本研究提出了一种弱监督框架HerdNet，通过基于补丁级别的预训练来提高在背景异质性和类别不平衡等挑战环境中的检测准确性。结果表明，该方法显著提高了检测性能，在多群体图像和独立测试集上分别达到了93.7%和92.6%的F1分数，同时在手动计数中提供了可靠的映射，尽管仍存在与假阳性和假阴性相关的一些局限性。</div>
</details>
</div>
<div class="card">
<div class="title">AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics</div>
<div class="meta-line">Authors: Bakhtawar Ahtisham, Kirk Vanacore, Jinsook Lee, Zhuqian Zhou, Doug Pietrzak, Rene F. Kizilcec</div>
<div class="meta-line">First: 2025-11-12T22:35:36+00:00 · Latest: 2026-01-28T18:09:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.09785v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.09785v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen&#x27;s kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human &quot;gold&quot; labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AI 注释编排：评估 LLM 验证者以提高学习分析中 LLM 注释的质量</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLM）越来越多地用于注释学习互动，但对其可靠性的担忧限制了其效用。我们测试了以验证为导向的编排提示模型，检查其自身标签（自我验证）或相互审核（交叉验证）是否改善辅导话语的定性编码。使用 30 次一对一数学课程的转录文本，我们在三种条件下比较了三种生产 LLM（GPT、Claude、Gemini）：未经验证的注释、自我验证和交叉验证，涵盖所有编排配置。输出结果与使用 Cohen&#x27;s kappa 的盲审、关注分歧的人类裁决进行基准比较。总体而言，编排在 kappa 上提高了 58%。自我验证相对于未经验证的基线几乎使一致性翻倍，尤其在具有挑战性的辅导动作中获得了最大的提升。交叉验证平均提高了 37%，具有配对和构造依赖效应：一些验证者-注释者对超越自我验证，而另一些则降低了一致性，反映了验证者严格性的差异。我们的贡献包括：（1）一个灵活的编排框架，实例化控制、自我和交叉验证；（2）在真实辅导数据上对前沿 LLM 进行的实证比较，使用盲人“金标准”标签；（3）一种简洁的符号，验证者（注释者）（例如，Gemini(GPT) 或 Claude(Claude)），以标准化报告并明确方向性效应以便复制。结果将验证定位为可靠、可扩展的 LLM 辅助注释在学习分析中的原则性设计杠杆。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research investigates the reliability of Large Language Models (LLMs) in annotating learning interactions, addressing concerns about their utility. The study employs verification-oriented orchestration-prompting models, including self-verification and cross-verification, to enhance the qualitative coding of tutoring discourse using transcripts from 30 one-to-one math sessions. The findings reveal a 58 percent improvement in inter-rater agreement measured by Cohen&#x27;s kappa, with self-verification nearly doubling agreement compared to unverified annotations, and cross-verification achieving a 37 percent average improvement, highlighting the varying effectiveness of different verifier-annotator pairs.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于解决使用大型语言模型（LLMs）进行学习互动注释时的可靠性问题。研究采用面向验证的编排提示模型，通过自我验证和交叉验证方法，提升辅导话语的定性编码，测试对象为30个一对一数学课程的转录文本。研究结果表明，编排使得Cohen&#x27;s kappa的协议度提高了58%，自我验证相比未验证注释几乎使协议度翻倍，尤其在处理具有挑战性的辅导动作时效果显著，而交叉验证平均提高了37%，显示出根据验证者-注释者对的不同而存在效果的变异性。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260129_0342.html">20260129_0342</a>
<a href="archive/20260128_0340.html">20260128_0340</a>
<a href="archive/20260127_0335.html">20260127_0335</a>
<a href="archive/20260126_0328.html">20260126_0328</a>
<a href="archive/20260125_0326.html">20260125_0326</a>
<a href="archive/20260124_0335.html">20260124_0335</a>
<a href="archive/20260123_0336.html">20260123_0336</a>
<a href="archive/20260122_0339.html">20260122_0339</a>
<a href="archive/20260121_0422.html">20260121_0422</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_0325.html">20260118_0325</a>
<a href="archive/20260117_0329.html">20260117_0329</a>
<a href="archive/20260116_0336.html">20260116_0336</a>
<a href="archive/20260115_0332.html">20260115_0332</a>
<a href="archive/20260114_0332.html">20260114_0332</a>
<a href="archive/20260113_0331.html">20260113_0331</a>
<a href="archive/20260112_0325.html">20260112_0325</a>
<a href="archive/20260111_0325.html">20260111_0325</a>
<a href="archive/20260110_0330.html">20260110_0330</a>
<a href="archive/20260109_0330.html">20260109_0330</a>
<a href="archive/20260108_0332.html">20260108_0332</a>
<a href="archive/20260107_0328.html">20260107_0328</a>
<a href="archive/20260106_1857.html">20260106_1857</a>
<a href="archive/20260106_1846.html">20260106_1846</a>
<a href="archive/20260106_0330.html">20260106_0330</a>
<a href="archive/20260105_0325.html">20260105_0325</a>
<a href="archive/20260104_2229.html">20260104_2229</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
